сравнение nlp-модель на задача суммаризация академический текст на русский язык д.в. мельничук, а.в. носкин саратовский национальный исследовательский государственный университет имя н.г. чернышевский 1. введение основной цель дать работа являться ответ на вопрос: «какать из nlp-модель суммаризация (natural language processing, nlp – обработка текст на естественный языке) наиболее оптимально работать в контекст академический литература на русский языке»? под суммаризация текст пониматься процесс автоматический сокращение объём исходный текст путём извлечение наиболее важный и существенный идей, факт и информации, а также представление в форма краткий и сводный текста, который сохранять основной аспект исходный материала. для сравнение эффективность разный тип предобученный (pre-trained) nlp-модель использоваться набор стать из открытый научный электронный библиотека cyberleninka, из часть массив доступный данных, быть использовать текст (text) научный стать и соответствовать аннотация (annotation) они автор на русский языке. весь 825 статей, среди который область наука и тип журнал браться в случайный порядке. 2. модель и дать для исследование быть выделить наиболее популярные, по версия ресурс huggingface hub, открытый nlp-модель суммаризация текста, обученный на один и тот же корпус новостной текст на русский язык (gazeta) [5]. языковой модель gpt-3 (generative pre-trained transformer) использовать механизм трансформера для анализ контекст и генерация последовательность слов, учитывать вероятность каждый следующий слово на основа предыдущий слово в тексте. модель также способный выполнить различный задачи, такие, как ответ на вопросы, перевод текст на другой язык и создание текстовый статей. в наш исследование быть использовать gpt-3 модель, обученный под задача суммаризации, под кодовый название модель на ресурс huggingface hub: rugpt3mediumsumgazeta [6]. модель t5 (text-to-text transfer transformer) также использовать архитектура трансформера и обучаться на задача преобразование текст в текст. на вход подаваться задание и исходный текст, а затем генерироваться выходной текст, решающий поставить задачу. модель обучаться на широкий спектр задач, включая машинный перевод, генерация текста, ответ на вопросы, классификация текст и многое другое. для наш исследование быть использовать базовый модель rut5base, обученный на новостной текст на русский язык (gazeta) под задача суммаризации: rut5sumgazeta [7]. модель mbart (multilingual bidirectional and auto-regressive transformer) использовать технология мультиязычный перевода, обученный на большой количество текст на разный языках. каждый язык представить в вид уникальный кода, и модель мочь работать с несколько язык одновременно. при обучение модель mbart использоваться подход обучение с подкреплением, который позволять модель улучшать свой перевод по мера того, как она получать обратный связь. архитектура трансформера позволять дать модель учитывать контекст и зависимость между слово в предложении. аналогичный образ использовать базовый модель mbart, обученный на новостной текст на русский язык (gazeta) под задача суммаризации: mbartrusumgazeta [8]. 3. метрика для оценка и сравнение языковой модель использоваться два подхода. первый подход - это внешний оценка (external evaluation), при который оценивание модель происходить за счёт решение с её помощь задачи, на который она рассчитана, и дальнейший анализ итоговый показатель потерь/точности, а также являться хороший подход к оценивание моделей, так как это единственный способ реально оценить, как разный модель справляться с интересовать мы задачей. однако реализация данный подход мочь потребовать больший вычислительный мощностей, он применение мочь оказаться медленным, так как для это нужно обучение весь анализировать система (bleu, rouge – это внешний оценка). второй же подход - это внутренний оценка (internal evaluation), который производить оценка сам языковой моделей, без учёт конкретный задач, для решение который они планироваться использовать; она являться не столь информативный для понимание качество работа модель на конкретный задаче, как внешняя, но, если необходимо провести итоговый оценка модели, то данный подход мочь быть весьма эффективный для быстрый сравнение модель (perplexity – это внутренний оценка). в дать работа быть использовать метрики: bleu, семейство метрика rouge и perplexity. метрика bleu (bilingual evaluation understudy) – это алгоритм оценка качество машинный генерация текст (в тот число перевода), основать на сравнение выходной текстов, т.е. сгенерировать (predictions) с известными, эталонный (references) текстами. сам подход заключаться в сравнение два вариант текста, по совпадение слово и они расположению, также это называть схожесть n-грамм (последовательность n слов). в итог получаться количественный оценка соответствие между результат работа nlp-модель и результат работа человека: чем близкий машинный генерация к исходный текст человека, тем он хороший - таков основный идея bleu. метрика bleu включать корректировка весов, такие, как фактор бонус на основа bi-грамм и сглаживание на основа ковариационный матрица предложений, чтобы справиться с некоторый из проблема данный подход [3]. пусть c – множество слово сгенерировать текста, r – множество слово эталонный текста, соответственно c_i и r_i – это i -е слово этот множество (списков). пусть n - максимальный длина n-грамм, который мы рассматриваем. тогда bleu оценивать качество сгенерировать текст с путём вычисление взвесить гармонический средний точность n-грамм: rouge (recall-oriented understudy for gisting evaluation) – это набор показатель (семейство метрик) для оценка автоматический суммирование текст (в тот число машинный перевода), основать на сравнение n-грамм сгенерировать (predictions) текст с n-грамм эталонный (references) текстов. основный идея метрика rouge заключаться в сравнение два текст и подсчёт базовый единица (n-грамм, т. е. последовательность слово и количество пара слов). в результат получать количественный оценка работа nlp-модели, который показывает, насколько сгенерировать текст совпадать с текстом, составить человек (экспертом). в отличие от bleu, rouge использовать как полнота (recall), так и точность (precision) для сравнение сгенерировать текст с эталонный текстами, составить человек [2]. в rouge-1 сравниваться единица (слова) между сгенерировать и эталонный текстами. в rouge-2 сравниваться последовательность из два слов, взять из сгенерировать и эталонный текста. в ряд источник rouge-1 и rouge-2 мочь обозначаться общий запись rouge-n. rouge-l, в свой очередь, не сравнивать n-граммы, а обрабатывать текст и искать самый длинный последовательность (lcs), который являться общий для два текстов, а затем измерять она длину. пусть s – сгенерировать текст, g – эталонный текст, соответственно s_i и g_i - это i-быть слово в s и g. rouge-n оценивать качество генерация из s путём вычисление точность совпадение слово в s с g, подсчитывать количество совпадать (co-occurrences) n-грамм (длить rouge-1 это один слово, для rouge-2 это последовательность из два слов), найти как в выходной дать модели, так и в эталоне, а затем делить это число на общий количество n-грамм в s: метрика perplexity в языковой модель использоваться для оценка того, насколько хорошо модель мочь предсказать следующий слово в тексте. для хороший nlp-модель метрика perplexity быть давать высокий вероятность синтаксически корректный предложениям, а предложение некорректный (ить очень редко встречающимся) – низкий вероятности. при условии, что набор дать состоять из корректный предложений, хороший модель быть та, который назначить высокий вероятность этот тестовый набору, что означать то, что модель обладать хороший понимание того, как устроенный язык [4]. 4. методология методология исследование выглядеть следующий образом: изначально выделяться данные, включать в себя авторский аннотация и три вариант автоматически сгенерировать для каждый отдельно взять текст статья nlp-модель суммаризаций, а затем проводиться сравнение на близость сгенерировать текст с исходный текст авторский аннотации. в результат для каждый исходный статья формироваться оценка по пять метрика для три nlp-моделей. далее, иметь дать результаты, находиться средний по каждый показателю, что и являться итоговый оценка эффективность работа дать nlp-модель на задача суммаризации. 5. результат и вывод в результате, на задача суммаризация академический текст на русский языке, хороший образ проявить себя модель t5, который показать больший эффективность на основа статистический метрик. данный результат мочь быть обусловить тем, что модель t5 обеспечивать хороший производительность и точность на задача суммаризация текста, благодаря свой более общий и гибкий архитектуре, а также улучшить параметр и настройкам, в отличие от mbart и gpt-3. в дальнейший исследование планироваться расширение проверочный набор статей, сравнение больший число моделей, разделение проверочный датасет на область наука и сравнение результат дискретно по научный областям.