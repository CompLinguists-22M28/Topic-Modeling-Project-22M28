определение семантический близость текст с использование инструмент dkpro similarity а. в. крюков санкт-петербургский государственный университет, 1. введение оценка семантический близость текст являться неотъемлемый составлять многий задача современный компьютерный лингвистики, среди который создание и функционирование информационно-поисковый систем, вопросно-ответный систем, система автоматический реферирования, классификация текстов, определение тематика текстов, перефразирования, разрешение лексический неоднозначность и др. до сей пора разработка и тестирование алгоритм и метрика для оценка семантический близость текст проводиться в основный применительно к материал английский языка. это можно проиллюстрировать класс компьютерный инструментов, создать для решение дать задачи: ср. wordnet::similarity1, alchemy api2 и ряд других. о успех в этот область также свидетельствовать результат соревнование semeval3 на специальный дорожка semantic textual similarity. необходимость подобный исследование для русский язык обусловить востребованность ожидать результат в компьютерный лингвистике. в частности, метрика семантический близость текст и определение семантический отношение между слово мочь использоваться при создание инструмент автоматический понимание текстов. в настоящий момент есть прогресс в область автоматический оценка семантический близость на уровень слово (ср. дать russe4 [1]), однако задача определение близость текст не подвергаться тщательный изучению: акцент делаться не на количественный дать о схожесть текстов, а на результат кластеризация или классификация большой число документ в корпус (например, когда нужно определить тематика корпус или назначить рубрика для отдельный он сегментов). наш исследование призвать восполнить существующий пробел. итак, в дать работа мы решать задача оценка семантический близость текст на русский язык средство открытый и свободно распространять компьютерный платформа dkpro similarity, что предполагать изучение возможность дать платформы, адаптация инструмент для работа с русский языком, эксперимент на текстовый материал с использование различный метрика семантический близости. 2. компьютерный инструмент dkpro similarity компьютерный инструмент dkpro similarity5 разработать в дармштадский технологический университет (tu darmstadt)6 исследовательский группа [2]. этот платформа быть создать как дополнение dkpro core, набор компонент по для обработка естественный языка; инструмент поддерживаться на язык java, jython и groovy. преимущество дать платформа являться она открытый характер, реализация множество существующий метрика близость текст с использование стандартизованный способ они вызова, а также возможность разрабатывать собственный метрика на основа уже существующих. dkpro similarity включать в себя различный класс метрика близость текстов: структурные, стилистические, строковые, семантический и фонетические7. в наш исследование мы опираться на строковый метрики, не зависеть от язык обрабатывать текста. полный список реализовать в dkpro метрика близость текст можно найти в хранилище на github: https://github.com/dkpro/dkpro-similarity. однако следовать учитывать, что многие из они не применимый к русский язык 2 3. лингвистический дать мы сформировать экспериментальный выборка текст такой образом, что в он войти тексты, результат вычисление близость который можно быть адекватно оценить (подробный о это см. раздел 4.2), так как для русский язык нет «золотой стандарта» для оценка семантический близость текстов, т.е. корпуса, в который пара текст быть бы снабдить экспертный оценка они сходства8. такой образом, материал исследование послужить следующий группа текстов: − аннотация научный стать из корпус по корпусный лингвистика кафедра математический лингвистика спбгу; − сообщение из сегмент «life» и «news» новостной корпус кафедра математический лингвистика спбгу; − три перевод на русский язык роман в. набоков «пнин» (а именно, перевод г. а. барабтарло, с. б. ильина, б. м. носика); − заголовок новостной стать из корпус парафраз в проект paraphraser.ru9. из каждый группа случайный образ быть выбрать несколько текст для дальнейший работы: пять аннотаций; по пять сообщение из два часть новостной корпуса; пять соответствовать друг друг отрывок из три переводов; а также по пять пара парафраз из каждый группа в корпус (преимущество являться то, что в это корпус каждый пара предложение соответствовать экспертный оценка того, в какой мера они действительно являться парафразами: «-1» — предложение на разный темы, «0» — предложение на один тему, но есть изменение смысла, «1» — абсолютный парафразы). в табл. 1 можно найти информация о длина использовать текстов. перед вычисление семантический близость текст быть провести они обработка: удаление знак препинание и лемматизация с использование библиотека pymorphy210 [3]. 4. ход эксперимент 4.1. использовать метрика семантический близость текст в dkpro similarity реализовать более 15 различный строковый метрика близости, из который в наш исследование мы использовать семь наиболее обсуждаемых, ср. [4, 5, 6, 7]: − word n-gram containment measure — документ разбиваться на n-граммы, и «мера включения» выражаться следующий формулой: cn(a,b)= , где s(a,n) и s(b,n) — это множество n-грамм в документ a и b соответственно [8]; − word n-gram jaccard measure — документ разбиваться на n-граммы, и для они вычисляться коэффициент жаккара: отношение количество общий n-грамм к количество n-грамм в целое [9]; в оба метрика с n-грамм мы использовать параметр n=2. − levenshtein comparator — вычисляться минимальный количество операция вставка или удаление один символ или замена он на другой, необходимый для преобразование один строка в другой [10]; − longest common subsequence comparator — самый длинный общий подпоследовательность вычисляться через нахождение больший количество операция вставка или удаление символ (длить строк, остаться после удаление общий подпоследовательности); затем − производиться нормализация: 1 − , где |a| и |b| – количество символ в документ a и b соответственно [11]; greedy string tiling — алгоритм искать такой разбиение документ а и в на непересекающийся друг с друг одинаковый цепочка (tiles), при который они оказаться покрыть больший число токен в документ [12]; на вход алгоритм принимать минимальный длина цепочка для поиск (по умолчание она равный трем); нормализоваться результат следующий образом: количество «покрытых» токен делиться на количество токен в второй документе: gst(a,b)= [13]; longest common substring comparator — самый длинный подстрока вычисляться с помощь общий для два строка дерево суффиксов; получить значение нормализоваться так же, как и в метрика с общий подпоследовательностью; − cosine similarity — строиться векторный представление сравнивать текстов, рассчитываться косинус угол между векторами; по умолчание вес термы в документ равный частота они встречаемости, а норма вектор вычисляться стандартно, как корень из сумма квадрат они координата [10]. следовать отметить, что значение весь из они принадлежать отрезок [0,1], кроме расстояние левенштейна, которое, наоборот, равно нулю, если два текст идентичны, и тем больше, чем большой в они различие в символах, причём это число ограничить сверху только длина больший текста. также важный деталь являться то, что значение два из дать метрика — word n-gram containment measure и greedy string tiling — зависеть от порядка, в который документ сравниваться друг с другом: в знаменатель формула стоить число, связанный только с один из текст (количество n-грамм в первый документ и длина второй документ соответственно). в связь с это при использование этот метрика мы вычислять оба значения. для текст из каждый группа (см. раздел 3) быть вычислить девять значение близости, в результат что мы получить несколько таблица с результатами: пять для каждый группа текст и одну, в который сравниваться текст из разный групп. в таблица 2 можно увидеть, как выглядеть значение весь метрика близость для сравнение несколько пара аннотаций. − здесь и в последующий таблица цифра в название столбцы или строка — это условный обозначение (порядковый номера) сравнивать текст 4.2. оценка результат близость текст как мы уже говорили, «золотой стандарта» для задача определение схожесть текст на русский язык не существует, поэтому мы выработать собственный способ оценка получить результатов. напомним, что в корпус парафраз предложение уже быть оценить вручную (см. раздел 3). мы решить следовать такой же методу, но он подходить только для текстов, который изначально близкий друг к другу: из наш материал этот параметр соответствовать отрывок перевод роман «пнин». каждый из они мы разбить на небольшой фрагмент (по одному-двум предложениям), соответствовать друг друг в разный переводах. в результат каждый из пять изначальный отрывок быть представить несколько текстовый документами, в который находиться три маленький отрывка. быть провести эксперимент с участие информант — эксперт (студент кафедра математический лингвистики). мы попросить они оценить попарный сходство фрагментов. семантический близость целостный текст определяться через средний оценка близость они отрывков. каждый значение оцениваться два участниками, и сравнение проводиться отдельно по два критериям: 1) смысловой критерий: насколько текст похожий по смысл (использоваться шкала «0−1−2», где «2» — сильный степень схожести, «1» — средний степень, «0» — небольшой степень схожести); 2) формальный критерий: насколько близость текст определяться входящий в они состав слово (такж использоваться шкала «0−1−2», но при оценка предлагаться учитывать критерии, схожий с критерий автоматический распознавание парафраз в проект paraphraser.ru): a) наличие одинаковый слов; b) наличие синоним / транспозиция / общий корней. в результат для каждый пара сравнивать текст быть получить два значение от «0» до «2»: один выражать близость текст с смысловой точка зрения, другой — с формальной, и именно они использоваться в машинный обучение (см. раздел 4.3.). для оценка согласованность ответ участник эксперимент мы использовать взвесить каппа коэн (weighted cohen’s kappa), присваивать вес 0,1 неодинаковый ответам, отличаться друг от друг на единица (то есть оценка «0» и «1» или «1» и «2»), и вес 10 — тем случаям, когда участник поставить оценка «0» и «2» один отрывку. показатель согласованность оказаться равный 0,68. однако для другой текст из экспериментальный выборка подобный критерий не применим, так как они изначально не объединить общий темой. поэтому мы следовать следующий стратегии: исходить из того, что текст из один группа похожий друг на друг больше, чем на текст из другой групп, каждый пара документ мы поставить оценка «1», если они принадлежать один группе, и «0», если они относиться к разным. после это шаг количество набор дать увеличилось: a) результат для текст из корпус новость быть разделить на три набора: два, состоять из значение близость текст внутри подгруппа «news» и «life» отдельно, и один, включать сравнение текст как внутри этот подгрупп, так и между собой; b) из группа с текст роман «пнин» быть так же составить два набора: один включать только сравнение перевод одинаковый фрагментов, другой — сравнение любой текст из романа; этот разделение обусловить тем, рассматривать ли мы всё текст из корпус новость или роман «пнин» как относиться к один группа или к разным. c) также мы создать ещё один набор данных, в который близость парафраз оцениваться бинарно: «0», если в корпус стоять значение «-1», т.е. если предложение друг с друг никак не связаны, и «1», если в корпус быть указать оценка «0» или «1». 4.3. обучение на данный этап у мы быть одиннадцать набор данных, объект в который выступать пара текстов, а они признак — значение мера близости. к признак мы также добавить длина оба текстов, так как от они зависеть значение некоторый метрика (см. раздел 4.1.). такой образом, каждый объект характеризоваться одиннадцать признаками, а также эталонный значением: для семь датасет это быть значение «1», для один (не-бинарный оценка парафраз) — «-1», «0» или «1», для два (смысловой и формальный близость отрывок из роман «пнин») — вещественный значение от 0 до 2, и для один (текст из разный групп) — значение «0». каждый датасет с значение целевой признак «1» быть объединить с датасет с «0», значение признак отмасштабированы. в результат каждый набор дать состоять в средний из 35 объектов. так как для оценка результат мы использовать трёхкратный кросс-валидацию, каждый раз объём обучать выборка составлять примерно 66% (23 объекта), а тестовой, соответственно, 33% (12 объектов). машинный обучение производиться на язык программирование «python», с использование библиотека scikit-learn12. в она можно найти реализация методов, о который речь пойти дальше. для задача классификация эксперимент проводиться с несколько линейный моделями: logistic regression, ridge classifier, sgd classifier, passive aggressive classifier, perceptron. различие в метод они работа для наш исследование несущественно, достаточно знать основной принцип работа линейный модель в целом. каждый признак объект они присваивать определённый коэффициент — он вес, который умножаться на значение признак у каждый конкретный объекта, потом получить значение складываются, и в зависимость от результат объект относиться к тот или иной классу: к класс «1», если результат положительный, и к класс «0»,есть он отрицательный. в результат для каждый набор дать выбираться один модель, показать хороший результат при трёхкратный кросс-валидация с оценка результат по f-мера (см. таблица 3). пояснить некоторый обозначение в таблице. если название метод не снабдить дополнительный комментариями, использоваться он реализация с параметр по умолчанию. «grid search» — подбор хороший комбинация параметр из предложить пользователем. «l1 regression» - это использование l1-регуляризация (регуляризация лассо) вместо l2-регуляризации, который применяться по умолчанию. для два задач, где ответ должный быть быть вещественный число (датасет с проставить вручную оценка близость фрагмент из роман «пнин»), также использоваться линейный модели, но они не показать точный результатов. малый значение средний абсолютный ошибка (mean absolute error) удаться достичь, использовать random forest regressor: для оценка по смысл ошибка оказаться равный 0,208, а для формальный оценка — 0,188. 4.4. вывод как мы видим, классификаторы, обученный даже на такой простой признаках, как значение строковый метрика близость текстов, показывать неплохой результаты. в связь с это мы предлагать использовать веса, назначить признак линейный моделями, в качество способ оценка строковый метрика для конкретный задачи. для этот цель быть составить таблица с значение вес хороший модель (см. табл. 4: в она выделить больший вес для каждый датасета). для каждый метрика мы вычислить средний значение вес по модуль (переть это мы не учитывать вес для датасет «all news» и «all pnin»13, так как изз использование регуляризация лассо (l1) многие признак иметь нулевой вес, а другие, наоборот, значительно бóльший вес по сравнение с остальными). вычисление показали, что больший вес у n-gram containment measure и cosine similarity. такой образом, именно они наиболее подходить для поставить задачи. см. таблица 4. для данный набор дать (парафраз с оценка «1», «0», «-1») класс не два, как в остальной датасетах, а три, и классификатор работать по принцип «один против всех» (one vs all), отделять каждый из они от два остальных; именно поэтому здесь три набор весов. 5. заключение итак, мы показали, что даже строковый метрика оценка близость текстов, которые, как обычно считается, давать хороший результат только для очень схожий по набор слово текстов, в данный случай позволять линейный модель достаточно хорошо работать при классификация текстов. в дальнейший также планироваться провести эксперимент с семантический метрика близости, опираться на внешний источник знание (например, на «википедию»: см. esa [14]), и сравнить результаты, который быть получены, с результат данный исследования. также планироваться расширить языковой материал и, возможно, использовать более сложный модель машинный обучение для получение хороший результатов.