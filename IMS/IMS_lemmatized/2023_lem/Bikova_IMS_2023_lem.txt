оценка эмоциональный окраска пост социальный сеть «вконтакте», включать эмодзи, метод машинный и глубокий обучение а.п. быков 1. введение уже не один десятилетие исследователь достаточно много внимание уделять анализ тональность текст и речи. результат анализ эмоциональный окраска текст иметь множество практический применений, например, в различный приложение при работа с клиентами, в политология при работа с политический окрасить текстами, здравоохранении. изучаться потенциал анализ эмоция для выявление и предотвращение различный форма онлайн-злоупотреблений, например, запугивание пользователей. кроме того, расти интерес к тому, как эмоция передаваться в разный язык и культурах, и как это мочь повлиять на оценка эмоциональный окраска различный информация [1]. оценка эмоциональный окраска текст мочь быть полезный в многий областях, например, для того, чтобы понять какой настроение выразить в тексте. этот информация мочь использоваться для анализ мнений, анализ отзыв клиентов, мониторинг социальный сетей. понимать эмоции, выраженный в тексте, организация мочь хороший учитывать потребность и предпочтение свой клиентов. понимание эмоция также можно использовать в личный общении, чтобы оценить настроение человек и отреагировать соответствовать образом. в данный исследование оценка эмоциональный окраска текст пост в социальный сеть «вконтакте» проводиться метод машинный и глубокий обучения. для разметка пост использоваться автоматический разметка на основание встречаться в этот пост эмо́дзи. эмо́дзь — это цифровой изображение или значки, который использоваться в текстовый сообщение в различный социальный сетях, в тот число «вконтакте». язык эмо́дзь свой родиться графический язык, где вместо слово использоваться сочетание картинок. впервые эмо́дзь появиться в япония и распространиться по весь миру. в настоящий время использование эмо́дзь достаточно популярно и доступно в самый разный стиль и дизайнах. популярность эмо́дзь обусловить тем, что они мочь передавать эмоция и добавлять контекст к текстовый общению. в некоторый случай эмо́дзь помогать преодолевать языковой барьер и делать общение более доступный среди людей, который владеть разный языками. 2. подход к анализ эмоциональный окраска текст анализ тональность текст - один из направление в компьютерный лингвистике, в рамка который решаться задача выявление мнение автор текст по повод того, что обсуждаться в тексте. тональность текст можно рассматривать как с точка зрение автор текста, так и с точка зрение того, кто читать и воспринимать этот текст. поскольку в данный исследование эмо́дзь являться маркёр для разметки, а эмо́дзь проставлять сам автор текста, то в это исследование тональность и эмоциональный окраска текст рассматриваться с точка зрение автор это текста. в целом, анализ эмоциональный окраска текст подразумевать себя применение методов, с помощь который можно определить, к какой класс относиться тот или иной текст. в основный использоваться алгоритм на основа словарь и правило [2; 3] и метод на основа машинный обучения. также существовать комбинированный методы, в который словарь оценочный лексика являться компонент модель машинный обучение [4]. для многий задача автоматический обработка текст необходимый специально разметить текстовый данные, например, для автоматический распознавание в текст ирония или сарказм [5]. больший популярность в задача анализ тональность приобрести метод машинный обучения. с начало 2000ха год широко применяться классический метод машинный обучения, такой как логистический регрессия, метод опорный векторов, наивный байесовский классификатор [6]. также широко применяться классический нейронный сети, например, рекуррентный нейронный сеть и свёрточный нейронный сеть [7]. в 2019 год появиться новый подход к анализ текст на основа нейросетевой архитектура трансформер, такой как модель bert [8]. использование архитектура серия bert для различный задача автоматический обработка текст привести к рост качество решение этот задач, в тот число и в задача анализ тональности. первоначально модель bert обучаться на многоязычный текстовый данных, затем в ряд исследование быть выявлено, что дообучение bert на дать конкретный естественный язык мочь дать хороший результат решение задача для это языка. так, например, в работа [9] исследователь описывать модель rubert, который дообучить на модель bert для русский языка. 3. сбор и разметка дать набор дать создаваться самостоятельно из пост социальный сеть «вконтакте». дать взять из 100 наиболее популярный сообщество «вконтакте» на 5 февраль 2023 года. статистика по самый популярный сообщество взять с сайт «toppost». выбор пост из социальный сеть «вконтакте» в качество материал исследование обусловить тем, что дать социальный сеть являться популярный платформой, который пользоваться русскоязычный пользователи. в пост пользователь выражать собственный мнение и открыто взаимодействовать посредством различный реакций (лайки, комментарии, репосты). в социальный сеть частый происходить неформальный эмоционально окрасить общение, поэтому текст пост можно использовать для оценка эмоциональный окраска текста. api (application programming interface) «вконтакте» представить в открытый доступе, с помощь открытый метод быть написать скрипт для скачивание текст постов. в качество маркёр для разметка текст использоваться эмо́дзи, который встречаться в постах. разметка на основа эмо́дзь являться ограничение данный исследования, поскольку такой разметка мочь быть недостаточно для точной классификация текст по эмоция и тональности, особенно в тот случае, если эмо́дзь использоваться автор пост неоднозначно. для пояснение значение эмо́дзь и они классификация использоваться карточка с описание с сайт «смайлик эмо́дзи». собранный словарь эмо́дзи, который встречаться в скачать постах, состоять из 146 эмо́дзи, входящий в тематический группа smileys & emotion. получить 146 эмо́дзь распределить по классам. в этот класс учитываться эмоциональный составлять и тональный составляющая, поскольку однозначно категоризировать эмоция достаточно сложно, например, для такой эмоции, как удивление, мочь присутствовать как положительная, так и отрицательный тональность (см. табл. 1). таблица 1. класс эмоция и тональность № эмоция настроение (тональность) 1 улыбка (smile) позитивное/негативный (positive/negative) 2 нет эмоция (no_emotion) нейтральное/скептический (neutral/skeptical) 3 удовольствие позитивный (positive) 4 нет эмоция (no_emotion) позитивное/негативный (positive/negative) 5 грусть (sadness) негативный (negative) 6 страх (feat) негативный (negative) 7 стыд (shame) негативный (negative) 8 гнев (anger) негативный (negative) 9 отвращение (disgust) негативный (negative) 10 удивление (surprise) позитивное/негативный (positive/negative) 11 отвращение (disgust) нейтральное/скептический (neutral/skeptical) 12 удивление (surprise) негативный (negative) 13 нет эмоция (no_emotion) негативный (negative) 14 грусть (sadness) позитивное/негативный (positive/negative) 15 испуг (fear) позитивное/негативный (positive/negative) самый большой количество эмо́дзь 26 из 146 относиться к класс joy positive (удовольствие позитивный настроение). для оценка эмоциональный окраска провести автоматический разметка дать на основа использовать в текст эмо́дзи. для обучение и оценка алгоритм машинный обучение быть выбрать пост с 1 эмо́дзь и длина пост не более 11 токен вместе с эмо́дзи, получиться 9220 постов. в дальнейший планироваться исследовать текст с другой параметр по количество эмо́дзь и количество токен в посте. среди выбрать дать большой весь пост с эмо́дзь из класс smile positive/negative (улыбка позитивное/негативный настроение), получить набор дать являться несбалансированным. для эффективный работа с дать необходимый они предобработка. для это из текст пост удалить id пользователь и групп, текст перевести в нижний регистр. получить 9220 пост автоматически разметить по 15 выделить классам. 4. эксперимент с модель машинный и глубокий обучение выбор метод для анализ эмоциональный окраска текст зависеть от требование решать задача и характер набор данных. для того, чтобы узнать, какой метод большой весь подходить для данный исследования, быть провести ряд экспериментов. тестовый выборка дать составлять 20% из общий число постов, то есть 9220 * 0,2 = 1844 поста. для оценка эмоциональный окраска разметить пост использоваться классический метод машинный обучение из пакет scikit-learn. для предобработка пост использоваться лемматизатор pymorphy2. эксперимент проводиться для текст с пунктуация и с эмо́дзи, для текст без пунктуация и без эмо́дзи, для лемматизировать с помощь pymorphy2 текст c пунктуация и с эмо́дзи. использоваться представление слово в вид мешок слово (bag of words) [10], предобученный плотный векторный представление слово для русский язык из библиотека navec и word2vec [11] для классический метод машинный обучения, такой как, наивный байесовский классификатор (gaussiannb), логистический регрессия (logistic regression), метод опорный вектор (svm), градиентный бустинг (gradient boosting), случайный лес (random forest), классификатор дерево решение (decisiontreeclassifier). также провести эксперимент с использование ансамбль классификатор с мажоритарный и мягкий голосование с помощь votingclassifier. для эксперимент использоваться нейросетевой модели: одномерный свёрточный нейросеть cnn, рекуррентный нейросеть lstm (long short-term memory) и рекуррентный нейросеть gru (gated recurrent units). 5. результат оценка эмоциональный окраска текст пост для оценка качество классификация использоваться метрики: f1-мера по макроусреднение (macro) и f1-мера по взвесить усреднение (weighted). выбор дать метрика для оценка эмоциональной окраска текст пост обусловить тем, что полученный набор дать не являться сбалансированным. по f1-мера лучший результат получиться для модель bow +votingclassifier (soft) (мешок слово + ансамблевый метод с мягкий голосованием) на лемматизировать текст c пунктуацией и с эмо́дзи, f1-мера macro равный 69.70%, f1-мера weighted равный 82.06%. получить результат представить в таблица 2 (хороший результат выделить жирный шрифтом). таблица 2. результат оценка эмоциональный окраска текст для классический метод машинный обучение модель f1 macro % f1 weighted % bow + logistic regression (текст с пунктуация и с эмо́дзи) 51.74 78.97 bow + svc (текст с пунктуация и с эмо́дзи) 40.26 72.21 bow + randomforestclassifier (текст с пунктуация и с эмо́дзи) 65.10 80.54 bow + decisiontreeclassifier (текст с пунктуация и с эмо́дзи) 63.79 79.45 bow + gaussiannb (текст с пунктуация и с эмо́дзи) 28.49 62.17 bow + gradientboostingclassifier (текст с пунктуация и с эмо́дзи) 65.27 81.48 bow + votingclassifier (hard) (текст с пунктуация и с эмо́дзи) 64.64 81.34 bow + votingclassifier (soft) (текст с пунктуация и с эмо́дзи) 67.99 82.02 navec + logistic regression (текст с пунктуация и с эмо́дзи) 11.31 49.51 navec + svc (текст с пунктуация и с эмо́дзи) 6.78 50.25 navec + randomforestclassifier (текст с пунктуация и с эмо́дзи) 11.02 51.75 navec + decisiontreeclassifier (текст с пунктуация и с эмо́дзи) 10.21 46.40 navec + gaussiannb (текст с пунктуация и с эмо́дзи) 1.15 4.34 navec + gradientboostingclassifier (текст с пунктуация и с эмо́дзи) 8.19 49.25 navec + votingclassifier (hard) (текст с пунктуация и с эмо́дзи) 10.50 51.68 navec + votingclassifier (soft) (текст с пунктуация и с эмо́дзи) 11.02 52.07 word2vec + logistic regression (текст с пунктуация и с эмо́дзи) 5.17 48.99 word2vec + svc (текст с пунктуация и с эмо́дзи) 5.17 48.99 word2vec + randomforestclassifier (текст с пунктуация и с эмо́дзи) 23.64 62.53 word2vec + decisiontreeclassifier (текст с пунктуация и с эмо́дзи) 15.22 54.54 word2vec + gaussiannb (текст с пунктуация и с эмо́дзи) 1.63 7.60 word2vec + gradientboostingclassifier (текст с пунктуация и с эмо́дзи) 15.55 57.24 word2vec + votingclassifier (hard) (текст с пунктуация и с эмо́дзи) 11.76 54.77 word2vec + votingclassifier (soft) (текст с пунктуация и с эмо́дзи) 13.21 57.14 bow + logistic regression (текст без пунктуация и без эмо́дзи) 8.33 52.19 bow + svc (текст без пунктуация и без эмо́дзи) 6.99 50.60 bow + randomforestclassifier (текст без пунктуация и без эмо́дзи) 15.36 53.06 bow + decisiontreeclassifier (текст без пунктуация и без эмо́дзи) 13.42 50.57 bow + gaussiannb (текст без пунктуация и без эмо́дзи) 10.86 39.11 bow + gradientboostingclassifier (текст без пунктуация и без эмо́дзи) 12.58 51.35 bow + votingclassifier (hard) (текст без пунктуация и без эмо́дзи) 14.38 52.34 bow + votingclassifier (soft) (текст без пунктуация и без эмо́дзи) 14.80 53.75 navec + logistic regression (текст без пунктуация и без эмо́дзи) 12.28 50.47 navec + svc (текст без пунктуация и без эмо́дзи) 7.67 50.36 navec + randomforestclassifier (текст без пунктуация и без эмо́дзи) 10.57 51.80 navec + decisiontreeclassifier (текст без пунктуация и без эмо́дзи) 10.63 44.41 navec + gaussiannb (текст без пунктуация и без эмо́дзи) 1.05 1.05 navec + gradientboostingclassifier (текст без пунктуация и без эмо́дзи) 9.12 49.62 navec + votingclassifier (hard) (текст без пунктуация и без эмо́дзи) 11.41 51.92 navec + votingclassifier (soft) (текст без пунктуация и без эмо́дзи) 11.89 52.67 word2vec + logistic regression (текст без пунктуация и без эмо́дзи) 5.17 48.99 word2vec + svc (текст без пунктуация и без эмо́дзи) 5.17 48.99 word2vec + randomforestclassifier (текст без пунктуация и без эмо́дзи) 9.71 51.74 word2vec + decisiontreeclassifier (текст без пунктуация и без эмо́дзи) 9.83 45.48 word2vec + gaussiannb (текст без пунктуация и без эмо́дзи) 0.03 0.01 word2vec + gradientboostingclassifier (текст без пунктуация и без эмо́дзи) 8.58 49.09 word2vec + votingclassifier (hard) (текст без пунктуация и без эмо́дзи) 8.78 50.66 word2vec + votingclassifier (soft) (текст без пунктуация и без эмо́дзи) 8.91 50.82 bow + logistic regression (лемматизировать текст c пунктуация и с эмо́дзи) 51.49 78.64 bow + svc (лемматизировать текст c пунктуация и с эмо́дзи) 40.16 72.11 bow + randomforestclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 66.77 81.43 bow + decisiontreeclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 66.30 79.28 bow + gaussiannb (лемматизировать текст c пунктуация и с эмо́дзи) 27.26 60.74 bow + gradientboostingclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 67.01 81.74 bow + votingclassifier (hard) (лемматизировать текст c пунктуация и с эмо́дзи) 63.35 81.32 bow + votingclassifier (soft) (лемматизировать текст c пунктуация и с эмо́дзи) 69.70 82.06 navec + logistic regression (лемматизировать текст c пунктуация и с эмо́дзи) 11.39 49.15 navec + svc (лемматизировать текст c пунктуация и с эмо́дзи) 6.59 50.04 navec + randomforestclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 11.14 51.98 navec + decisiontreeclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 9.89 46.18 navec + gaussiannb (лемматизировать текст c пунктуация и с эмо́дзи) 1.14 4.83 navec + gradientboostingclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 7.35 49.20 navec + votingclassifier (hard) (лемматизировать текст c пунктуация и с эмо́дзи) 10.50 51.60 navec + votingclassifier (soft) (лемматизировать текст c пунктуация и с эмо́дзи) 10.91 51.73 word2vec + logistic regression (лемматизировать текст c пунктуация и с эмо́дзи) 5.17 48.99 word2vec + svc (лемматизировать текст c пунктуация и с эмо́дзи) 5.17 48.99 word2vec + randomforestclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 25.85 64.19 word2vec + decisiontreeclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 18.91 55.79 word2vec + gaussiannb (лемматизировать текст c пунктуация и с эмо́дзи) 1.40 6.56 word2vec + gradientboostingclassifier (лемматизировать текст c пунктуация и с эмо́дзи) 18.77 56.97 word2vec +votingclassifier (hard) (лемматизировать текст c пунктуация и с эмо́дзи) 13.93 55.47 word2vec +votingclassifier (soft) (лемматизировать текст c пунктуация и с эмо́дзи) 18.09 59.61 также для эксперимент использоваться нейросетевой модели: одномерный свёрточный нейросеть cnn, рекуррентный нейросеть lstm (long short-term memory) и рекуррентный нейросеть gru (gated recurrent units). хороший результат среди использовать нейросетевой модель показать рекуррентный нейросеть gru на 15 эпоха обучения: f1-мера macro равный 48.77%, f1-мера weighted равный 83.74%. получить результат представить в таблица 3 (хороший результат выделить жирный шрифтом). таблица 3. результат оценка эмоциональный окраска текст для нейросетевой метод модель f1 macro % f1 weighted % одномерный свёрточный нейросеть (токенизатор keras, optimizer=‘adam’, epochs=5) 17.42 71.54 рекуррентный нейросеть lstm (токенизатор keras, optimizer=‘adam’, epochs=5) 11.85 62.66 рекуррентный нейросеть gru (токенизатор keras, optimizer=‘adam’, epochs=5) 28.29 78.42 одномерный свёрточный нейросеть (токенизатор keras, optimizer=‘adam’, epochs=10) 40.20 81.86 рекуррентный нейросеть lstm (токенизатор keras, optimizer=‘adam’, epochs=10) 23.44 78.39 рекуррентный нейросеть gru (токенизатор keras, optimizer=‘adam’, epochs=10) 43.15 83.85 одномерный свёрточный нейросеть (токенизатор keras, optimizer=‘adam’, epochs=15) 27.77 78.96 lstm (токенизатор keras, optimizer=‘adam’, epochs=15) 29.34 79.81 рекуррентный нейросеть gru (токенизатор keras, optimizer=‘adam’, epochs=15) 48.77 83.74 получили, что в случай макроусреднения, т.е. когда весь класс даёться одинаковый вес, независимо от они количество в набор данных, лучший результат f1-мера macro = 69.70% для модель bow +votingclassifier (soft) (мешок слово + ансамблевый метод с мягкий голосованием) на лемматизировать текст c пунктуацией и с эмо́дзи. в случай же взвесить усреднения, т.е. когда вес класс даёться согласно количество объект в этот классах, лучший результат f1-мера weighted = 83.74% для модель рекуррентной нейросеть gru на 15 эпоха обучения. в дальнейший планироваться сравнить получить результат по метрика качество классификация f1-мера с результат работа модель rubert, который позволять работать с текст на русский язык и иметь качественный распределённый векторный вложение (embeddings) текстов. 6. заключение в дать статья представить оценка эмоциональный окраска пост из социальный сеть «вконтакте», описать процесс получения, обработка и использование получить набор данных. приводиться результат эксперимент с использование метод машинный и глубокий обучение с оценкой работа метод по метрика качество классификации. по оценка качество классификация текст пост лучший результат по метрика f1-мера macro = 69.70% показать модель bow +votingclassifier (soft) (мешок слово + ансамблевый метод с мягкий голосованием) на лемматизировать текст c пунктуация и с эмо́дзи. хороший результат по метрика качество классификация f1-мера weighted получить для модель рекуррентный нейросеть gru f1-мера weighted = 83.74%. поскольку эксперт не размечать получить данные, а использоваться автоматический разметка пост на основание встречаться в этот пост эмо́дзи, в дальнейший планироваться провести экспертный оценка получить автоматический разметка пост по выделить классам. также планироваться провести эксперимент на сбалансированный данных. в будущее можно продолжить исследование с использование текст с другой параметр по количество эмо́дзь и токен в тексте.