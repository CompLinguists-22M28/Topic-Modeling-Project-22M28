linis-crowd.org: лексический ресурс для анализ тональность социально-политический текст на русский язык с. в. алексеева, с. н. кольцов, о. ю. кольцов национальный исследовательский университет «высокий школа экономики»- санкт-петербург 1. введение тональный анализ (сентимент-анализ) или автоматизированный анализ эмоциональный окрашенность текст (плохо / хорошо, нравиться / не нравиться и др.) можно отнести к область компьютерный лингвистики, однако, задача он применения, в основном, лежать за предел собственно лингвистика [1]. они можно разделить на два обширный области: маркетинг (в первый очередь — как анализ отзыв на товар и услуги) и социология / политология. последний включает, во-первых, анализ текст сми для выявление того, как тот или иной социально значимый вопрос преподноситься аудитория и, соответственно, какой отклик можно ожидать на они от публики. во-вторых, это исследование текст социальный медиа: блогов, социальный сетей, форумов, а также другой пользовательский контент с цель выявление общественный мнение или, более точно, он части, представить в интернете. этот последний компонент являться главный целевой область знание настоящий проекта; в второй очередь проект обращать внимание на анализ сми. на сегодняшний день существовать два основный подход к автоматический определение тональность текстов: (1) словарный и (2) не использовать словарь. последний, применять различный метод автоматический классификация на основа обучать коллекций, удобный тогда, когда такой коллекция доступный в избыток (напр., отзыв на товар с общий позитивный / негативный оценка товара). в англоязычный сфера создать большой количество текстовый коллекция [1], среди который особо можно выделить blog06 (http://ir.dcs.gla.ac.uk/test_collections/blog06info.html) университет глазго, который сконцентрировать на блог разный тематики. в русский сегменте, насколько мы известно, в свободный доступ находиться только коллекция прямой и косвенный речь новостной текстов, создать ромип (http://romip.ru/ru/collections/index.html), но она непригодный к исследование эмоциональный составлять текст блогов. в отсутствие необходимый количество коллекция текст с проставить тональный окраска мы обратиться к словарный подходу. для английский язык словарный подход успешно применяться в система sentistrength (http://sentistrength.wlv.ac.uk/), создать м. фелвол в университет вулверхемптон (великобритания). данный по специально предназначить для анализ социальный медиа. кроме того, в английский сегмент доступный обширный словари, такой как opinionfinder (http://mpqa.cs.pitt.edu/opinionfinder/) и sentiwordnet (http://sentiwordnet.isti.cnr.it/). для русский язык мы известный словарь и. четверкин и н. лукашевич [2] (http://www.cir.ru/sentilexicon/productsentirus.txt), представлять себя список из 5000 оценочный слов, извлечь из коллекция отзыв в несколько предметный область (фильмы, книги, игры, телефоны, камеры). словарь быть разработать исследователь для соревнование ромип по тональный анализ отзывов. как видно из описания, он создать прежде весь для выявление предпочтение в маркетинговый исследованиях, а не для анализ общественный мнение в текст социально-политический направленности. такой образом, цель данный исследование являться разработка тональный словарь и краудсорсинговый веб-ресурс для создание инструмент сентимент-анализа. тональный словарь – это список слов, каждый из который присвоить «вес», описывать он эмоциональный окраску. такой словарь использоваться в программный обеспечении, который находить соответствовать слово в текст и на основа усреднение они вес определять общий тональность текста. точность (качество) работа такой по и такой словарь проверяться путём сравнение он результат с результат работа людей. тогда как создавать веб-ресурс применимый для любой вид тональный разметки, словарь в данный проект создаваться и «настраивается» специально для анализ пользовательский интернет-контент социально- политический содержания. конечный цель использование такой словарь в дальнейший являться изучение общественный мнение интернет-аудитории. 2. разработка тональный словарь составление тональный словарь какой-либо язык требовать вычленение эмоционально окрасить слово из весь слово данный языка, что в полный объём невыполнимо, поскольку любой развитый язык насчитывать несколько сотня тысяча слов. здесь возможно несколько альтернативный стратегий: использование уже накопить знание о язык vs. создание собственных; опора на мнение эксперт vs. сбор представление о язык «простых» носителей. в дать работа быть выбрать сочетание этот стратегий: на первый этап собираться прототип словаря, куда «с запасом» включаться потенциально окрасить слова; на второй этап прототип размечаться добровольцами, по три человек на каждый слово. 2.1. прототип словаря: потенциально окрасить слова, без привязка к текст социально-политический направленности. на первый этап мы использовать уже иметься сведение о тональный окрасить словах. в сила того, что оценочный значение частый весь выражаться в язык при помощь признаковый слово (прилагательное и наречий), мы начать поиск потенциально окрасить слово с частотный словарь прилагательных, создать лаборатория цифровой общество (http://digsolab.ru) на основа обширный коллекция русскоязычный текст фэйсбук в рамка сотрудничество с лаборатория интернет-исследование (линис) ниу вшэ. данный список содержать 14933 прилагательных, встретиться в коллекция не менее 1000 раз. получить прилагательное быть разметить три кодировщик линиса с точка зрение наличие эмоциональный компонент (по 1/3 список на каждый кодировщика). в конец мы получить список из 3293 прилагательных, который кодировщик посчитать отрицательно/положительный окрасить или передавать усиление/уменьшение эмоции. затем словарь прилагательное из социальный сеть фэйсбук быть дополнить следующий данными: − 2310 наречий, получить из прилагательных, уже содержаться в списке. добавление наречие быть сделать автоматически. от прилагательное отрезаться окончание (-ий, -ый, -ой) и добавляться окончание наречие (-о, -е, -и). затем получить слово проверяться при помощь морфоанализатор pymorphy2 (https://pymorphy2.readthedocs.org/en/latest/user/guide.html#id2): если слово присутствовать в словаре, использовать в анализатор (т.е. быть реальный наречием), оно добавляться в список; − словарь и. четверкин и н. лукашевич [2]. словарь находиться в свободный доступ по адресу: http://www.cir.ru/sentilexicon/productsentirus.txt; − 53 междометие быть взять из объяснительный словарь русский язык [3]; 1213 слово быть добавить из словаря, составить ю. в. павлов [4] на основа перевод англоязычный словаря, поставлять с по sentistrength (http://sentistrength.wlv.ac.uk) [5]. sentistrength – программа оценка сила положительный и отрицательный настроений, ориентировать на работа с краткий интернет-сообщениями, публиковать в социальный сеть (myspace, twitter), который в многий отношение сходный с текст блогосферы, в первый очередь с комментарий к постам. такой образом, предварительный итоговый словарь потенциально окрасить тональный слов, составить из различный источник состоять из 11869 лексический единиц, включая повторяться слова. − 2.2. тональный словарь, ориентировать на текст социальный медиа дать блог-платформа "живой журнал". на это этап быть сформировать коллекция документов, посвятить социально-политический тематике, использовать в данный проект с три целями: как источник специфичный для дать предметный область тональный слов, как источник контекст этот слов, облегчать разметка (особенно в случай полисемии), и как источник тестовый коллекции, на который быть проверяться качество словарь и который быть размечаться в 2015 год на вебресурсе. в качество источник дать использоваться запись блог-платформа живой журнал. в линиса быть разработать программный обеспечение blogminer (http://linis.hse.ru/soft-linis), позволять закачивать пост и комментарий из живой журнала. на протяжение год (с март 2013 по март 2014) в лаборатория вестись постоянный еженедельный закачка пост и комментарий 2000 самый популярный блогер из живой журнал (по рейтинг «социальный капитал», предоставлять жж) в реляционный база ms sql server. в дать работа быть использовать пост за весь год в размер порядок 1.5 млн. единиц. период в один год быть взять для того, чтобы компенсировать наличие узкий событийно-зависимый тем, который мочь бы служить источник слишком специализировать слов. топовый блогер быть взяты, поскольку из предыдущий исследование известно [6], что они не отличаться от обычный по тематике, однако дать они блог гораздо менее разредить и гораздо менее зашумлен спамом. тематический моделирование. вычленение группа текст социально-политический тематика для последующий отбор специфичный для они тональный слово возможно несколько способами: заимствование запись из создать кто-то рубрик, либо по тэгам, либо с помощь ручной разметки, либо с помощь автоматический выделение релевантный текст – например, с помощь кластерный анализ или вероятностный алгоритмов, включая тематический моделирование. поскольку представление создатель рубрика и тэг о граница социально-политический не известны, автоматический метод наиболее подходить для самостоятельный извлечение релевантный тем из больший коллекция текстов. мы предпочесть тематический моделирование кластерный анализу, так как оно создавать нечёткий множество текстов, который можно отсортировать по релевантности. тематический моделирование проводиться при помощь программный обеспечение topicminer (http://linis.hse.ru/soft-linis), также разработать в лаборатория интернет-исследований. быть тематический модель заключаться в следующем. в компьютерный лингвистика под тема пониматься совокупность слов, который иметь тенденция встречаться совместно в один и тот же текстах. хотя это упрощённый понимание темы, результат она применение – а именно группа сходный текст – многократно проверяться на предмет интерпретируемость людьми, и демонстрировать хороший качество. такой интерпретация тема позволять сформулировать лингвистический модель генерация контент документ коллекции, и на основание модель разработать алгоритм вычисление распределение документ и слово по темам. на данный момент разработать множество различный вариант тематический модель (latent dirichlet allocation, lda), однако они базироваться на два основный вариантах: 1. вариационный модель [7]. 2. сэмплирование гиббс [8]. в lda предполагается, что существовать конечный множество скрытый тем t, и коллекция документ порождаться дискретный распределение p(d,w, t), где d - документ, w - слово, t - тема. переменный d и w являться наблюдать переменный в коллекция документов, а переменный t — скрытой, т. е. появление каждый пара (d, w) связать с некоторый неизвестный тема t. построить тематический модель коллекция — означать найти множество скрытый тем t, и определить условный распределение p(w| t) ≡ φ(w,t) для каждый тема t и p(t | d) ≡ θ(t,d) для каждый документ d. такой образом, φ(w,t) - представлять себя матрицу, в который набор уникальный слово иметь разный вероятность принадлежность к темам, θ(t,d) - представлять себя матрица в который набор документ иметь разный вероятность по темам. в рамка дать работа использоваться процедура сэмплирование гиббс [8] для нахождение распределение документ и слово по тема по задать коллекция документов. выбор этот методика обусловить вычислительный простотой. существовать множество различный программный средство для проведение тематический моделирование [9]. однако, как показывать анализ этот средство [10], как правило в они отсутствовать что-либо, кроме вычислительный ядро (препроцессинг, интерфейс и др.), и они либо не справляться с больший объемами, либо требовать развёртывание кластера. поэтому быть выбрать программный продукт собственный разработка topicminer (разработчик с.н. кольцов, в.г. филипов) [10, 11], способный работать с больший дать на персональный компьютер и иметь всё необходимый модули: модуль препроцессина, модуль тематический моделирование и модуль анализ результатов. препроцессинг данных. провести препроцессинг включить в себя следующий процедуры: удаление html-тэгов, лемматизация (приведение весь слово к начальный форме), удаление стопа-слово (слов, не несущий в себя смысл и не влиять на он тематику, для что в линиса составить и постоянно корректироваться список), подсчёт частота слово (лемм), удаление слишком частый и слишком редкий слов, не иметь дискриминировать силы, конвертация текст в векторный формат. последний основать на векторный модель текст [12] и предполагать представление текст в вид набор значение частота весь слово коллекции, где частота – это количество раз, который данный слово встретиться в данный тексте. тематический моделирование. входной параметр для сэмплирование гиббс являются: число тем, параметр описывать распределение дирихнуть (α,β), число итерация сэмплирования. результат моделирование являться два матрицы: (а) матрица φ(w,t) распределение слово по темам; (б) матрица θ(t,d) - распределение документ по темам. в каждый ячейка матрица находиться вероятность принадлежность слов/документ к теме. число тем быть выбрать равный 300 на основание предыдущий опыта, показавшего, что на больший коллекция число тем в 100 и маленький приводить к излишний укрупнённый темам, с большой доля мало релевантный текстов. параметр распределение быть заимствовать из [8] и равный 0,1 и 0,5 соответственно. число итерация подбираться экспериментально на основа графика сходимость алгоритм и равно 300. отбор документ социально-политический направленности. такой образом, в ход тематический моделирование мы быть получить два матрицы: матрица, содержать распределение слово по темам, и матрица распределение документ по темам, при это каждый столбец матрица означать отдельный тему. элемент матрица в каждый тема быть отсортировать по убыванию. поскольку величина вероятность в каждый тема падать достаточно быстро, мы быть выделить 100 наиболее вероятностный документ по каждый тема и 200 наиболее вероятностный слов. этот два матрица быть передать три кодировщикам, который определяли, какой из 300 тем являться социально политическими. в результат кодирование быть отобрать 104 социально-политический темы. тема считаться социальнополитической, если она отобрать как минимум два из три кодировщика. согласованность (inter-rater agreement) между три кодировщик составлять 0.578. расчёт проводиться при помощь online calculator for inter-rater agreement with multiple raters: https://mlnl.net/jg/software/ira/. это довольно низкий показатель для простой задач, но для задача вычленение тем из пользовательский контент он редко бывать выше, поэтому и использоваться согласие хотя бы два кодировщиков. несмотря на то, что в выбор тем, относиться к социально-политический тематика мы использовать 100 наиболее вероятностный документ по и 200 наиболее вероятностный слово по каждый теме, для дальнейший работа внутри выбрать тем мы выбирать документы, чей вероятность принадлежность к социально-политический тематика быть не маленький величина 0.1 (средний величина вероятность равный 0,03). такой образом, при выбрать порог вероятность 0.1, из весь массив документ (1.5 миллион документов) у мы получиться 70710 наиболее вероятностный текст социально-политический направленности. формирование окончательный список потенциально окрасить слов. в дополнение к вычленение социально-политический тем лингвист проект быть выделить девять тем, который можно назвать темами, связанный с высказывание мнение или эмоций. такой тема формироваться алгоритм не вокруг предметный областей, а вокруг эмоциональный или оценочный лексики, потому что такой лексика часто встречаться в текст вместе; объект же, на который она направлена, мочь быть разным, в тот число и политическим. такой лексика не специфичный для социально-политический тематики, но передавать эмоциональный оценку, поэтому она быть решить включить в прототип словаря. такой образом, по итог тематический моделирование мы сформировать три следующий список слов: ниже привести пример оформление списка: − частотный список весь слово коллекция из 70710 социальнополитический тематики, привести в нормализовать форму; − список, содержать в себя по 200 наиболее вероятностный слово из каждый из 104 социально-политический тем; после удаление дублироваться слово из 20800 единица в немой остаться 8152 слова; − список, содержать в себя по 200 наиболее вероятностный слово из каждый из девять тем, который быть признать темами, связанный с высказывание мнение или эмоция (752 слова). далее, мы пересечь частотный список слово из коллекция социальнополитический текст с остальной списками, чтобы найти слово для прототип словаря, который присутствовать в отобрать текстах. причем, для каждый найти слово быть указать из какого/какий источника/источник «пришло» слово. т.о. для каждый слова, встречаться хотя бы в один из списков, мы получить информация о том, в какой ещё список (списках) оно встречается. в конечный прототип словарь быть сразу взять всё слова, встречаться не менее чем в два источников. исключение быть сделать для топ-слово социально-политический тем (как специфичный для дать области): всё найти в частотный список слово из 200 наиболее вероятностный слово по каждый из 104 социально-политический тем добавляться в окончательный версия словаря, даже если в остальной источник они не быть представлены. затем мы просмотреть всё слова, который содержаться только в один источник (за исключение слов, получить из 200 самый вероятностный слово к каждый теме) и вручную исключить те, который счесть нерелевантными. в основный это быть слово из словарь и. четверкин и н. лукашевич. это словарь быть составить на основа отзывов, поэтому в он войти такой не относиться к социально-политический сфера слова, как аккумулятор, диагональ, панель. помимо этого, мы просмотреть первый 3500 слово из остаться часть частотный список и отобрать ещё 545 потенциально тональный окрасить слов, а остальные, включая все, оказаться за предел 3500, исключили. после этот операция сумма размер весь список оказаться равный 12612, однако поскольку больший часть слово встречаться в несколько списках, дубликат быть удалены. в итог в окончательно версия словарь потенциально окрасить лексический единица содержаться 9539 единиц. на основание список потенциально окрасить слово и коллекция документов, мы сопоставить каждый слово из словарь по три разный текст социально-политический тематики. для это из весь 70710 текстов, в который встретиться данный слово, выбираться три текст с максимальный вероятность принадлежность к какой-либо социально-политический теме. в финальный коллекция документ войти 28617 документ и словарь в размер 9539 лексический единиц. для успешный разработка по для определение общественный мнение необходимо понимать, какой именно эмоция (хорошо/плохо, усиление/уменьшение) передавать отобрать слово в текст социальнополитический направленности. чтобы получить тональный разметка мы разработать веб-ресурс http://linis-crowd.org, на который метод краудсорсинг [13, 14] в настоящий время проводиться разметка эмоциональный окрашенность сам слово и отобрать текстов. 3. заключение в дать статья описать методика и промежуточный результат создание тональный словаря, ориентировать на текст социально-политический направленности. данный лингвистический ресурс дать возможность в дальнейший разработать методика автоматический определение «эмоциональный заряженности» пользовательский интернет-контента. в сочетание с автоматический извлечение тем из такой текст это позволить социальный исследователь определять общественный мнение – точнее, отношение интернет-активный часть население к разный социально значимый вопросам. важность изучение мнение интернет-общественность подтверждается, среди прочего, высокий роль социальный сеть и блог в прокатиться по мир волна протест и революция 2011-2013 годов.