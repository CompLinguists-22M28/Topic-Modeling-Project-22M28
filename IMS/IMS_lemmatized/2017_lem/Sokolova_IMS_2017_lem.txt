автоматический извлечение ключевой слово и словосочетание из русскоязычный текст с помощь алгоритм kea е.в. соколова, о.а. митрофанов санкт-петербургский государственный университет, 1. введение набор назначить вручную или автоматически выделить ключевой слово и словосочетание текст использоваться для формирование у пользователь общий представление о содержание текста. ключевой слово и словосочетание частый весь понимать как структурный единица текста, содержать наиболее важный информация о содержание текста. необходимо различать два основный подход к решение проблема автоматизация выделение ключевой слово и словосочетаний: назначение ключевой слово и словосочетание (keyphrase assignment) и они извлечение (keyphrase extraction) [2, 3]. главное отличие заключаться в том, что первый подход позволять выделять только тот ключевой слово и словосочетания, который содержаться в некоторый предусмотреть словаре, а второй подход предполагать выбор ключевой информация непосредственно из текста. существовать различный метод извлечение ключевой слово и словосочетание [4, 5]: статистический (например, метрика tf×idf), лингвистический (включать семантический, синтаксический анализ и т.п.), метод машинный обучение (наивный байесовский классификатор, метод опорный вектор и др.), а также гибридный подход (kea, textrank и др.). некоторый из они предполагать наличие словарь или фоновый корпусов, другой не требовать таковых. стоить также отметить, что каждый отдельный алгоритм мочь выделять только ключевой слова, словосочетание или и те, и другой одновременно. так как больший часть исследование в этот область проводиться на материал английский языка, то в англоязычный литература встречаться несколько синонимичный термин для обозначение ключевой слово и словосочетаний, например, «key terms», «keyphrases» или «keywords», но частый весь использоваться последний два, причём как для униграмм, так и для nграмм. в качество основный направление дать работа мы избрать исследование один из алгоритм автоматический извлечение слово и словосочетание из текста, а именно kea (keyphrase extraction algorithm) [6]. данный алгоритм широко известный благодаря свой высокий результат на материал английский язык [7, 8, 9], поэтому мы попытаться применить он к русскоязычный текст и найти оптимальный способ оценка он эффективность для русский языка. такой образом, основный цель наш исследование — адаптация kea для работа с русскоязычный материалом. для её достижение необходимо дополнение алгоритм инструмент для работа с русский язык и подготовка дать для проведение экспериментов. инструмент включать в себя модуль графематический и морфологический анализ для русский языка, а также русскоязычный стоп-словарь. материал для проверка работа алгоритм и оценка он эффективность после адаптация служить четыре корпуса, содержать текст по ракетостроение и аэрокосмический исследованиям. 2. внутренний организация kea и этап он работа kea быть разработать йеном виттен и он коллега в новый зеландия в 1999 г. [1]. как быть отметить выше, kea относиться к класс гибридный алгоритм и включать в себя два этапа: − машинный обучение с учителем: на вход подаваться обучать выборка с выделить автор или эксперт ключевой слово и словосочетаниями; в результат обучение строиться модель для определение ключевой слово и словосочетаний; − автоматический извлечение ключевой слово и словосочетание на основа построить модели. 2. 1. выделение кандидат в ключевой слово и словосочетание на каждый из этап работа выбираться кандидат в ключевой слово и словосочетания, для каждый из который затем вычисляться значение определённый признаков. выбор кандидатов, в свой очередь, предполагать три шага: 1) предварительный обработка подавать на вход документов: – токенизация; – замена знак пунктуация и цифра на символы, обозначать граница словосочетаний; – сегментация слов, предполагать дефисный написание; – удаление остаться небуквенный символов. 2) определение кандидат с помощь следующий набор правил: – ограничение максимальный длина словосочетание (как правило, три слова); – отбрасывание кандидат имя собственных; – отбрасывание кандидатов, содержать стоп-слово в начало или конце. всё последовательность слов, получить на шаг 1, рассматриваться с учёт правил, выделить на шаг 2, в результат что получаться набор наиболее релевантный на данный этап обработка кандидатов. 3) выравнивание регистр и стемминг: в оригинальный алгоритм для английский язык использоваться стеммера джулить ловинс, написать в 1968 г. первоначальный форма и регистр слово сохраняться для представление пользователь в тот случае, если кандидат действительно оказаться ключевой слово или словосочетанием. 2.2. вычисление значение основный признак для каждый кандидат для каждый кандидат вычисляться значение два основный признаков, использовать в дальнейший как в обучать выборке, так и для тестовый набор документов: метрика tf×idf и расстояние от начало документ до первый появление рассматривать слово или словосочетание в нём. 2.3. метрика tf×idf tf×idf (term frequency — inverse document frequency) — это статистический мера частота встречаемость слово или словосочетание в конкретный документе, определять в сравнение с частота он использование в другой документ коллекция или в некоторый фоновый корпусе. для этот цель kea создавать файл, в который хранить информация о частота встречаемость слово или словосочетание в конкретный обрабатывать документ и о количество документ коллекции, содержать данный структурный единицу. такой образом, для каждый слово или словосочетание p в документ d метрика tf×idf рассчитываться по следующий формуле: freq(p,d) — количество раз, который данный слово или словосочетание встречаться в d; size(d) — количество слово в d; df(p) — количество документ в некоторый коллекция или фоновый корпусе, содержать p. n — размер коллекция или фоновый корпуса. второй множитель — это функция правдоподобия, отвечать за вероятность появление данный слово или словосочетание в документ (представить с отрицанием, так как вероятность маленький единицы). если документ не являться часть коллекция или фоновый корпуса, перёд вычисление функция параметр df(p) и n увеличиваться на единицу, чтобы симулировать он появление. 2.4. расстояние от начало документ до первый появление слово или словосочетание в он расстояние от начало документ до первый появление слово или словосочетание в он являться отношение количество слов, предшествовать данному, и общий количество слово в документе. результат представить значение 1 или 0 в зависимость от размер часть документ до первый появление данный слово или словосочетание в нём. 2.5. обучение алгоритм и построение модель прогнозирование кандидат в ключевой слово и словосочетание на данный этап работа алгоритм использоваться обучать выборка с выделить автор или эксперт ключевой слово и словосочетаниями. в весь документ определяться кандидаты, для каждый из который вычисляться значение описать выше признаков. чтобы уменьшить объём обрабатывать данных, игнорироваться слово с единичный частотой, после что каждый кандидат помечаться как «ключевой» или «неключевой». это бинарный деление являться классовый признаком, использовать наивный байесовский классификатор [10]. наивный байесовский классификатор представлять себя классификатор, который определять вероятность принадлежность рассматривать объект к один из заранее определённый классов. при это процесс классификация строиться на предположение о независимость класс друг от друга. такой образом, данный классификатор относить объект x к класс ci тогда и только тогда, когда выполняться условие p(ci|x)>p(cj|x), где p(ci|x) — апостериорный вероятность принадлежность объект x класс ci, а p(cj|x) — апостериорный вероятность принадлежность объект x класс cj. в kea он изучать веса, назначить кандидату, и на они основа часть помечать как «ключевые», а другой — как «неключевые». далее он строить модель, который предсказывает, к какой из обозначить класс относиться слово или словосочетание в зависимость от значение вычислить признаков. 2.6. извлечение новый ключевой слово и словосочетание чтобы выбрать ключевой слово и словосочетание из новый документа, kea определять кандидат и вычислять для каждый из они значение признаков, после что применять модель прогнозирования, построить на предыдущий этапе. она вычислять полный вероятность того, что каждый кандидат являться ключевой слово или словосочетанием, а затем, после обработки, выбираться хороший набор ключевой слово и словосочетаний. когда классификатор обрабатывать кандидат с признак t (tf×idf) и d (distance), вычисляться два величины: и аналогичный для p[no], где y — количество положительный пример в обучать выборке, то есть слово и/ить словосочетания, назначить автором, а n — количество отрицательный примеров, то есть кандидаты, который не являться ключевой (чтоба избежать нулевой вероятность использоваться сглаживание лапласа, который y и n заменять на y+1 и n+1). полный вероятность того, что кандидат являться ключевой слово или словосочетанием, в свой очередь, вычисляться следующий образом: согласно значение этот величины, кандидат ранжироваться и осуществляться два следующий шага. во-первых, значение tf×idf использоваться в тот случае, если вероятность два кандидат равны. вовторых, из список удаляться всё слово и словосочетания, который содержаться в другой выражениях, иметь более высокий ранг. из получить ранжировать список первый r предоставляться пользователю, где r — количество запрашивать ключевой слово и словосочетаний. 3. адаптация kea и оценка он работа на материал русский язык 3.1. планирование эксперимент kea являться универсальный лингвонезависить алгоритмом, он программный реализация позволять использовать он совместно с процессор для любой естественный языка. для проверка эффективность работа данный алгоритм на материал русскоязычный текст мы осуществить адаптация kea, совместить он с модуль графематический и морфологический анализ для русский языка. kea реализовать на язык программирование java и поставляться разработчик с весь необходимый инструмент для работа алгоритм на материал несколько языков. как быть отметить выше, на один из этап свой работа алгоритм подразумевать стемминг. единственный доступный инструмент для работа с русскоязычный текст на java оказываться стеммера портер [11]. основываться на особенность языка, он отсекать лишь суффикс и флексии, поэтому на данный этап мы использоваться морфологический анализатор pymorphy2 [12] для python. проводиться предварительный лемматизация текст как из обучающей, так и из тестовый выборок, после что к обработать текст применяться kea. следующий шагом, требовать адаптации, являться удаление из документ стоп-слов. для этот цель быть использовать стоп-словарь, составить на основа дать из национальный корпус русский язык (нкря) [13], который включать наиболее частотный предлоги, частицы, местоимения, междометия, некоторый вводный слово и конструкции, а также количественный и порядковый числительные, цифра и символ латиница [14]. на основа уже иметься в пакет методов, предполагать удаление стопа-слово из исходный текст для другой языков, быть разработать отдельный метод для русскоязычный стопсловаря. 3.2. ход эксперимента, получить дать эксперимент проводиться на материал четыре корпус русскоязычный текст по ракетостроение и аэрокосмический исследованиям, представлять научный, публицистический, официально-деловой и художественный функциональный стиль [15]. объём каждый из корпус составлять примерно 500 тыс. с/у, суммарный объём обработать текстов, тем самым, оцениваться в 2 млн с/у. для корпус с текст научный и художественный стиль автоматически быть получить список ключевой выражение (по 40 наиболее частотный биграмм, ранжировать по значение mi, общий число — 80 биграмм). корпус быть поделить на обучать и тестовый выборки. для обучение использоваться корпус с текст научный и художественный стилей, а для тестирование — публицистический и официально-делового. в обучать выборка быть разметить употребление выражений, совпадать с биграмм из списка. в результат эксперимент для каждый документ из тестовый выборка быть выделить 20 ключевой слово и словосочетаний. пример ключевой слово и словосочетаний, выделить kea: система координат, космический аппарат, система управления, источник энергии, анализировать причину, принимать решение, солнечный система, планета, химический состав, удельный импульс, сила тяги, решать проблему, процесс горения, стартовый масса, компонент топлива, слой атмосферы, космический корабль, космический аппарат, и т.д. 3.3. оценка качество автоматический выделение ключевой слово и словосочетание существовать два основный подход к оценка качество ключевой слово и словосочетаний, выделить автоматически, и они оба, так или иначе, предполагать участие автор или информантов. первый подход основать на вычисление стандартный метрика из область информационный поиск — точность и полноты. автоматически выделить ключевой информация сравниваться с так называть «золотой стандартом», представить ключевой слово и словосочетаниями, назначить автором. разумеется, у это подход есть свой недостатки. во-первых, выделить автор выражение не всегда наблюдаться в тексте. во-вторых, они выбор порой преследовать также несколько иной цель помимо краткий описание документа. в-третьих, далеко не каждый документ содержать ключевой слова, выделить вручную. в-четвёртых, зачастую автор выбирать лишь небольшой количество слово и словосочетаний. второй подход — оценивание автоматически выделить ключевой выражение экспертами. каждый информант представлять документ и список ключевой слово и словосочетаний, выделить для он автоматически, и предлагать тем или иной образ оценить релевантность каждый выражение по отношение к дать документу. как и у предыдущего, у это подход тоже есть свой недостатки. главный из они является, разумеется, субъективность оценка и её последующий объективизация. второй существенный недостаток — очевидный трудность проведение эксперимент для объёмный документов. мы быть выбрать полностью автоматизированный способ оценка работа данный алгоритма. во-первых, как отмечаться выше, 40 наиболее частотный биграмм для каждый документ из обучать выборка быть получить автоматически. во-вторых, непосредственный оценка результат применение алгоритм kea при работа с экспериментальный корпус осуществляться с помощь построение тематический модель для каждый из корпусов. этот выбор обусловить тем, что ключевой слово и словосочетания, составлять семантический ядро корпуса, находить соответствие в тематический модель корпус (т.е. компонент n-грамм должный быть представить в состав кластеров, отражать распределение слово по тема и тем по документ корпуса). при построение тематический модель корпус использоваться алгоритм lda (latent dirichlet allocation) в пакет gensim для python [12]. в каждый тематический модель отбираться 200 статистически значимый лемма (по 10 из 20 тем), далее фиксироваться они наличие/отсутствие в список ключевой выражений. за единичный исключение всё лемма в состав тем обнаружить в верхний треть список ключевой выражений, который оцениваться как наиболее информативная. 4. заключение такой образом, в ход данный эксперимент быть осуществить адаптация kea посредством дополнение алгоритм инструмент для работа с русский языком. также, мы осуществить оценка эффективность работа kea на материал русский язык с помощь построение тематический модель и выяснили, что получить дать давать основание считать результат работа алгоритм kea приемлемыми, а сам алгоритм в русскоязычный модификация пригодный для использование в лингвистический исследованиях. сравнить результат работа kea на материал русский язык с выдача неоднократно протестировать и доказать свой эффективность тематический моделей, построить с помощь алгоритм lda, мы мочь прийти к выводу, что адаптировать мы алгоритм kea являться весьма полезный инструмент в автоматический определение тематика текста. он показывать удовлетворительный результаты, что подтверждаться нахождение выделить они ключевой слово и выражение в наиболее информативный часть построить тематический моделей, которые, как указываться выше, призвать отражать статистический распределение слово по тема и тем по документ корпуса. что касаться перспектива дальнейший исследования, то планироваться сравнение kea с другой алгоритм и экспертиза результат с участие информантов. исследование поддержать грант рффи № 16-06-00529 «разработка лингвистический комплекс для автоматический семантический анализ русскоязычный корпус текст с применение статистический методов» (2015–2018 гг.).