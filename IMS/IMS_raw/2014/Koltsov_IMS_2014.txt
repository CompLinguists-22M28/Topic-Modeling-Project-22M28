Интерпретация семантических связей в текстах
русскоязычного сегмента Живого Журнала на основе
тематической модели LDA
С.Н. Кольцов, О.Ю. Кольцова, О.А. Митрофанова, А.С. Шиморина
Национальный исследовательский университет «Высшая школа экономики»,
Санкт-Петербургский государственный университет, ИЛИ РАН
1. Введение
Создание сверхбольших корпусов текстов, разработка новых методов и алгоритмов лингвистического моделирования заставляет исследователей поновому взглянуть на смысловую компрессию, специфический класс задач автоматической обработки
естественного языка. Это задачи автоматического
выделения ключевых слов и словосочетаний, классификации и кластеризации лексики и документов в
корпусах текстов, выделения классов слов с близкими дистрибутивными свойствами и т.п. [1]. В
данном ряду особняком стоит задача тематического
моделирования корпусов текстов, поскольку пристальное внимание лингвистов и социологов сейчас
обращено к анализу социальных сетей и выявлению
тематической структуры сообществ [2, 3]. Компьютерная обработка корпусов текстов, сформированных на основе социальных сетей, открывает широкие возможности для оперативной оценки не только
общественного мнения, но и состояния русскоязычного дискурса, динамики словаря, развития внутриязыковых связей. Цель нашего исследования заключается в том, чтобы 1) осуществить эксперименты
по моделированию тематики корпуса текстов Живого Журнала (ЖЖ) Livejournal.ru с помощью программного комплекса TopicMiner, основанного на
алгоритме LDA (Latent Dirichlet Allocation),
2) определить содержательное наполнение тем, отраженных в записях пользователей ЖЖ, 3) выявить
и проинтерпретировать основные типы семантических связей слов внутри тем, 4) найти адекватные
лингвистические модели анализа полученных экспериментальных данных.
2. Моделирование тематики текстов в
компьютерной лингвистике
Тематическое моделирование – способ построения модели корпуса текстов, отражающий переход
от совокупности документов, совокупности слов в
документах к набору тем, характеризующих содержание документов. Тематические модели – модели
со скрытыми переменными, для выявления которых
лучше всего подходит нечеткая кластеризация. При
нечеткой кластеризации любое слово или документ
с некоторой вероятностью относится к нескольким
темам. Можно сказать, что в тематической модели
текстовой коллекции описанию слова или документа ставится в соответствие семейство вероятностных распределений на множестве тем.
В практических разработках последних лет широко используется ряд методов тематического моделирования. Среди алгебраических моделей текста,
на которые опираются процедуры тематического
моделирования, наиболее распространены стандартная векторная модель текста VSM (Vector Space
Model) и латентно-семантический анализ LSA
(Latent Semantic Analysis), среди вероятностных
(генеративных) моделей наиболее всего применяются вероятностный латентно-семантический анализ pLSA (probalilistic Latent Semantic Analysis), латентное размещение Дирихле LDA (Latent Dirichlet
Allocation). Дадим их краткую характеристику (подробные обзоры см. [4–10].
В VSM, а также и в других моделях, текст рассматривается как «мешок слов» и описывается
терм-документной матрицей. Словам или текстам
ставятся в соответствие вектора в n-мерном пространстве. Соответственно, сравнение векторов позволяет оценить, насколько слово характерно для
некого документа, насколько связаны слова между
собой в документе, насколько близки документы.
Недостатки VSM связаны с неудобством использования в работе с текстами больших объемов, с невозможностью учесть синонимические отношения
между словами и их многозначность. Модель LSA
наследует основные характеристики VSM, однако в
LSA для выявления наиболее значимых слов в текстах используется разложение терм-документной
матрицы по сингулярным значениям – так называемое сингулярное разложение (Singular Value Decomposition, SVD). В рамках такого разложения можно
выбрать К наибольших сингулярных значений, соответственно, в преобразованной терм-документной
матрице останутся К первых линейно независимых
компонент, что отражает основную структуру различных зависимостей, присутствующих в исходной
матрице. Таким образом, каждый термин и документ представляются при помощи векторов в общем
семантическом пространстве размерности К. Близость между любой комбинацией терминов и/или
документов легко вычисляется при помощи скалярного произведения векторов. Значение величины K
зависит от задачи: если К велико, то результаты
метода близки к результатам VSM, если значение K
мало, то данный метод не позволяет уловить различие между похожими документами или терминами.
Недостатками метода LSA является сложность работы с большими разреженными матрицами, также
данная методика позволяет указать лишь близость
документов или терминов между собой, но не позволяет сгруппировать похожие документы – термины в темы.
Методы pLSA и LDA относятся к алгоритмам
вероятностного тематического моделирования, которые позволяют анализировать слова в огромных
наборах документов, а также выявлять скрытые темы, связи между темами и изменение их во времени. В основе pLSI лежит модель, которая связывает
скрытые переменные тем с каждым наблюдаемым
словом или документом. Таким образом, каждый
документ может относиться к нескольким темам с
некоторой вероятностью, что является отличительной особенностью этой модели по сравнению с подходами, не позволяющими вероятностного моделирования. Недостатки pLSA обуславливаются следующими причинами. Во-первых, данная модель
содержит большое число параметров, которое растет в линейной зависимости от числа документов.
Соответственно, модель склонна к переобучению и
неприменима к большим наборам данных. В-вторых, отсутствует какая-либо закономерность при
генерации документов из сочетания полученных
тем. Все эти недостатки устранены в модели LDA,
где порождение документа, характеризующих его
тем, слов в этой теме производится с опорой на распределение Дирихле. Данные о свободно распространяемых пакетах для тематического моделирования на основе LDA приведены в конце статьи.
Известны также и другие тематические модели,
в той или иной мере связанные с упомянутыми выше: это, в частности, совместная вероятностная модель JPM (Joint Probabilistic Model), скрытая тематическая марковская модель AHMM (Aspect Hidden
Markov Model), автор-тематическая модель ATM
(Author-Topic Model), модель автор-получатель
ARTM (Author-Recipient Topic Model), корреляционная тематическая модель CTM (Correlated Topic
Model) и т.п.
Спецификация тематических моделей может
быть связана с различиями на уровне лингвистической обработки входных текстов и с привлечением
аппарата дистрибутивной семантики [11, 12]. Большинство разработчиков языковых ресурсов склоняются к необходимости интеграции статистических и
традиционных лингвистических методов анализа,
что было реализовано, например, в моделях семантического пространства WSM (Word Space Model),
HAL (Hyperspace Analogue to Language), COALS
(Correlated Occurrence Analogue to Lexical Semantics)
и т.п. [13, 14]. Использование многоуровневой разметки текстов (лемматизация, морфосинтаксическая
и в случае доступности семантическая аннотация),
учет границ синтаксических групп и существующих
внутри них связей, ограничение контекстного окна,
назначение весов контекстных элементов, нормализация значений коэффициентов совместной встречаемости, свертка признакового пространства – эти
и другие методы способствуют повышению качества автоматической обработки текстов.
3. Корпусные данные и программное
обеспечение экспериментов
Корпус текстов для проведения экспериментов
по тематическому моделированию был автоматически сформирован на основе постов Живого Журнала
Livejournal.ru. Корпус ЖЖ включает в себя записи
первых 2000 блогеров по рейтингу популярности
Живого Журнала за 4 недели (11.03.13 – 07.04.13),
всего 103056 постов, около 30,5 млн с/у. Для загрузки текстов использовался компьютерный инструмент BlogMiner, созданный в Лаборатории Интернет-исследований Национального исследовательского университета Высшей школы экономики ЛИНИС (НИУ ВШЭ) (разработчики О.Ю.Кольцова,
С.Н.Кольцов).
Предобработка текстов корпуса ЖЖ включает в
себя графематический анализ, лемматизацию, очистку от нетекстовых элементов (прежде всего, htmlтегов), создание списка стоп-слов. Лемматизация
текстов осуществлялась с помощью морфологического анализатора mystem [http://company.yandex.ru/
technologies/mystem/] (дата обращения: 15.10.2014)
[15]. В предобработке использовался стоп-словарь
объемом около 1300 лексем. В первую очередь к
стоп-словам были отнесены закрытые классы слов –
предлоги, союзы, междометия, частицы, местоименные форманты и вводные слова. Данные единицы
более близки к грамматическим, нежели к лексическим средствам языка, и таким образом могут быть
легко отброшены при тематическом моделировании. Основой для составления данного списка послужил «Словарь структурных слов русского языка» [16]. Дальнейшая обработка текстов показала,
что в стоп-словарь нужно внести римские цифры,
обозначаемые латинскими буквами, некоторые характерные для ЖЖ слова и обозначения (например,
ljuser), а также нерусскоязычные (прежде всего,
английские и украинские) слова. Сверх 1300 заранее
выделенных лексем, в стоп-словарь были также добавлены слова, имеющие частоту менее 5 с/у в корпусе текстов. После очистки корпуса от стоп-слов
его размер существенно уменьшается, остается около 40% от исходного объема.
В экспериментах задействован программный
комплекс для тематического моделирования TopicMiner, разработанный в ЛИНИС НИУ ВШЭ (разработчики О.Ю.Кольцова, С.Н.Кольцов). TopicMiner
позволяет проводить процедуры предобработки
корпуса текстов и собственно тематического моделирования его содержания. Тематическое моделирование в TopicMiner проводится с помощью алгоритма латентного размещения Дирихле с сэмплированием Гиббса [5, 17]. Результатом работы программного комплекса являются списки наиболее
вероятных документов и слов для каждой темы.
Эксперименты по тематическому моделированию
проводились в несколько итераций с изменением
параметров. Число тем варьировалось от 50 до 400 с
шагом 50 (50, 100, 150, 200, ... 400). Объем списков
слов, соотносимых с темой, ограничивался по умолчанию 100 словами. Все слова внутри темы качественно равноправны. В силу того, что для лингвистической интерпретации результатов было необходимо назначить метки тем, в качестве таковых выбирались слова, формально занимающие первую
позицию в списке.
4. Лингвистическая интерпретация
результатов экспериментов
Наибольший интерес для лингвистического анализа представляет содержательное наполнение тем,
характеризующих корпус ЖЖ, а также исследование типов связей, которые эксплицированы в наборах слов, формирующих темы. Слова, составляющие автоматически сформированные темы, распределяются между номинативным, атрибутивным и
предикативным классами. Наиболее многочисленным является номинативный класс, который представлен существительными абстрактными и конкретными, нарицательными и собственными. Номинативный класс включает в себя обозначения общих
понятий (Бог, жизнь, мир, смерть и т.п.), институтов и явлений общественно-политической жизни
(армия, власть, государство, закон, культура, музей, наука, общество, организация, партия, страна,
фестиваль, церковь, экономика и т.п.); человека
(девочка, дитя, друг, женщина, мама, муж, старик
и т.п.), животных (животное, кот, кошка, олень,
собака и т.п.), бытовых реалий (автомобиль, аэропорт, город, деревня, дом, здание, игрушка, квартира, корабль, магазин, масло, машина, одежда,
отель, самолет, сахар, телефон, файл и т.п.). Из
имен собственных встречаются имена и фамилии
(Александр, Андрей, Джон, Иван и т.п.; Березовский,
Навальный, Медведев, Проханов, Путин, Собчак,
Сталин и т.п.), топонимы (Грузия, Италия, Кипр,
Россия, США и т.п.; Екатеринбург, Москва, Петербург, Ростов и т.п.). Атрибутивный класс включает
качественные (великий, древний, красивый, хороший
и т.п.) и относительные прилагательные (английский, русский, японский и т.п.). Предикативный
класс оказывается самым узким, он представлен
глаголами типа выставлять, любить, оставлять,
просить, прощать, рассказывать, смотреть, случаться, сообщить, считать и т.п.
Автоматически сформированные темы различаются по информативности. С одной стороны, мы
наблюдаем темы, в которых актуализируется основное содержание текстов корпуса ЖЖ (например,
общественно-политическая проблематика в неформальном изложении, свойственном дискурсу социальных сетей), с другой стороны, это фоновые темы,
которые формируются общей лексикой и присутствуют в любых текстах независимо от их тематики
(например, день, месяц, цвет и т.п.). Если в социологических исследованиях более важны темы первого типа, отражающие общественное мнение в
пределах определенного хронологического среза, то
в лингвистическом аспекте полезен анализ того,
какие семантические связи реализуются внутри тем
обоих типов, а также оценка универсальности этих
связей в русском языке.
Важный аспект в оценке содержания корпуса
ЖЖ – это многовариантность тематического анализа, проявляющаяся в возможности пересечения тем.
Например, при разных параметрах экспериментов
повторяются темы с метками власть, день, дорога,
друг, жизнь, компания, мир, область, работа, Россия, самолет, слово, страна, фильм, хороший и т.п.
Это смежные темы, различающиеся наполнением и
отражающие разные аспекты одного явления. Рассмотрим в качестве примера две темы с меткой Россия. Ниже в списках представлены первые 20 слов,
упорядоченные по значению коэффициента ассоциации: Россия1, Путин, партия, власть, выбор,
депутат, президент, единый, Навальный, политическая, глава, оппозиция, политик, член, страна,
Владимир, дума, митинг, кандидат, Медведев и т.п.;
Россия2, страна, русская, народ, государство,
власть, мир, общество, русский, советский, война,
запад, право, история, национальный, СССР, российский, политик, западный, революция и т.п. Можно предположить, что тема Россия1 объединяет тексты о современной политической истории России,
тогда как тема Россия2 более связана с описанием
советского периода.
Смежными являются темы с высокой долей общих слов. Максимальная доля совпадений составляет 36%, как например, в списках для тем самолет и
танк (тип, экипаж, управление, высокий, боевой,
разработка, ракета, масса, система, комплекс,
устанавливать, находиться, скорость, двигатель,
технический, машин, вариант, тяжелый, установка, применение, разрабатывать, конструкция, техник, кг, создавать, км, частить, вооружение, боевая, дальность, составлять, работа, конструктор,
оружие, испытание, целить), что можно объяснить
стереотипностью описаний боевой техники.
Анализируя связи слов внутри тем, мы принимали во внимание следующее соображение: состав тем
определяется автоматически в результате построения статистической модели корпуса текстов, которая отражает близость дистрибутивных свойств
формирующих тему слов, тенденцию их взаимозамены или совместного употребления. На этом основании отношения между словами в темах можно
характеризовать как контекстные или квазиотношения, поскольку они наблюдаются в рамках
определенного корпуса текстов.
Проиллюстрируем обработанный нами материал
в табл. 1, где приведены слова из 20 случайно выбранных тем (списки ограничены первыми 20 позициями из 100). Соотношение слов в темах отражает
многообразие парадигматических и синтагматических отношений, организующих текст. Нам представляется, что наиболее удобная схема описания
языковых связей внутри тем – это аппарат лексических функций в модели «Смысл <=> Текст» [18, 19],
позволяющий охватить предсказуемые, идиоматизированные связи слова и его лексических коррелятов (парадигматических вариантов – «замен» и синтагматических партнеров – «параметров»).
Среди парадигматических отношений доминируют синонимия (Syn), антонимия (Anti), конверсия
(Conv), гиперонимические (Gener), деривационные
(Der) отношения и т.п. Например: Syn: дитя – ребенок; церковь – храм; бог – господь; предприятие –
производство; армия – войска; оружие – вооружение и т.п.; Anti: правда – ложь; хороший – плохой;
детский – взрослый; брать – отдавать; зарабатывать – тратить (деньги); привлекать – отвлекать
(внимание) и т.п.; Conv: обращать – привлекать
(внимание) и т.п.; Gener: игра – футбол; оружие –
пистолет, винтовка, пулемет, ружье; машина –
автомобиль; животное – собака, кошка, кот, медведь и т.п.; Der: казак – казачий; Италия – итальянский; игра – играть, выигрывать; работать – работа; стрелять – стрельба и т.п. Кроме того, внутри тем наблюдаются партитивные отношения: семья
– родители, ребенок, мама, отец, сын, дочь; армия
– полк, генерал, офицер, солдат; винтовка – ствол,
пуля, магазин; машина – руль, колесо; животное –
хвост и т.п.
Синтагматические отношения реализуются на
уровне рамок валентностей, заполняемых словами
из темы. Среди лексических функций этим связям
соответствуют, например, функции Oper1,2, связывающие глагол, название первого или второго актантов в роли подлежащего и название ситуации в
роли дополнения: внимание – обращать, привлекать, уделять, отвлекать; письмо – отправлять,
писать, написать, присылать, доставлять; фильм
– снимать; дом – строить и т.п. В именных атрибутивных сочетаниях, обозначающих характерный
признак объекта, реализуется лексическая функция
Ver («соответствующий назначению»): власть –
политическая, государственная; закон – российский, федеральный; животное – дикое; цвет – яркий и т.п. Довольно распространены стандартные
метонимические связи внутри тем, закрепляемые
лексической функцией Attr: водитель – машина,
автомобиль; автор, писатель – книга; ученый –
наука; журналист – газета; художник – картина и
т.п. Был обнаружен ряд примеров на реализацию
лексической функции Cap («глава», «начальник»):
страна – президент; штаб – начальник; отряд –
командир и т.п., лексической функции Equip («личный состав»): полк – солдат; стадо – олень и т.п.,
лексической функции Doc(res) («документ, являющийся результатом»): писать – письмо; рисовать –
рисунок и т.п. Во многих случаях мы обнаружили,
что наполнение тем соответствует традиционным
лексико-семантическим или тематическим закрытым группам, например: час – минута, секунда, сутки и т.п.; (месяц) – январь, февраль, март, апрель
и т.п., знак (зодиака) – лев, весы, близнец, рак, рыба,
дева, скорпион, телец, водолей и т.п.
Полученный нами материал подтверждает, что
внутренняя организация тем, описываемая как пучок парадигматических и синтагматических связей
между словами из темы, проецируется на структуру
отраженных в корпусе ЖЖ экстралингвистических
ситуаций, где участникам и их признакам соответствует лексическое наполнение тем с учетом их сочетаемостных предпочтений, типового заполнения
рамок валентностей и т.п. Поэтому внутренняя организация тем может быть представлена в виде ассоциативных сетей или ситуационных фреймов [20–
25], где в качестве имени ситуации будет выбрана
метка темы, а представляющие тему слова будут
распределены по слотам, соответствующим участникам ситуации и их признакам. Примеры ситуационных фреймов для тем игра, производство, письмо
и слово приведены в табл. 2.
В лингвистическом смысле тема организуется
словами, проявляющими тенденцию к совместному
употреблению в устойчивых языковых структурах,
точнее говоря, в конструкциях с фиксированными
лексическими компонентами [26, 27]. Например, как
конструкцию следует рассматривать сочетания типа
V(привлекать, обращать, уделять…) + внимание +
PR (на, к, #…) + ADJ(интересный…) + S(проблема…); V(указывать…) + PR (на…) + S(проблема…); S(состояние…) + S(проблема…) и т.п. Тем
самым, тематическое моделирование дает ценный
материал для исследований в области автоматического выделения конструкций [28, 29]
На сегодняшний день в русскоязычной компьютерной лингвистике отсутствуют доступные
программные средства, использующие LDA и
сопоставимые с инструментом тематического моделирования типа TopicMiner. По этой причине
для проверки данных, полученных с помощью
TopicMiner, мы сравнили наполнение тем со списками реакций на соответствующие стимулы в
«Русском ассоциативном словаре» (РАС) [30].
Тексты, присутствующие в социальных сетях вообще и в ЖЖ в частности, есть результат языкового творчества разных авторов, это полилогический дискурс, созданный в условиях, которые
приближаются к спонтанному ассоциативному
эксперименту. Тем самым, можно предположить,
что в корпусе ЖЖ содержатся ассоциативные
связи, отражающие языковое сознание русскоязычных блогеров первой декады XXI века. Поскольку данные РАС относятся к 1980-м...1990-м
годам XX века, сравнение наиболее продуктивных стимулов и связанных с ними ассоциаций,
формирующих ядро языкового сознания русскоязычной среды конца XX века [31, 32], с темами,
автоматически сгенерированными при обработке
корпуса ЖЖ, дает возможность выделить стабильные понятия, фигурирующие в дискурсе независимо от эпохи, и оценить динамику русскоязычной картины мира.
Так, в случае с темой церковь мы наблюдаем
совпадение свыше 30% слов в составе темы и в
списке ассоциатов из РАС (православный, храм,
священник, вера, святая, Христос, Иисус, бог, божий, икона, монастырь, христианский, религия,
молитва, крест, епископ, приход, обряд и т.п.) Это
указывает на существование стабильной идиоматизированной области в парадигматических и синтагматических связях слова церковь, которые одновременно отражается и в теме (где преобладает
парадигматика), и в данных ассоциативного эксперимента (с преобладанием синтагматики)
При сравнении данных корпуса ЖЖ и РАС
для темы газета мы выявили не более 15% пересечений (информация, интересно, ложь, новость,
письмо, политический, правда, пресса, российская, статья, текст, хороший, читать и т.п.). В
составе темы газета присутствуют слова, связанные с электронными СМИ (сайт, сеть, интернет, канал, эфир и т.п.), тогда как в РАС отражено представление о газете как печатном периодическом издании (свежая, вечерняя, новая, бумага,
шрифт, киоск, ежедневная, еженедельная, запах
краски, запах типографии, почтовый ящик и т.п.;
Humanite, Morning Star, Аргументы и факты,
Литературка, Коммунист, Киноафиша, Молодой
учитель, Труд и т.п.). Столь глубокое различие
между корпусом ЖЖ и РАС объясняется не только методологическими расхождениями данных
лингвистических источников, но и динамикой
языкового сознания.
5. Заключение
Наблюдения, сделанные нами в ходе экспериментов, подтверждают целесообразность использования алгоритма LDA при решении задач тематического моделирования, в том числе при оценке
содержания текстов в результате семантической
компрессии. Данные, полученные при обработке
корпуса текстов Живого Журнала с помощью
компьютерного инструмента тематического моделирования TopicMiner (ЛИНИС НИУ ВШЭ), свидетельствуют о многообразии тематики записей
русскоязычных авторов ЖЖ. Нам удалось выявить содержательное ядро корпуса, описать его в
виде набора тем, систематизировать семантические отношения между словами внутри тем, детально охарактеризовать парадигматические и
синтагматические связи в темах. Исследовательский материал допускает интерпретацию с позиций теории лексических функций, ситуационной
фреймовой семантики и грамматики конструкций.
Содержательное наполнение тем позволяет делать
выводы о динамике языкового сознания русскоязычных пользователей социальных сетей.
Перспективы исследования связаны с совершенствованием инструментов автоматической
обработки текстов, с поиском методов автоматизации построения ситуационных моделей на основе тем, с проведением тематического моделирования в специализированных корпусах текстов.