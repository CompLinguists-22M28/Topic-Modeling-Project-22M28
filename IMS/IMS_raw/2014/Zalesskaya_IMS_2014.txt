Программа выявления в тексте двучленных
статистически значимых осмысленных коллокаций (на
материале русского языка)
В.В. Залесская
Санкт-Петербургский государственный университет
Введение
С появлением компьютеров возникла
возможность автоматической обработки
лингвистических данных. Разнообразные
программные средства помогают исследователям
решать многие проблемы лингвистики, позволяют
проводить недоступные ранее исследования.
Появление корпусной лингвистики дало
возможность изучать сочетаемость слов в больших
массивах текстовых данных. Однако использование
стандартных корпусных менеджеров не всегда дает
удовлетворительные результаты.
В данной работе мы обратимся к проблеме
повышения эффективности автоматического поиска
коллокаций. Коллокацией называется «лексикофразеологически обусловленная сочетаемость слов
в речи как реализация их полисемии» [1, с. 193].
Степень обусловленности такой сочетаемости
можно определить автоматически при помощи
статистических методов ― так называемых мер
ассоциации. Мы постараемся увеличить их
эффективность при выявлении коллокаций за счёт
решения проблем, препятствующих корректной
работе современных корпусных менеджеров, и
создать собственное программное обеспечение,
способное выявлять двусловные статистически
значимые осмысленные коллокации в текстах на
русском языке.
1. Меры ассоциации и проблемы
выявления коллокаций
В качестве статистических методов выявления
коллокаций мы рассмотрим в данной работе меры
ассоциации — «математический аппарат для
установления синтагматической связи между
словами в тексте» [4, с. 11]. Меры ассоциации
определяют силу ассоциации между коллокатами на
основе частот их собственной и совместной
встречаемости в корпусе.
При описании мер ассоциации в этой главе мы
будем опираться на материалы Интернет-сайта [7].
1.1. Классификация мер ассоциации
На Интернет-сайте [7] в разделе, посвящённом
мерам ассоциации, даются описание,
характеристика и оценка эффективности различных
типов этих мер. С.Эверт выделяет семь типов мер
ассоциации:
− меры правдоподобия: binomial-likelihood,
multinomial-likelihood, Poisson-Stirling,
Poisson-likelihood, hypergeometric-likelihood;
− точные критерии для проверки гипотезы:
binomial, Poisson, Fisher;
− асимптотические критерии для проверки
гипотезы: z-score, t-score, chi-squared, loglikelihood;
− точечные оценки силы ассоциации: MI,
odds-ratio, relative-risk, MS, Liddell, Dice,
Jaccard;
− оценки силы ассоциации с запасом: MIconf,α;
− меры из теории информации: pointwise MI,
average MI, local MI;
− эвристические меры: frequency, MI2, MI3,
random.
Далее мы подробнее рассмотрим те меры
ассоциации, которые будут использованы нами при
создании программы выявления коллокаций.
1.2. Широко используемые меры ассоциации
1.2.1.Мера Log-likelihood
Как мы уже указали ранее, мера Log-likelihood
(критерий отношения правдоподобия) относится к
типу асимптотических критериев для проверки
гипотезы. Формула для её вычисления существует в
нескольких вариантах, однако мы воспользуемся
модификацией оригинальной формулы Т.Даннинга
[5], предложенной в [7] (см. рис.1).
При создании программы мы будем пользоваться
стандартным способом представления и зададим
значения наблюдаемых частот следующим образом:
O11 = f(n,c);
O12 = f(n) – f(n,c);
O21 = f(c) – f(n,c);
O22 = N – f(n,c) – (f(n) – f(n,c)) – (f(c) – f(n,c)) = N
+ f(n,c) – f(n) – f(c),
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте); N — общее число
словоформ в корпусе (тексте).
1.2.2.Мера MI
Мера MI (коэффициент взаимной информации)
относится к точечным оценкам силы ассоциации. В
основе MI лежит понятие взаимной информации
(mutual information), заимствованное из теории
информации. Коэффициент взаимной информации
сравнивает зависимые контекстно-связанные
частоты с независимыми (при случайном появлении
слов в контексте) [4, с.12]:
MI (n, c) = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте); N — общее число
словоформ в корпусе (тексте).
Мы видим, что наиболее высокие значения MI
получают сочетания, для которых f(n,c) стремится к
. Это характерно в частности для
сочетаний низкочастотных элементов, которые
могут оказаться случайными, а также для разного
рода опечаток.
Мера MI существует в разных вариантах —
обычном и нескольких нормализованных. Мы будем
использовать при создании программы как обычный
вариант, так и один из нормализованных –
эвристическую меру MI3. Её значение вычисляется
по формуле [7]:
MI3 = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте); N — общее число
словоформ в корпусе (тексте).
Как видно, эвристическая мера MI3 увеличивает
вес частоты совместной встречаемости в числителе,
что не даёт MI завышать значения для
низкочастотных сочетаний. Таким образом, MI3
должна показать лучшие результаты при выявлении
коллокаций на практике, чем обычная мера MI.
1.2.3.Мера T-score
T-score - мера ассоциации, которая, как и loglikelihood, относится к асимптотическим критериям
для проверки гипотезы. Она вычисляется по
формуле [8]:
t-score (n, c) = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте); N — общее число
словоформ в корпусе (тексте).
Эта формула показывает, насколько
распределения ключевого слова и коллоката в
корпусе (тексте) зависят друг от друга. Однако
возможна переоценка некоторых случайных
результатов, в частности, сочетаний
высокочастотного элемента с низкочастотным. По
этой причине t-score обычно используется в
комбинации с другими мерами, чаще всего с MI.
1.2.4.Мера Dice
Мера Dice относится к точечным оценкам силы
ассоциации. Она вычисляется по формуле [8]:
Dice = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте).
В отличие от рассмотренных выше мер, Dice не
учитывает размер корпуса (текста), будучи
основанной только на частоте совместной
встречаемости и независимых частотах. Опять же,
как и в случае с MI, мы видим здесь возможность
переоценки низкочастотных сочетаний.
Мера Dice имеет также нормализованную форму
– logDice:
logDice = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте).
1.2.5.Мера Minimum sensitivity
Мера minimum sensitivity – ещё одна точечная
оценка силы ассоциации. Она рассчитывается по
формуле[8]:
minimum sensitivity = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте).
Как и мера Dice, minimum sensitivity не
учитывает размер корпуса (текста). Опять же,
возникает возможность переоценки низкочастотных
сочетаний и элементов.
1.2.6.Мера salience
Мера salience (MI.log-f[6]) не рассматривается в
рамках классификации [7], однако мы считаем
возможным рассматривать её как нормализованный
вариант меры MI. Формула для её расчёта:
salience = ;
где n — ключевое слово; c — коллокат; f(n,c) —
частота встречаемости ключевого слова n в паре с
коллокатом с; f(n), f(c) — абсолютные
(независимые) частоты ключевого слова n и
коллоката c в корпусе (тексте).
Эта мера увеличивает вес частоты совместной
встречаемости ключевого слова и коллоката по
сравнению с MI. Таким образом, эффективность
salience также должна быть выше, чем у MI.
2.Проблемы выявления коллокаций
Как мы указали ранее, существует множество
разнообразных мер ассоциации. Не все из них
используются при решении практических задач, но
даже те, которые уже утвердились в традиционной
практике, не лишены серьёзных недостатков. В
нашем прошлом исследовании [3, с.26―28] мы
выявили и наглядно проиллюстрировали некоторые
проблемы, возникающие при решении практических
задач с использованием распространённых мер
ассоциации. Здесь мы упомянем главные из них,
решить которые мы собираемся в нашей программе.
Во-первых, главной проблемой таких мер
ассоциации, как log-likelihood и t-score, является
выделение сочетаний слов со знаками препинания
(или комбинациями знаков препинания) в качестве
коллокаций. Такие сочетания в текстах встречаются
очень часто и в результате имеют большие значения
этих мер, чем осмысленные коллокации. Нужно
также отметить, что мера MI имеет заниженные
значения для таких сочетаний и таким образом не
рассматривает их как полноценные коллокации.
Второй важной проблемой мер этого рода
является выделение в качестве коллокаций
сочетаний знаменательного слова со служебным.
Такие сочетания, как правило, неосмысленны и не
характеризуются зависимостью распределений
коллокатов друг от друга. Мера MI и здесь
отличается более правильным подходом к таким
сочетаниям и занижением их значений.
Во-третьих, возникает проблема выделения в
качестве коллокаций случайных неосмысленных
сочетаний. К ним относятся опечатки разного рода и
просто случайные употребления сочетаний слов в
некоторых контекстах (например, в заголовках
статей). Это становится наиболее очевидным при
использовании меры MI – она завышает вес таких
неосмысленных сочетаний. Однако такие меры, как
log-likelihood и t-score, придают этим сочетаниям
низкие значения, и они не попадают в список
частотных коллокаций.
Таким образом, ни одна из самых
распространённых мер ассоциаций не решает задачу
выявления коллокаций безошибочно. Поэтому
необходимо либо использовать эти меры в
комбинации друг с другом, либо создать новый
алгоритм выявления коллокаций, который занижал
бы значения мер ассоциации для неосмысленных
сочетаний, или вовсе исключал бы их на
промежуточной стадии выделения.
3.Программа выявления коллокаций
3.1.Используемое программное обеспечение
Разработанная нами программа написана на
языке программирования Python, что позволяет ей
работать практически на всех платформах. Для
корректной работы программы необходим Python
версии 2.7 и установленная библиотека для
морфологического анализа pymorphy со словарями
для русского языка, а также установленная
библиотека PyQt4 для поддержки программ с
графическим интерфейсом.
3.2.Требования к входным данным
На вход программе подаётся текстовый файл на
русском языке с расширением .txt, сохранённый в
кодировке UTF-8. Для того, чтобы привести текст в
необходимый формат, можно выполнить, например,
такую последовательность действий:
− открыть текстовый файл в Microsoft
Word;
− сохранить его как обычный текст;
− при сохранении указать кодировку
Юникод (UTF-8).
3.3.Оценка эффективности программы
выявления коллокаций
Для оценки эффективности программы
выявления коллокаций мы использовали
специальный текст ― реферат по философии, так
как для специальных текстов характерно наличие
большого числа устойчивых и терминологических
словосочетаний. Объём текста ― 1098 слов (6785
знаков). Мы специально выбрали текст небольшого
объёма, чтобы количество коллокаций было не
очень большим (не более 50) и можно было
подробно проанализировать результаты выполнения
программы. Полный список коллокаций, найденных
программой в специальном тексте, для двух типов
поиска приведён в Приложении 2.
Как мы можем увидеть, программа находит в
специальном тексте разные типы сочетаний:
− терминологические сочетания (теория
познания, простые идеи, внутренний опыт);
− общеязыковые сочетания (представлять
собой, органы чувств, основные черты);
− имена собственные (Джон Локк);
− вводные конструкции (то есть);
− сочетания, характеризующие тему текста
(черты эмпиризма, получение знаний, наш
ум);
− свободные сочетания (ум получает,
существует три);
− сочетания с нераспознанными служебными
словами (при помощи);
− сочетания с нераспознанными
окказиональными элементами (познание
Дж).
Наибольшее количество найденных в тексте
сочетаний относится к первой группе ― это
различные термины философии и других наук.
Также программа распознаёт много общеязыковых
сочетаний, сочетаний, характеризующих тему
текста, и свободных сочетаний.
Два последних типа сочетаний встречаются
крайне редко. Проблемы с нераспознанными
служебными словами и окказиональными
элементами обусловлены не недоработками в
алгоритме программы, а некорректностью работы
библиотеки для морфологического анализа
pymorphy в ряде случаев. Эти недостатки мы
рассмотрим подробнее в следующем подразделе.
3.4.Случаи некорректной работы библиотеки
pymorphy
Как можно увидеть из таблиц в Приложении 2,
некорректная работа библиотеки pymorphy в ряде
случаев приводит к следующим недостаткам:
− неправильное определение части речи слова
может привести к включению сочетаний со
служебными словами в выдачу (в сочетании
«при помощи» часть речи предлога ‘при’
определена как имя существительное,
поэтому это сочетание было включено
программой в итоговую таблицу);
− неправильное определение леммы (при
правильном определении части речи) может
мешать правильному подсчёту частот
встречаемости (в сочетании «получения
знаний» лемма второго слова была
определена как «ЗНАНЬЕ»);
− приписывание леммы и части речи
окказиональным элементам (в сочетании
«познание Дж» элементу «Дж» была
приписана лемма «ДЖ» и часть речи ― имя
существительное);
− нераспознавание леммы (в сочетании
«врождённых идей» лемма первого слова не
была распознана, и оно было оставлено в
исходном виде);
Так как случаи выдачи некорректных
результатов крайне редки и обусловлены
недостатками в работе библиотеки для
морфологического анализа, а не алгоритма
программы, то, в целом, можно считать, что
поставленная нами задача решена и программа
решает заявленные нами проблемы.
3.5.Решение проблем выявления коллокаций в
разработанной программе
Разработанная нами программа решает
несколько проблем выявления коллокаций,
исследованных нами в прошлом году.
Во-первых, решена проблема поиска сочетаний
слова и знака препинания в качестве коллокаций.
Знаки препинания в нашей программе не
рассматриваются как словоупотребления в тексте и
исключаются из рассмотрения на одной из ранних
стадий обработки текста.
Во-вторых, решена проблема поиска сочетаний
знаменательного и служебного слова в качестве
коллокаций. При помощи библиотеки pymorphy
программа определяет часть речи для каждого
словоупотребления в тексте и на стадии
формирования списка потенциальных коллокаций
исключает такие сочетания из рассмотрения.
В-третьих, решена проблема поиска
низкочастотных сочетаний в качестве коллокаций.
Наша программа исключает из рассмотрения все
сочетания с частотой совместной встречаемости,
меньшей или равной единице. Так как наша
программа разработана для работы с небольшими по
объёму текстами, этого вполне достаточно для
достижения необходимых результатов.
В-четвёртых, словоупотребления, разделённые
знаком препинания, в нашей программе не
считаются коллокациями. Возможно, это
некорректно в ряде случаев, но всё же, в основном,
это очень эффективная мера отсеивания
нерелевантных сочетаний.
Таким образом, наша программа решает
некоторые важные проблемы выделения
коллокаций, которые затрудняют корректную
работу многих современных корпусных
менеджеров.
3.6.Сравнение эффективности используемых в
программе мер ассоциации
Чтобы оценить эффективность используемых
мер, мы отобрали для каждой меры и типа поиска 10
выданных коллокатов с наибольшими значениями
мер. Список коллокаций, использованный для
оценки эффективности мер в нашей программе, мы
поместили в Приложении 1.
Из таблиц Приложения 1 можно увидеть, что
практически все меры ассоциации в нашей
программе работают достаточно эффективно. Ни в
одной из таблиц не оказалось сочетаний с
окказиональными элементами. Сочетание «при
помощи», выделенное многими мерами, оказалось в
таблицах только из-за упомянутой нами выше ошибки библиотеки pymorphy в приписывании
частей речи.
Если считать выделенные мерами ассоциации
свободные сочетания слов отрицательным
показателем эффективности, то с этой точки зрения
наименее эффективными оказались меры MI (по 2
свободных сочетания из 10 словоформ и лемм) и
minimum sensitivity (2 свободных сочетания для
словоформ и 1 для лемм). Чуть более эффективны
меры Dice и Log-Dice (по одному свободному
сочетанию для словоформ и лемм), причём
нормализованная мера показала такую же
эффективность, как и ненормализованная версия.
Остальные меры не выделили ни одного свободного
сочетания, все выявленные ими коллокации
относятся к пяти первым категориям из пункта 2.5.,
то есть, они действительно выделяют
словосочетания, воспринимаемые нами как
несвободные или неслучайные. Следует отметить,
что нормализованные версии меры MI ― MI3 и
salience ― оказались эффективнее, чем
ненормализованная мера.
Ещё одно интересное наблюдение состоит в том,
что набор терминологических сочетаний,
выделенных различными мерами, несколько
отличается, в то время как те немногие сочетания,
которые были выделены всеми мерами без
исключения, характерны для общей системы языка.
Поэтому наше решение использовать в программе 9
мер ассоциации было полностью оправданным.
Таким образом, при правильной комбинации
алгоритма выявления коллокаций и эффективных
мер ассоциации можно достичь достаточно точных
результатов при выявлении коллокаций.
Заключение и направления
совершенствования программы
В данной работе мы привели подробное
описание использующихся на практике мер
ассоциации ― статистических методов выявления
сочетаемости слов в тексте, рассмотрели основные
проблемы, возникающие при выявлении
коллокаций, и попытались решить их при создании
собственной программы поиска коллокаций в
текстах на русском языке. Проблема выделения
сочетаний со знаками препинания в нашей
программе решена полностью, проблемы выделения
сочетаний знаменательного слова со служебным и
случайных сочетаний решены в той мере, в какой
позволяет корректная работа библиотеки
морфологического анализа. Разработанная нами
программа выделяет двусловные коллокации
нескольких типов: терминологические и
общеязыковые сочетания, имена собственные,
вводные конструкции, сочетания, характеризующие
тему текста, а также некоторые свободные
сочетания. Используемые в программе меры
ассоциации в целом показали высокую
эффективность при поиске коллокаций и не
переоценивали свободные сочетания. Результаты
разных мер совпадали при выделении
общеупотребительных слов и расходились при
выделении терминов. Это свидетельствует о том,
что для эффективного выявления в тексте
коллокаций разных типов необходимо использовать
комбинацию нескольких мер. Однако главным
является то, что решение проблем выявления
коллокаций позволяет существенно повысить
эффективность поиска осмысленных сочетаний и
мер ассоциации.