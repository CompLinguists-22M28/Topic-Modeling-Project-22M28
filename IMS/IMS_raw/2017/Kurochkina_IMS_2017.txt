Оценка автоматических методов выявления
устойчивых словосочетаний
Ю.Н.Курочкина
Санкт-Петербургский государственный университет,
Kurochkina.Julie@yandex.ru


1. Введение
В языке как системе элементы определяются синтаксическими
связями и парадигматическими. "СИНТАГМАТИКА -1) один из двух
аспектов исследований языка - изучение языковых единиц в
линейном ряду, в тех реальных отношениях, которыми они связаны в
тексте; противополагается парадигматике"[3,
с.273]."ПАРАДИГМАТИКА - 1) один из двух аспектов системного
изучения языка, определяемый выделением и противопоставлением

двух типов отношений между элементами и/или единицами языка —
парадигматических и синтагматических; раздел науки о языке,
занимающийся парадигматическими отношениями, их классификацией, определением области их действия и т. п.; противопоставляется
синтагматике по типу изучаемых отношений и их группировок; 2) в
более широком смысле — то же, что система языковая, понимаемая
как совокупность лингвистических классов — парадигм; противопоставляется синтагматике как синониму понятия лингвистического
процесса и текста (Л. Ельмслев)" [3, с.205]. Есть мнение, что в голове
у человека находятся уже готовые синтагмы. Линейный текст также
не обходится без парадигматических связей, однако принято считать,
что в тексте присутствуют только синтагмы.
Сочетаемость - это "свойство языковых единиц сочетаться при
образовании единиц более высокого уровня; одно из фундаментальных свойств языковых единиц, отражающее синтагматические
отношения между ними" [3, с.284]. В языке наблюдаются
универсальные и конкретно-языковые законы и тенденции сочетаемости, отступив от которых, говорящий или пишущий нарушает
норму или способствует изменению свойств языковых единиц.
Однако, намеренное нарушение правил сочетаемости может быть
средством художественной выразительности
Наш научный интерес сосредоточен на устойчивых сочетаниях, в
состав которых входят также разные виды словосочетаний–
фразеологические
единства,
фразеологические
сочетания,
фразеологические выражения. Но не только – сюда же входят и
устойчивые нефразеологизированные сочетания, терминологические,
имена собственные.
Говоря о коллокациях, мы используем следующее определение
«Коллокации— это слабоидиоматичные фразеологизмы
преимущественно со структурой словосочетания, в которых
семантически главный компонент (база) употреблен в своем прямом
значении, а сочетаемость со вспомогательным компонентом
(коллокатором) может быть задана в терминах семантического
класса, но выбор конкретного слова предопределен узусом» [Баранов
и Добровольский, 2014:73]. Примеры: проливной [коллокатор] дождь
[база], принимать [коллокатор] решение [база], зерно [коллокатор]
истины [база], ставить под [коллокатор] сомнение [база], топорная
[коллокатор] работа [база], трескучий [коллокатор] мороз [база]. [1,
с.73]
Существуют различные методы автоматического выявления
устойчивых словосочетаний на базе больших корпусов текстов – в
целом процедура заключается в отборе кандидатов в коллокации на
основе выбранных критериев (мер ассоциаций, одной или
нескольких).
Помимо выявления устойчивых словосочетаний, нужно оценить
как коллокации, так и работу выбранных нами мер. Суть
исследования заключается в том, чтобы проанализировать
возможные и доступные автоматические методы, связанные с
нашими мерами ассоциации, сравнить их, выявить положительные и
отрицательные стороны и предложить вариант их улучшения или
применения в зависимости от полученного результата.

2. Теоретическая база
Как правило, извлечение коллокаций - самое популярное
применение лексической ассоциативности. И на эту тему было
опубликовано довольно много значительных исследований. В
компьютерной лексикографии автоматическая идентификация
коллокаций
используется
для
помощи
лексикографам
в
распознавании
возможных
смыслов
слова,
лексических
предпочтений, примеров использования и т. д., Для традиционных
словарей или специальных, извлечение коллокаций используется,
например, в переводах, двуязычных словарях или для обучения
языкам. Коллокации играют важную роль в системах генерации
естественного языка, где словари коллокаций и частые фразы
используются в процессе выбора слов, чтобы улучшить беглость
автоматически
генерируемого
текста.
В
области
снятия
семантической неоднозначности слова были описаны два
применимых принципа: во-первых, слово с определенным значением
имеет тенденцию к совпадению с другими словами, чем тогда, когда
оно используется в другом смысле. Во-вторых, согласно гипотезе
Яровского «Один смысл на коллокацию», все вхождения слова в
одной коллокации имеют одно и то же значение.
Важное применение коллокации - в области машинного перевода.
Часто словосочетания не могут быть пословно переведены. В
переводе они должны рассматриваться скорее как лексические
единицы, отличные от синтаксически и семантически регулярных
выражений. В этом случае меры ассоциации используются для
идентификации переводных эквивалентов из параллельных корпусов,
выровненных по предложениям, а также из непараллельных
корпусов. В статистическом машинном переводе меры ассоциации
используются по отношению к параллельным корусам для
выполнения двуязычного выравнивания слов для идентификации пар
переводов слов и фраз (или более сложных структур), хранящихся в
виде таблиц перевода, и используемых для выполнения возможного
перевода.
Применение коллокаций в поиске информации изучалось как
естественное расширение индексации однословных терминов на
многословные единицы (фразы). Ранние исследования были
сосредоточены на небольших подборках и приводили к
непоследовательному
и
незначительному
улучшению
производительности. Позже аналогичные методы были применены к
более крупным и разнообразным коллекциям в рамках конференции
по поиску текста (TREC), но с небольшим успехом. Другие
исследования были мотивированы только поиском информации без
прикладного использования. Недавно некоторые исследователи
попытались включить ассоциативную информацию в вероятностные
модели, но не было продемонстрировано последовательного
улучшения показателей. Несмотря на эти результаты, использование
коллокаций в поиске информации по-прежнему вызывает
относительно большой интерес). Коллокационные фразы также
использовались и при межъязыковом поиске информации.

Значительная часть работы была проделана в области распознавания
терминов.
Лексические меры ассоциации были применены к различным
другим задачам, из которых мы выбираем следующие примеры:
распознавание
именованных
сущностей,
определение
синтаксических границ составных частей, синтаксический парсинг,
снятие синтаксической неоднозначности, адаптированное языковое
моделирование, извлечение японско-английских пар морфем из
двуязычных терминологических корпусов, обнаружение границы
предложений, выявление аббревиатур, вычисление норм ассоциаций
слов, сегментация тем и обнаружение ссылок, обнаружение
морфологически связанных слов на основе семантического сходства
и, возможно, другие [6, рр. 1-6].

3. Извлечение коллокаций
Тема извлечения коллокаций до сих пор актуальна, внутри нее
существуют некоторые проблемы и задачи. В первую очередь
подробнее остановимся на методах извлечения, способах и оценке.
3.1.Методы выявления устойчивых словосочетаний
Методика извлечения устойчивых словосочетаний на 99% связана
с корпусной лингвистикой, которая напрямую работает с корпусами.
Лингвистический
корпус
текстов
это
"большой,
представленный
в
электронном
виде,
унифицированный,
структурированный, размеченный, филологически компетентный
массив языковых данных, предназначенный для решения конкретных
лингвистических задач". Понятие «корпус текстов» включает также
систему управления текстовыми и лингвистическими данными,
которая называется корпусным менеджером (или корпусменеджером)
(англ.
corpus
manager).
Она
является
специализированной поисковой системой, содержащей программные
средства для поиска данных в корпусе, получения статистической
информации и предоставления результатов пользователю в удобной
форме.
Наличие текстов не решает различные лингвистические задачи нужно, чтобы в массиве содержалась лингвистическая информация
для полноты картины. Для того, чтобы извлечь нужную информацию,
например, коллокации, в корпус нужно добавить лингвистическую
информацию. Также такое действие называется Лингвистической
предобработкой текста. Под лингвистической предварительной
обработкой мы имеем в виду морфологическую разметку и
синтаксическую разметку на этапе создания корпуса и снятия
неоднозначности. анализ и устранение неоднозначности на уровне
морфологии и синтаксиса. Разметка (tagging, annotation) заключается
в приписывании текстам специальных меток , или тэгов(tags):
экстралингвистических (сведения об авторе и сведения о тексте:
автор, название, год и место издания, жанр, тематика метаразметка),
структурных
(глава,
абзац,
предложение,
словоформа)
и
собственно
лингвистических
маркеров.

Лингвистические тэги содержат в себе информацию о лексических и
грамматических свойствах компонентов текста [2, с. 5-6].
Автоматическое извлечение коллокаций обычно выполняется как
процесс, состоящий из нескольких шагов :
Во-первых, корпус в виде набора машиночитаемых текстов на
одном языке лингвистически предварительно обрабатывается (как
уже было сказано выше) - анализируется морфологически и
синтаксически и снимается неоднозначность.
Во-вторых, все кандидаты, которые могут быть коллокацией (т.е.
потенциальные фразеологизмы),выявляются и их статистика
встречаемости извлекается из корпуса. В-третьих, кандидаты
фильтруются для повышения точности (на основе грамматических
моделей и / или частоты возникновения). В-четвертых, выбирается
лексическая мера и применяется к статистическим данным
встречаемости, полученные из корпуса. И, наконец, кандидаты в
коллокации
классифицируются в соответствии с оценкой их
сочетаемости и вычисляется определенный порог - кандидаты выше
этого порога классифицируются как словосочетания, кандидаты
ниже этого порога - не являются словосочетаниями.
Задача извлечения коллокаций далее сводится к ранжированию
кандидатов в коллокации - Цель состоит не в извлечении
ограниченного набора словосочетаний из данного корпуса, а в
ранжировании всех потенциальных словосочетаний в зависимости от
степени сочетаемости, так что те кандидаты, в которых наблюдается
наиболее крепкая ассоциативная связь, сконцентрированы в верхней
части списка. [6, р.26].
3.2. Инструменты
Для извлечения коллокаций есть готовые инструменты, в
частности, SketchEngine (SkE). Существует и бесплатная версия NoSketchEngine, в которой находятся те же корпуса. Этот инструмент
использует систему Manatee. Представленная система управления
корпусом Manatee способна работать с чрезвычайно крупными
корпусами и способна предоставить платформу для вычисления
широкого диапазона лексической статистики..
Система спроектирована по модульному принципу. Она содержит
библиотеку индексирования для сжатия, создания и извлечения
индексов; Модуль оценки запросов с классами для различных
операций запроса, анализатор запросов, который преобразует
запросы в абстрактные синтаксические деревья, набор инструментов
командной строки для построения и обслуживания корпусов, два
графических пользовательских интерфейса. Система SkE также
использует интерфейс Bonito. Bonito - графический пользовательский
интерфейс корпус-менеджера Manatee. Он позволяет формировать
запросы и выдавать их. Результаты четко отображаются и могут быть
изменены различными способами. Статистика также может быть
вычислена. В NoSketch Engine1 используется вся система Manatee и
интерфейс Bonito, и в качестве дополнений предоставляются


вордскетчи, грамматические отношения и дистрибуционный
тезаурус. Вордскетчи (word sketches) это автоматическое
одностраничное резюме грамматического и коллокационного
поведения слова, созданное на основе корпуса. Каждый вордскетч
содержит прямые ссылки на конкордансы, иллюстрирующие
указанную коллокацию [9, р.65-70].
3.3. Корпуса
Корпус Aranea был создан Владимиром Бенко для замены
устаревших и неудобных в использовании корпусов. Его название
происходит от латинского "лингвистически нейтральный", и части
корпуса, относящиеся к разным языкам, названы соответственно
Araneum Anglicum, Araneum Germanicum, Araneum Russicum и т.д.
Каждый корпус существует в четырех вариантах размеров, из
которых основных два: Maius (от лат. "больше") и Minus (от лат.
"меньше"), составляющий 10% от всех данных. Также есть версии
Minimum , который составляет 1%, и Maximum, содержащий столько
данных, сколько можно загрузить из Интернета для конкретного
языка, а его размер в основном определяется конфигурацией сервера.
Старые корпуса слишком большие и их нельзя скачать к себе на
компьютер. Сбор всех исходных данных нового корпуса Aranea
осуществляется
с
помощью
SpiderLing,
веб-сканера,
оптимизированного для сбора текстовых данных из Интернета.
Система содержит встроенный модуль кодирования символов
(chared.py) и распознавания языка (trigrams.py), а также инструмент
для удаления шаблона (jusText). Данные в корпусе защищены от
повторов, так как система их распознает. Для автоматического
аннотирования текста используется теггер под названием TreeTagger.
Подробнее см. [6]. Чтобы упростить создание совместимых
грамматик, все собственные тэг-таблицы внесены в универсальный
набор тегов Araneum. Для всех корпусов были написаны
совместимые скетч-грамматики. Их основная идея состоит в том,
чтобы иметь одинаковое количество граммем (и отображать таблицы
вордскетчей) для всех классов слов во всех языках. [5, р.257-264].
3.4.Оценка эффективности ассоциативных мер
К автоматическим способам оценки относятся вычисление
полноты, точности, F-меры и средней точности. Процедура
извлечения коллокаций включает в себя
получение списка
кандидатов в устойчивые словосочетания, и оценка заключается в
том, чтобы выделить среди всех кандидатов настоящие коллокации.
В сущности процесс извлечения и оценки зависит от многих
факторов.
Способы оценки можно делить по нескольким основаниям [8,
р.70-72]:
1. по природе используемых мер
a. количественные. Такой вид оценки предполагает использование
полноты, точности, F-меры, а также среднее арифметическое
точности.
b. качественные. При качественной оценке производится обзор
полученного списка с учетом таких критериев, как частеречные

цепочки, частотное распределение и контекст. Такая оценка
возможна как вручную, так и при помощи статистического анализа.
Обычно она имеет рекурсивный характер – получение списка
кандидатов, его оценка, учет ошибок, прогон заново, и т.д. до
получения приемлемого результата.
2. по типу доступных ресурсов для оценки
a. оценка вручную. При такой оценке носители языка или
эксперты в той предметной области, для которой выделялись
устойчивые словосочетания, вручную оценивают получившийся
список кандидатов в устойчивые словосочетания и отбирают среди
них действительные и ложные устойчивые словосочетания. К
сожалению, такой вид оценки очень затратный по временным и
человеческим ресурсам. Однако, он был использован в нашей работе
С результатами оценки можно ознакомиться в разделе 4.
b. автоматическая оценка. Такой вид оценки проводится при
наличии золотого стандарта, который является некоторым эталоном,
списком, который содержит только «правильные» устойчивые
словосочетания. Для подобной оценки необходимым условием
должно быть полное или значительное покрытие устойчивых
словосочетаний золотым стандартом.
3.5. Составление золотого стандарта
Для оценки нужен золотой стандарт или список действительных
устойчивых словосочетаний и метод, который составляет
ранжированный список возможных устойчивых словосочетаний.
Сложность составления золотого стандарта заключается в том,
что часто бывает неясно, как проводить работу, на что опираться. Но
важность и удобство золотого стандарта давно широко признаны.
Для хорошего золотого стандарта в идеале требуется хотя бы
частичная проверка вручную.
Для создания нашего мини-золотого стандарта были
использованы следующие словари:
− Словарь сочетаемости русского языка под редакцией
Денисова и Морковкина;
− МАС (малый академический словарь);
− СИБАС (Сибирский ассоциативный словарь русского языка);
− БТС (Большой Толковый Словарь);
− Русский ассоциативный словарь;
− Ассоциативная база данных УрРАС;
− Словарь-тезаурус ЕВРАС;
− Толковый словарь Ушакова;
− Толковый словарь Ожегова;
− Современный толковый словарь русского языка Ефремовой;
− Лингво-страноведческий словарь "Русские фразеологизмы"
Фелициной и Мокиенко;
− Фразеологический словарь русского языка под редакцией
Молоткова.
Мы опросили трех экспертов с филологическим образованием, а
также двоих экспертов с образованием в другой сфере. Кандидаты в
коллокации были рассортированы по группам в зависимости от

количества случаев встречаемости в словарях и мер, которые
выявили эти коллокации. Экспертам было необходимо оценить
каждого кандидата по шкале от 0 до 2, где 0 - не коллокация, 1слабая коллокация/затрудняюсь ответить, 2 - абсолютно точно
коллокация. Также экспертам был представлен текст, поясняющий,
что есть коллокация. Он звучит так: "Коллокации - это
словосочетания, в которых главный по смыслу компонент (база)
употреблен в своем прямом значении, а вспомогательный компонент
(коллокатор) сочетается в рамках смыслового класса, но выбор
конкретного слова предопределен общепринятым употреблением.
Например: проливной [коллокатор] дождь [база], принимать
[коллокатор] решение [база], зерно [коллокатор] истины [база],
ставить под [коллокатор] сомнение [база], топорная [коллокатор]
работа [база], трескучий [коллокатор] мороз [база]" [1, с.73].

4. Эксперимент
Цель эксперимента – оценить эффективность статистических мер
путем сравнения результатов автоматического выделения коллокаций
с «золотым стандартом». Исследование проводилось с помощью
инструмента NoSketchEngine на корпусе Araneum Russicum Russicum
Maius 1,20 G2 с использованием различных словарей русского языка.
Наш выбор пал именно на данный корпус, так как, например, в
корпусе НКРЯ3 невозможно выделение коллокаций. Это значит, что в
корпус-менеджере выше упомянутого корпуса нет функции
извлечения коллокаций.
Какова была процедура выполнения– мы выбрали слова, выбрали
слова для золотого стандарта, проанализировали словарные статьи,
выбрали оттуда коллокации и сделали их золотым стандартом. Затем
воспользовались
инструментом
NoSketсhEngine,
ввели
анализируемые слова и сравнили выдачу различных мер с золотым
стандартом.

5. Результаты
С помощью этих словарей был создан "золотой стандарт" adhoc
под 7 слов, которые мы анализировали (сердце, вода, рука, белый,
скакать, семь, свой). Например, словосочетание газированная вода
встретилось в 8 из 12 словарей, правая рука - 10 из 12, доброе сердце
- 9 из 12 (см. таблицу 1).

В нашем материале есть также очень редкие коллокации,
встретившиеся лишь в одном или двух словарях. Для слова рука мы
получили 246 кандидатов в коллокаторы, для слова вода - 328, для
слова сердце – 245, для слова белый – 90, для слова скакать – 62, для
слова семь – 24, для слова свой – 75. Мы полагаем, что имеем
основания опираться на данную подборку в качестве золотого
стандарта, т.к. наша гипотеза состоит в том, что обычно в словарях
дана полная информация о словах и о возможных коллокациях.
Далее, мы воспользовались инструментом NoSketchEngine для
оценки работы мер logdice, MI3, T-score, loglikelihood. Были
исследованы кандидаты в коллокаты для слов рука, вода и сердце с
диапазонами от 0 до 1,от 0 до 2,от 0 до 3,от -1 до 0, от -2 до 0, от -3 до
0 и для слов белый от 0 до +3, скакать от -1 до 1, семь от -3 до 3, свой
от -1 до 1.При выборе диапазона мы руководствовались
характеристиками базы коллокации, то есть частью речи. Так,
существительное требует диапазона от -3 до 3, для прилагательного
предпочтительней поставить диапазон от 0 до 3, ибо потенциальные
коллокаторы в тексте будут расположены справа от базы.
Предполагается, что числительное ведет себя подобно имени
существительному, поэтому мы выбираем соответствующий
диапазон.
Мы исследовали полные списки коллокатов для каждого слова.
Таким образом, коллокаты в каждой мере совпадают, отличаясь при
этом рангами. То есть, может оказаться так, что в выдаче какой-либо
меры хорошие коллокаты "спустились" в самый низ, но остальные
меры выдали их в начале своих списков. Как правило, большая часть
«хороших» коллокатов оказывается в верхней части списка. Поэтому
для некоторых задач достаточно оценивать только эту верхнюю
часть. Мы определяли пороговое значение каждой меры
эмпирическим путем, хотя есть исследования, предлагающие такие
пороговые значения (напр., Ф. Чермак для меры MI предлагает порог,
равным 8 [6, с.40] ). Мы проранжировали слова и значения мер.
Каждое слово имеет разный ранг в списках, выданных разнымaи


мерами. Например, коллокация махнуть рукой - в T-score она на 101
месте, в MI3на 19, loglikelihood на 39 и так далее (см. таблицу.4). На
основе полученных рангов мы подсчитали коэффициент корреляции
Спирмена (см. таблицу. 5).


Чтобы оценить эффективность каждой меры, мы использовали
метод Харина-Ашманова [4, с. 33-37], который оценивает
релевантность полученной информации. На основе экспертной
оценки выделенных коллокатов и их места в ранжированном списке в
отношении каждой меры был сформирован набор характеристик.
Набор характеристик показывает отношение количества истинных
коллокаций к количеству коллокатов из ранжированного списка
(точность). Согласно [4, с. 33-37], мы выбираем элементы этого
набора, которые содержат 5 элементов - значения точности для
первых 20, 50, 100, 150 и 200 коллокаций в верхней части списка. В
таблице 6 показано распределение количества истинных коллокаций
в разных мерах:


Вес присваивается каждому элементу набора признаков (1, 2, 3, 4
и 5 соответственно). Каждый элемент «взвешивается»: каждое из
пяти значений точности умножается на его вес и делится на 15
(сумма весов). Сумма взвешенных элементов - это результирующая
точность характеристического множества. Приведем пример для
MI3.Количество истинных коллокаций в мере MI3 в первых 20
примерах- 3 (точность 0,15), в первых 50 - 7 (точность 0.14), в первых
100- 16 (точность 0.16), в первых 150 - 17 (точность 0,113), в первых
200 -21
(точность 0.105). Средняя точность получается
0.15*1/15+0.14*2/15+0.16*3/15+0.113*4/15+0.105*5/15=0,01+0,019+0,
032+0,03+0,035=0,126.
В таблице 7 можно ознакомиться с результатами для остальных
мер ассоциации.

Итак, лидирует мера MI. На втором месте MI.log_f, за ней следует
Min.sensitivity. Интересно заметить, что лучше всего оказались
меры семейства MI. Однако, родственная им мера MI3 оказалась на
7 месте, последнем.
В нашем исследовании мы вычисляем условную полноту. Мы не
можем вычислить истинную полноту, но можно утверждать, что на

достаточно большом корпусе должно встречаться большинство
коллокаций из золотого стандарта.
Условная полнота была вычислена следующим образом (на
примере слова рука): коллокация считается истинной, если она
встретилась более в чем 2 словарях и выдана более чем 1 мерой (см.
таблицу 8).


Дано: всего b коллокаций, a – количество «хороших» коллокатов,
c - количество коллокатов по словарям. Для нашего слова рука это
!
a=72, b= 246,c= 153. Полнота = .
!
Таким образом, мы вычислили точность, полноту и F-меру для
наших слов. Эти метрики представлены в таблице 9.


Также мы разделили все получившиеся словосочетания по
группам: группа 1 - кандидаты, не встретившиеся в словарях, и
выданы 1-2 мерами; группа 2 - кандидаты, не встретившиеся в

словарях, и выданы 3-4 мерами; группа 3 - кандидаты, встретившиеся
в 1-3 словарях, и выданы 1-2 мерами; группа 4 - кандидаты,
встретившиеся в 1-3 словарях, и выданы 3-4 мерами; группа 5 кандидаты, встретившиеся в 4-12 словарях, и выданы 1-2 мерами;
группа 6 - кандидаты, встретившиеся в 4-12 словарях, и выданы 34мерами; группа 7 - кандидаты, встретившиеся в 1-3 словарях, но не
выданы ни одной мерой; группа 8 - кандидаты, встретившиеся в 412словарях,но не выданы ни одной мерой .
Перейдем к анализу результатов оценки экспертов. Как мы видим
в таблице 10, в большинстве случаев ответы экспертов
распределились в соответствии с сортировкой кандидатов в
коллокации в зависимости от количества случаев встречаемости в
словарях и мер.


Также мы посчитали для каждой коллокации среднее
арифметическое ответов экспертов и стандартное отклонение.
Среднее арифметическое позволяет нам сразу увидеть, насколько
высоко оценили эксперты данную коллокацию. Однако и
распределение коллокаций по группам имеет смысл. Например,
сочетание «выпрямить руки» было в группе №1, то есть оно
встретилось 0 раз в словарях и 1-2 раза оно было выдано мерами
ассоциации. Эксперты посчитали его «не коллокацией» и поставили
0. Это подтверждает предположение, что данное словосочетание
коллокацией не является. Аналогично, выражение «газированная
вода», которое встретилось 8 раз в словарях и было выдано всеми
мерами, набрало максимальное количество баллов, все эксперты
единодушно поставили 2. На основе этого экспертного решения мы
можем сделать вывод, словосочетание является «качественной»
коллокацией. Однако, не всегда мнение экспертов совпадает со
словарями - в эксперименте встретились сочетания, входящие в
группы с редкой встречаемостью, (например, в первую (0|1-2) ,
вторую( 0|3-4), седьмую( 1-3|0) и восьмую ( 4-12|0) группы), которые
также получили максимальное количество оценок «2» - в самое
сердце, водой не разольешь, под горячую руку, прижать к сердцу,
наложить руки. Основываясь на эксперименте, можно сделать
вывод, что не стоит полагаться на наш золотой стандарт, так как
многие коллокации, не встретившиеся в словарях, признаны
экспертами «хорошими». Возьмем коллокации со словом сердце. В
первой группе приблизительно 20% коллокаций, получивших оценку
2, во второй 15%, в третьей 20%, в четвертой 25%, в пятой 38%,
шестой 45%, седьмой 15% и восьмой 40%. Первая и вторая группы
содержат словосочетания, мало встретившиеся в словарях, но при
этом в них достаточно много (20 и 15%) коллокаций, отмеченных
экспертами оценкой 2.

5. Заключение
Подводя итоги, мы видим, что меры лексической ассоциации
выполняют важную работу по извлечению коллокаций из корпуса.
Важно отметить, что эксперимент был проведен на большом
репрезентативном корпусе, поэтому результаты разнообразны и
достоверны. Выводы:
1) В отношении золотого стандарта можно сказать, что словари
неполны. Наш специальный золотой стандарт показал себя слабо:
многие словосочетания, выданные мерами, отсутствуют в словарях.
2) Из первого утверждения вытекает еще один вывод, что в
словарях содержатся только действительно фразеологизмы, а
эксперты оценивают просто устойчивые словосочетания. Также меры
ассоциации выдают все возможные словосочетания, то есть
словосочетания разных типов, и работа экспертов заключается в том,
чтобы выделить среди них хотя бы устойчивые.
3) Также мы сравнили меры лексической ассоциации. Опираясь
на подсчеты средней точности, мы можем сказать, что лучше всего

справляется со своей работой мера MI, На втором месте MI.log_f, за
ней следует Min.sensitivity
4) Для нашего исследования достаточно было оценивать только
верхнюю часть списка, выданного мерой.
