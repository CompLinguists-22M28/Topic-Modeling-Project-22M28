Определение семантической близости текстов
с использованием инструмента DKPro Similarity
А. В. Крюкова
Санкт-Петербургский
государственный
университет,

1. Введение
Оценка семантической близости текстов является неотъемлемой
составляющей многих задач современной компьютерной лингвистики, среди
которых создание и функционирование информационно-поисковых систем,
вопросно-ответных
систем,
систем
автоматического
реферирования,
классификации текстов, определения тематики текстов, перефразирования,
разрешения лексической неоднозначности и др. До сих пор разработка и
тестирование алгоритмов и метрик для оценки семантической близости текстов
проводились в основном применительно к материалу английского языка. Это
можно проиллюстрировать классом компьютерных инструментов, созданных

для решения данной задачи: ср. WordNet::Similarity1, Alchemy API2 и ряд
других. Об успехах в этой области также свидетельствуют результаты
соревнований SemEval3 на специальной дорожке Semantic Textual Similarity.
Необходимость подобных исследований для русского языка обусловлена
востребованностью ожидаемых результатов в компьютерной лингвистике. В
частности, метрики семантической близости текстов и определение
семантических отношений между словами могут использоваться при создании
инструментов автоматического понимания текстов.
В настоящий момент есть прогресс в области автоматической оценки
семантической близости на уровне слов (ср. данные RUSSE4 [1]), однако задача
определения близости текстов не подвергалась тщательному изучению: акцент
делается не на количественных данных о схожести текстов, а на результатах
кластеризации или классификации большого числа документов в корпусе
(например, когда нужно определить тематику корпуса или назначить рубрики
для отдельных его сегментов). Наше исследование призвано восполнить
существующий пробел.
Итак, в данной работе мы решаем задачу оценки семантической близости
текстов на русском языке средствами открытой и свободно распространяемой
компьютерной платформы DKPro Similarity, что предполагает изучение
возможностей данной платформы, адаптацию инструмента для работы с
русским языком, эксперименты на текстовом материале с использованием
различных метрик семантической близости.

2. Компьютерный инструмент DKPro Similarity
Компьютерный инструмент DKPro Similarity5 разработан в Дармштадском
Технологическом Университете (TU Darmstadt)6 исследовательской группой [2].
Эта платформа была создана как дополнение DKPro Core, набора компонентов
ПО для обработки естественного языка; инструмент поддерживается на языках
Java, Jython и Groovy. Преимуществами данной платформы являются ее
открытый характер, реализация множества существующих метрик близости
текстов с использованием стандартизованного способа их вызова, а также
возможность разрабатывать собственные метрики на основе уже
существующих. DKPro Similarity включает в себя различные классы метрик
близости текстов: структурные, стилистические, строковые, семантические и
фонетические7. В нашем исследовании мы опираемся на строковые метрики, не
зависящие от языка обрабатываемого текста.
Полный список реализованных в DKPro метрик близости текстов можно найти
в хранилище на GitHub: https://github.com/dkpro/dkpro-similarity. Однако следует
учитывать, что многие из них не применимы к русскому языку
2

3. Лингвистические данные
Мы сформировали экспериментальную выборку текстов таким образом, что
в него вошли тексты, результаты вычисления близости которых можно было
адекватно оценить (подробнее об этом см. раздел 4.2), так как для русского
языка нет «золотого стандарта» для оценки семантической близости текстов,
т.е. корпуса, в котором пары текстов были бы снабжены экспертными оценками
их сходства8. Таким образом, материалом исследования послужили следующие
группы текстов:
− аннотации научных статей из корпуса по корпусной лингвистике
кафедры математической лингвистики СПбГУ;
− сообщения из сегментов «life» и «news» новостного корпуса кафедры
математической лингвистики СПбГУ;
− три перевода на русский язык романа В. Набокова «Пнин» (а именно,
переводы Г. А. Барабтарло, С. Б. Ильина, Б. М. Носика);
− заголовки новостных статей из корпуса парафразов в проекте
ParaPhraser.ru9.
Из каждой группы случайным образом было выбрано несколько текстов для
дальнейшей работы: пять аннотаций; по пять сообщений из двух частей
новостного корпуса; пять соответствующих друг другу отрывков из трех
переводов; а также по пять пар парафразов из каждой группы в корпусе
(преимуществом является то, что в этом корпусе каждой паре предложений
соответствует экспертная оценка того, в какой мере они действительно
являются парафразами: «-1» — предложения на разные темы, «0» —
предложения на одну тему, но есть изменения смысла, «1» — абсолютные
парафразы). В табл. 1 можно найти информацию о длине используемых текстов.
Перед вычислением семантической близости текстов была проведена их
обработка: удаление знаков препинания и лемматизация с использованием
библиотеки PyMorphy210 [3].



4. Ход экспериментов
4.1. Используемые метрики семантической близости текстов
В DKPro Similarity реализовано более 15 различных строковых метрик
близости, из которых в нашем исследовании мы использовали семь наиболее
обсуждаемых, ср. [4, 5, 6, 7]:
− Word N-Gram Containment Measure — документы разбиваются на
n-граммы, и «мера включения» выражается следующей формулой:
Cn(A,B)=
, где S(A,n) и S(B,n) — это множество
n-грамм в документах A и B соответственно [8];
− Word N-Gram Jaccard Measure — документы разбиваются на n-граммы,
и для них вычисляется коэффициент Жаккара: отношение количества
общих n-грамм к количеству n-грамм в целом [9];
В обеих метриках с n-граммами мы используем параметр n=2.
− Levenshtein Comparator — вычисляется минимальное количество
операций вставки или удаления одного символа или замены его на
другой, необходимых для преобразования одной строки в другую [10];
− Longest Common Subsequence Comparator — самая длинная общая
подпоследовательность вычисляется через нахождение наибольшего
количества операций вставки или удаления символов (для строк,
оставшихся после удаления общей подпоследовательности); затем

−

производится нормализация: 1 −
,
где |A| и |B| – количество символов в документах A и B соответственно
[11];
Greedy String Tiling — алгоритм ищет такое разбиение документов А и
В на непересекающиеся друг с другом одинаковые цепочки (tiles), при
котором ими окажется покрытым наибольшее число токенов в
документах [12]; на вход алгоритм принимает минимальную длину

цепочек для поиска (по умолчанию она равна трем); нормализуется
результат следующим образом: количество «покрытых» токенов
делится
на
количество
токенов
во
втором
документе:
GST(A,B)=
[13];
Longest Common Substring Comparator — самая длинная подстрока
вычисляется с помощью общего для двух строк дерева суффиксов;
полученное значение нормализуется так же, как и в метрике с общей
подпоследовательностью;
− Cosine Similarity — строятся векторные представления сравниваемых
текстов, рассчитывается косинус угла между векторами; по умолчанию
веса термов в документе равны частоте их встречаемости, а норма
векторов вычисляется стандартно, как корень из суммы квадратов их
координат [10].
Следует отметить, что значение всех из них принадлежит отрезку [0,1],
кроме расстояния Левенштейна, которое, наоборот, равно нулю, если два текста
идентичны, и тем больше, чем больше в них различий в символах, причем это
число ограничено сверху только длиной большего текста. Также важной
деталью является то, что значение двух из данных метрик — Word N-Gram
Containment Measure и Greedy String Tiling — зависит от порядка, в котором
документы сравниваются друг с другом: в знаменателе формулы стоит число,
связанное только с одним из текстов (количество n-грамм в первом документе и
длина второго документа соответственно). В связи с этим при использовании
этих метрик мы вычисляли оба значения.
Для текстов из каждой группы (см. раздел 3) было вычислено девять
значений близости, в результате чего мы получили несколько таблиц с
результатами: пять для каждой группы текстов и одну, в которой сравнивались
тексты из разных групп. В Таблице 2 можно увидеть, как выглядели значения
всех метрик близости для сравнений нескольких пар аннотаций.
−


Здесь и в последующих таблицах цифры в названиях столбцов или строк —
это условные обозначения (порядковые номера) сравниваемых текстов

4.2. Оценка результатов близости текстов
Как мы уже говорили, «золотого стандарта» для задачи определения
схожести текстов на русском языке не существует, поэтому мы выработали
собственные способы оценки полученных результатов. Напомним, что в
корпусе парафразов предложения уже были оценены вручную (см. раздел 3).
Мы решили следовать такому же методу, но он подходит только для текстов,
которые изначально близки друг к другу: из наших материалов этому параметру
соответствуют отрывки переводов романа «Пнин». Каждый из них мы разбили
на небольшие фрагменты (по одному-двум предложениям), соответствующие
друг другу в разных переводах. В результате каждый из пяти изначальных
отрывков был представлен несколькими текстовыми документами, в которых
находилось три маленьких отрывка. Был проведен эксперимент с участием
информантов — экспертов (студентов кафедры математической лингвистики).
Мы попросили их оценить попарное сходство фрагментов. Семантическая
близость целостных текстов определялась через средние оценки близости их
отрывков. Каждое значение оценивалось двумя участниками, и сравнение
проводилось отдельно по двум критериям:
1) Смысловой критерий: насколько тексты похожи по смыслу
(используется шкала «0−1−2», где «2» — сильная степень схожести,
«1» — средняя степень, «0» — небольшая степень схожести);
2) Формальный критерий: насколько близость текстов определяется
входящими в их состав словами (также используется шкала «0−1−2», но
при оценке предлагалось учитывать критерии, схожие с критериями
автоматического распознавания парафраз в проекте ParaPhraser.ru):
a) наличие одинаковых слов;
b) наличие синонимов / транспозиции / общих корней.
В результате для каждой пары сравниваемых текстов было получено два
значения от «0» до «2»: одно выражает близость текстов со смысловой точки
зрения, другое — с формальной, и именно они использовались в машинном
обучении (см. раздел 4.3.). Для оценки согласованности ответов участников
эксперимента мы использовали взвешенную Каппу Коэна (Weighted Cohen’s
Kappa), присваивая вес 0,1 неодинаковым ответам, отличающимся друг от друга
на единицу (то есть оценкам «0» и «1» или «1» и «2»), и вес 10 — тем случаям,
когда участники поставили оценки «0» и «2» одному отрывку. Показатель
согласованности оказался равен 0,68.
Однако для других текстов из экспериментальной выборки подобный
критерий не применим, так как они изначально не объединены общей темой.
Поэтому мы следовали следующей стратегии: исходя из того, что тексты из
одной группы похожи друг на друга больше, чем на тексты из других групп,
каждой паре документов мы поставили оценку «1», если они принадлежат
одной группе, и «0», если они относятся к разным. После этого шага количество
наборов данных увеличилось:
a) Результаты для текстов из корпуса новостей были разделены на три
набора: два, состоящих из значений близости текстов внутри подгрупп
«news» и «life» отдельно, и один, включающий сравнения текстов как
внутри этих подгрупп, так и между собой;

b) Из группы с текстами романа «Пнин» было так же составлено два
набора: один включает только сравнения переводов одинаковых
фрагментов, другой — сравнения любых текстов из романа;
Эти разделения обусловлены тем, рассматриваем ли мы все тексты из
корпуса новостей или романа «Пнин» как относящиеся к одной группе или к
разным.
c) Также мы создали еще один набор данных, в котором близость
парафраз оценивалась бинарно: «0», если в корпусе стояло значение
«-1», т.е. если предложения друг с другом никак не связаны, и «1», если
в корпусе были указаны оценки «0» или «1».
4.3. Обучение
На данном этапе у нас было одиннадцать наборов данных, объектами в
которых выступали пары текстов, а их признаками — значения мер близости. К
признакам мы также добавили длину обоих текстов, так как от них зависит
значение некоторых метрик (см. раздел 4.1.). Таким образом, каждый объект
характеризовался одиннадцатью признаками, а также эталонным значением: для
семи датасетов это было значение «1», для одного (не-бинарной оценки
парафраз) — «-1», «0» или «1», для двух (смысловой и формальной близости
отрывков из романа «Пнин») — вещественное значение от 0 до 2, и для одного
(текстов из разных групп) — значение «0». Каждый датасет со значением
целевого признака «1» был объединен с датасетом с «0», значения признаков
отмасштабированы.
В результате каждый набор данных состоял в среднем из 35 объектов. Так
как для оценки результатов мы используем трехкратную кросс-валидацию,
каждый раз объем обучающей выборки составлял примерно 66% (23 объекта), а
тестовой, соответственно, 33% (12 объектов). Машинное обучение
производилось на языке программирования «Python», с использованием
библиотеки scikit-learn12. В ней можно найти реализацию методов, о которых
речь пойдет дальше.
Для задач классификации эксперименты проводились с несколькими
линейными моделями: Logistic Regression, Ridge Classifier, SGD Classifier,
Passive Aggressive Classifier, Perceptron. Различие в методах их работы для
нашего исследование несущественно, достаточно знать основной принцип
работы линейных моделей в целом. Каждому признаку объектов они
присваивают определенный коэффициент — его вес, который умножается на
значение признака у каждого конкретного объекта, потом полученные значения
складываются, и в зависимости от результата объект относится к тому или
иному классу: к классу «1», если результат положительный, и к классу «0»,если
он отрицательный.
В результате для каждого набора данных выбиралась одна модель,
показавшая наилучший результат при трехкратной кросс-валидации с оценкой
результатов по F-мере (см. Таблицу 3). Поясним некоторые обозначения в
таблице. Если название метода не снабжено дополнительными комментариями,




использовалась его реализация с параметрами по умолчанию. «Grid Search» —
подбор наилучшей комбинации параметров из предложенных пользователем.
«L1 regression» - это использование L1-регуляризации (регуляризации Лассо)
вместо L2-регуляризации, которая применяется по умолчанию.


Для двух задач, где ответом должно было быть вещественное число
(датасеты с проставленной вручную оценкой близости фрагментов из романа
«Пнин»), также использовались линейные модели, но они не показали точных
результатов. Меньших значений средней абсолютной ошибки (mean absolute
error) удалось достичь, используя Random Forest Regressor: для оценок по
смыслу ошибка оказалась равна 0,208, а для формальных оценок — 0,188.
4.4. Выводы
Как мы видим, классификаторы, обученные даже на таких простых
признаках, как значения строковых метрик близости текстов, показывают
неплохие результаты. В связи с этим мы предлагаем использовать веса,
назначенные признакам линейными моделями, в качестве способа оценки
строковых метрик для конкретной задачи. Для этой цели была составлена
таблица со значениями весов лучших моделей (см. табл. 4: в ней выделены
наибольшие веса для каждого датасета).
Для каждой метрики мы вычислили среднее значение весов по модулю (при
этом мы не учитывали веса для датасетов «All News» и «All Pnin»13, так как изза использования регуляризации Лассо (L1) многие признаки имеют нулевой
вес, а другие, наоборот, значительно бóльшие веса по сравнению с остальными).
Вычисления показали, что наибольшие веса у N-Gram Containment Measure и
Cosine Similarity. Таким образом, именно они наиболее подходят для
поставленной задачи.


См. Таблицу 4.


Для данного набора данных (парафразы с оценками «1», «0», «-1») классов не
два, как в остальных датасетах, а три, и классификатор работает по принципу
«один против всех» (One VS All), отделяя каждый из них от двух остальных;
именно поэтому здесь три набора весов.

5. Заключение
Итак, мы показали, что даже строковые метрики оценки близости текстов,
которые, как обычно считается, дают хорошие результаты только для очень
схожих по наборам слов текстов, в данном случае позволяют линейным
моделям достаточно хорошо работать при классификации текстов. В
дальнейшем также планируется провести эксперименты с семантическими
метриками близости, опирающимися на внешние источники знаний (например,
на «Википедию»: см. ESA [14]), и сравнить результаты, которые будут
получены, с результатами данного исследования. Также планируется расширить
языковой материал и, возможно, использовать более сложные модели
машинного обучения для получения лучших результатов.
