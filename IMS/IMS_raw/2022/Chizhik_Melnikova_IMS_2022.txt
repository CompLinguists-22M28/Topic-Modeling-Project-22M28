Обработка текстовой медицинской информации: 
метод сбора и маркировки симптомов заболеваний
А.В. Чижик1, С.А. Мельникова2
Введение
Практически все существующие задачи машинного обучения базируются на необходимости наличия обучающего набора данных, в особенности это касается задач классификации и выстраивания человеко-машинного диалога. Датасет – это обработанные и структурированные данные в табличном виде. Иными словами, это размеченные данные, на основе которых и происходит машинное обучение. Например, если перед нами стоит задача интеграции взаимодействия голосовыми командами с интерфейсом, то для начала своей модели мы должны предоставить набор данных с транскрипциями живой речи. Чем больше образцов речи нам удастся собрать в наш датасет, тем лучше модель будет отрабатывать n+1 случай.
На данный момент гипотеза возможности внедрения ИИ в рутинный конвейер взаимодействия «клиника-пациент» выглядит достаточно привлекательной. Однако, есть ряд ограничений: во-первых, все еще нет четкой позиции медиков и юристов на тему легитимности включения ИИ в рутинные процессы на первом этапе взаимодействия пациента и клиники; во-вторых, практически всегда реализация общения «робота» с живым человеком строится на интерфейсах с использованием правил (если…,то…), а не на реализации человеко-машинного разговора в формате естественного диалога. Последняя проблема является ключевой для нас. Отметим, что для того, чтобы построить коммуникацию на естественном языке и при этом преследовать цель сбора полезных фактов, а также не разочаровывать бессмысленностью ответов, необходима разработка сценариев поведения чат-бота, но, главное, требуется сбор датасетов с примерами как реплик человека (для детекции классов намерения пользователя), так и с коллекцией симптомов (ведь основная задача первичного взаимодействия пациента с клиникой почти всегда сводится к тому, что человек хочет записаться на прием к врачу, а регистратура нуждается в информации на тему его состояния).
Также стоит упомянуть перспективную задачу анализа поведения пациентов вне клиники с точки зрения рефлексии на тему своего самочувствия и поставленных диагнозов. Такая проблема также упирается в сбор медицинских текстовых данных и в последующем нахождения в них закономерностей.
Базовым подходом к сбору медицинских данных является обращение к медицинским выпискам. В целом это логично, так как на данный момент любой приход к врачу фиксируется в цифровой форме, что означает наличие после каждого наблюдения пациента большого количества данных: информация о физическом состоянии, симптомы, описание жалоб и т.д. Однако такого рода информация ограничена в распространении, использование ее в чат-ботах является сомнительным кейсом (так как нет согласия автора текстов, т.е. пациента). В связи с этим возникает гипотеза, что стоит обратиться к анализу большого количества данных, размещенных в сети интернет.
Разделы сайтов клиник типа «вопрос-ответ», а также взаимодействия между людьми в социальных сетях с целью обмена публичной информацией представляют собой важный новый источник данных. 
Стоит отметить, что количество данных, содержащихся в открытых источниках (новые и социальные медиа), можно отнести к категории Big Data [1] 
Если обратиться к рефлексии на тему полезности такого рода слабо структурированных данных, то их можно использовать для понимания воздействия лекарств, болезней и методов лечения на пациентов за пределами контролируемых клинических условий, а также, чтобы понять паттерны поведения индивидов, связанные со здоровьем. 
Для нас же было интересно попытаться выделить из этого массива данные, которые бы можно было использовать для разметки симптомов на классы (определение диагноза). 
Особенность интернета как источника таких данных заключается в том, что перед нами оказываются тексты на естественном языке с очень разнообразной структурой. Это их существенно отличает от электронных медицинских записей, где содержится текст на естественном языке, однако он более формален, что дает возможность быстрее извлечь и структурировать релевантную информацию.
1. Постановка задачи
Перед нами стояла задача «чтения» неструктурированных текстов с целью сбора определенной медицинской информации и формирования на ее основе датасета, пригодного для использования в алгоритмах машинного обучения.
Датасет отличается от простого сбора медицинских данных тем, что он наделён особыми свойствами ― унификацией и структурированностью данных; отсутствием грубых неточностей; наличием дополнительной информации. Каждый датасет уникален не только образцами данных, которые в него входят, но также способом их классификации и подходами к разметке. 
Для того чтобы создать датасет, которым можно воспользоваться в дальнейших исследованиях и применить в прикладных разработках, было необходимо сформулировать клиническую и/или практическую задачу в области медицины, которая (потенциально) подвержена автоматизации с помощью интеллектуальных систем.
В нашем случае прикладной целью создания датасета явилось желание создать сервис для социологических опросов на медицинскую тему. Веб-сервис предполагается реализовать в формате чат-бота с открытым доменом для симуляции человеко-машинного диалога (симуляция медицинского сервиса). Основной конечной целью такой прикладной разработки мы видим изучение пользовательского опыта и фиксацию пути решения стандартной проблемы при обращении в автоматизированные центры скорой помощи 
и регистратуры (так как мы предполагаем, что положительное восприятие автоматизации происходит за счет использования естественного языка со стороны бота вместо реализации подобных приложений на базе правил). Таким образом, датасет с размеченными классами симптомов будет полезным для решения технических задач, в том числе распознавания намерения пользователя. Также мы хотим протестировать с помощью респондентов точность классификации, которая возможна при условии наличия «чистого» датасета.
Стоит отметить, что для таких задач существуют специализированные сервисы, например Amazon Comprehend Medical [2]. Он позволяет извлекать значимую информацию (жалобы, диагноз, назначенные препараты и их дозировку, результаты исследований и т.п) из неструктурированных медицинских записей. В конце 2019 г. JAMIA [3] опубликовала исследование, которое показало, что данные, полученные из неструктурированных ЭМК, являются более точным источником информации для прогнозирования ИБС, чем структурированные данные. Это подкрепляет нашу перспективность извлечения признаков из неструктурированных открытых медицинских данных для задач сбора больших наборов данных для машинного обучения. 
Для решения нашей задачи она была разбита на три подзадачи:
₋	выбор источников данных и сбор чернового датасета (неструктурированные тексты и техническая информация);
₋	извлечение названий болезней (классы);
₋	выделение симптомов.
2. Этап отбора исходных данных
Медицинские данные могут накапливаться как при фиксации рутинного диагностического процесса в медицинском учреждении, так и с использованием неструктурированных данных из социальных и новых медиа. Люди часто обеспокоены состоянием своего здоровья и рядом медицинских проблем, особенно когда речь идет о сложных или хронических заболеваниях. Пациенты часто желают иметь легкий доступ к информации о заболеваниях и симптомах, чтобы понять свое состояние и облегчить самоконтроль заболеваний, не полагаясь полностью на взаимодействие с врачом [4]. К примеру, пациенты с хроническими заболеваниями используют социальные сети для получения эмоциональной и практической поддержки [5]. К тому же медицинские работники часто делятся своим опытом в социальных сетях, в том числе исходя из маркетинговых целей. Существует статистика, согласно которой 42% интернет-пользователей используют социальные сети для получения медицинской информации. 29% ищут информацию о здоровье через платформы социальных сетей, чтобы наблюдать за опытом других пациентов с их заболеваниями [6] (это значит, что в одном сообщении появляются как диагнозы, так и симптомы). Разговоры пользователей на темы, связанные со здоровьем, которые содержатся в Twitter и Facebook, были проанализированы рядом ученых. В частности, есть исследование, описывающее анализ текстовых данных с целью выделения кластеров симптомов рака молочной железы [7]. Также текстовые данные изучали в контексте анализа поведения курящих людей [8,9].
Еще одна научная группа [10] извлекла данные из онлайн-сообществ, посвященных вопросам здравоохранения, ученые использовали кластеризацию текстовых данных для изучения потребностей и интересов пациентов. Были извлечены медицинские термины, в том числе связанные с состояниями, симптомами, лечением, эффективностью и побочными эффектами. Их результаты показывают, что существовали значительные различия в темах, которые присутствовали на различных платформах для обсуждения болезней, если сравнивать их с вектором популярного контента в научной литературе.
Латентное распределение Дирихле (LDA) было использовано для кластеризации обсуждений диагнозов в Facebook [11]. Сгруппированные тематические кластера были проанализированы с точки зрения полярности настроений. 
Таким образом, становится очевидно, что данные, собранные из открытых источников, обычно имеют широкую вариативность в изложении информации и позволяют создать наиболее репрезентативный датасет. 
Ключевое значение имеет баланс классов: в какой пропорции распределены образцы в датасете. Проблема работы с несбалансированными наборами данных заключается в том, что большинство методов машинного обучения игнорирует или имеет низкую производительность при анализе малого класса. В то время как с практической точки зрения производительность в этом классе является наиболее важной задачей. 
В задаче классификации данные называются несбалансированными, если в обучающей выборке доли объектов разных классов существенно различаются [12]. Проблема с дисбалансом чаще всего возникает, когда какой-то из классов соответствует очень редко наблюдаемым или диагностируемым явлениям (например, редкая болезнь). Для решения задачи уравновешивания классов обычно применяют перебалансировку данных: недо- или пересэмплирование (SMOTE). SMOTE заключается в идее увеличения малого класса за счёт представителей выпуклых комбинаций пар. Самый простой подход включает в себя дублирование примеров в миноритарном классе, хотя эти примеры не добавляют в модель никакой новой информации. Поэтому новые примеры могут быть синтезированы из существующих примеров. Этот тип увеличения данных для малого класса называется методом пересэмплирования. Вторая идея перебалансировки [13] заключается в том, что мы можем сделать классы сбалансированными за счет замены большого класса подвыборкой по мощности равной малому классу, этот прием называется недосэмлированием. 
Подводя практический итог, простейшая стратегия недосэмплирования – взять случайную подвыборку, простейшая стратегия пересэмплирования – продублировать объекты малого класса. У пересэмплирования качество, как правило, выше, т.к. используются все данные, однако недосэмплирование позволяет учить модель на маленькой выборке.
3. Обзор возможностей извлечения качественных характеристик заболевания и описание полученных результатов
На первом этапе мы сформировали набор из 120 заболеваний, которые взяли на официальных сайтах клиник. Эта информация была необходима для того, чтобы затем собирать описания симптомов этих заболеваний. Таким образом, мы выявили метки классов и получили по одному образцу статьи, описывающей заболевание. Средняя длина такой статьи 4000 знаков. Далее было принято решение сфокусироваться при сборе данных на 5 заболеваниях: «аппендицит», «холицестит», «эзофагит», «энтерит», «язва». В итоге был собран корпус из 13 624 текстовых сообщений на тему этих заболеваний (разделы сайтов медицинских учреждений, дискуссии в социальных сетях, посвященные конкретным заболеваниям).
Дальнейшую задачу можно сформулировать как извлечение качественных характеристик заболевания (указывающих на симптоматику) из текста. 
Для анализа медицинских текстовых записей используются специализированные методы и инструменты распознавания именованных сущностей (NER). Эти методы обработки человеческого языка позволяют находить в образцах текста на естественном языке опредмеченные категории слов и словосочетаний. Часто (как и в нашем случае) речь идет о работе с метками классов, количество которых является заранее известным. Классами могут являться наименования заболеваний, факты госпитализации пациента (есть или нет), различные количественные и качественные параметры, признаки и случаи и т.д. 
Большинство NER-классификаторов базируются на алгоритме CRF (Conditional random field), который относится к классу скрытых марковских моделей [14]. 
Для создания моделей NER-классификации обычно используется библиотека с открытым исходным кодом для обработки естественного языка – SpaCy. Она написана на языке программирования Python, выполняет токенизацию, разметку части речи (PoS) и разбор зависимостей. Библиотека опубликована под лицензией MIT. SpaCy предлагает 18 меток (tags), которыми отмечаются именованные сущности, а также простой способ дообучить свою собственную модель. В работе [15] оценивались 10 различных готовых систем извлечения признаков на точность и скорость извлечения. В итоге SpaCy показал лучшую скорость извлечения, поддерживая сопоставимую точность от 85% до 90%. Модели SpaCy представляют собой сверточные нейросети (CNN), которые позволяют делать прогноз, основанный на представленных во время обучения примерах.
В 2020 г. университет Стенфорда выпустил свою библиотеку Stanza [16]. Модули библиотеки построены на основе библиотеки PyTorch. Это набор инструментов, которые можно использовать для создания конвейеров нейронных сетей для анализа текста. Библиотека поддерживает такие функции как токенизация, расширение токена до нескольких слов, лемматизация, части речи (POS), тегирование морфологических признаков, анализ зависимостей, распознавание именованных сущностей и анализ настроений. Она использует универсальные зависимости для предоставления согласованных аннотаций грамматики на более чем 60 языках. Таким образом, по сути, библиотека покрывает минус SpaCy (отсутствие языковых моделей для некоторых языков, в том числе поддержка русского языка стала возможна только в 2021 г. и пока годится не для всех задач) и реализует мультиязычность. Отметим, что Stanza предоставляет готовые функции, которые поддерживают синтаксический анализ и распознавание именованных объектов в текстах клинических выписок (что оказалось полезно для нашей задачи).
Нами также была предпринята попытка анализа текстов с помощью проекта Natasha. Это один из главных NLP-проектов для русского языка. Он имеет долгую историю, и начинался с rule-based решений, сейчас же библиотека решает основные задачи NLP для русского языка современными методами: токенизацию, сегментация предложения, лемматизация, нормализация фразы, синтаксический разбор, NER-тегирование, извлечение фактов. К минусам можно отнести нестабильный результат работы (в зависимости от сложности и специфичности текстов, подаваемых на вход). 
В итоге мы остановились на использовании библиотеки Stanza. 
Для оценки качества задач NER, как правило, используются метрики: Precision (точность), Recall (полнота), F1 (среднее гармоническое точности и полноты). При этом для улучшения детекции симптомов мы проанализировали исходный датасет с использованием метрик релевантности, читаемости и спамности (которые заимствовали из маркетинговых исследований). После чего удалили тексты не соответствующие критериям читаемости (иными словами, проверили тексты на предмет присутствия бессодержательной демагогии), чтобы получаемые данные были более «читаемы» и нашим алгоритмом извлечения симптомов.
В итоге обученная нами модель имела следующие метрики качества: Precision=91,1%, Recall=87,3%, F1 = 89,2%.
Заключение
Обученная модель извлечения признаков из медицинских текстов методами NLP показала достаточную точность при обработке неструктурированных текстовых данных. Собранные данные будут тестироваться внутри чат-бота (ручными методами), 
а датасет планируется продолжить пополнять. Итоговый датасет выложен в открытый доступ [ссылка].