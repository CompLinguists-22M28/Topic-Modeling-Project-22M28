Оценка эмоциональной окраски постов социальной сети «ВКонтакте», включающих эмодзи, 
методами машинного и глубокого обучения
А.П. Быкова
1. Введение
Уже не одно десятилетие исследователи достаточно много внимания уделяют анализу тональности текста и речи. Результаты анализа эмоциональной окраски текстов имеют множество практических применений, например, в различных приложениях при работе с клиентами, в политологии при работе с политическими окрашенными текстами, здравоохранении. Изучается потенциал анализа эмоций для выявления и предотвращения различных форм онлайн-злоупотреблений, например, запугивания пользователей. Кроме того, растёт интерес к тому, как эмоции передаются в разных языках и культурах, и как это может повлиять на оценку эмоциональной окраски различной информации [1].
Оценка эмоциональной окраски текста может быть полезна во многих областях, например, для того, чтобы понять какое настроение выражено в тексте. Эта информация может использоваться для анализа мнений, анализа отзывов клиентов, мониторинга социальных сетей. Понимая эмоции, выраженные в тексте, организации могут лучше учитывать потребности и предпочтения своих клиентов. Понимание эмоций также можно использовать в личном общении, чтобы оценить настроение человека и отреагировать соответствующим образом. В данном исследовании оценка эмоциональной окраски текста постов в социальной сети «ВКонтакте» проводится методами машинного и глубокого обучения. Для разметки постов использовалась автоматическая разметка на основании встречающихся в этих постах эмо́дзи.
Эмо́дзи — это цифровые изображения или значки, которые используются в текстовых сообщениях в различных социальных сетях, в том числе «ВКонтакте». Язык эмо́дзи своего рода графический язык, где вместо слов используются сочетания картинок. Впервые эмо́дзи появились в Японии и распространились по всему миру. В настоящее время использование эмо́дзи достаточно популярно и доступно в самых разных стилях и дизайнах. Популярность эмо́дзи обусловлена тем, что они могут передавать эмоции и добавлять контекст к текстовому общению. В некоторых случаях эмо́дзи помогают преодолевать языковые барьеры и делают общение более доступным среди людей, которые владеют разными языками.
2. Подходы к анализу эмоциональной окраски текста
Анализ тональности текста - одно из направлений в компьютерной лингвистике, в рамках которого решается задача выявления мнения автора текста по поводу того, что обсуждается в тексте.
Тональность текста можно рассматривать как с точки зрения автора текста, так и с точки зрения того, кто читает и воспринимает этот текст. Поскольку в данном исследовании эмо́дзи являются маркером для разметки, а эмо́дзи проставляет сам автор текста, то в этом исследовании тональность и эмоциональная окраска текста рассматривается с точки зрения автора этого текста.
В целом, анализ эмоциональной окраски текста подразумевает собой применение методов, с помощью которых можно определить, к какому классу относится тот или иной текст. В основном используются алгоритмы на основе словарей и правил [2; 3] и методы на основе машинного обучения. Также существуют комбинированные методы, в которых словари оценочной лексики являются компонентом модели машинного обучения [4].
Для многих задач автоматической обработки текста необходимы специально размеченные текстовые данные, например, для автоматического распознавания в тексте иронии или сарказма [5].
Большую популярность в задачах анализа тональности приобрели методы машинного обучения. С начала 2000х годов широко применяются классические методы машинного обучения, такие как логистическая регрессия, метод опорных векторов, наивный байесовский классификатор [6]. Также широко применяются классические нейронные сети, например, рекуррентные нейронные сети и свёрточные нейронные сети [7]. В 2019 году появились новые подходы к анализу текста на основе нейросетевой архитектуры трансформер, такие как модель BERT [8]. Использование архитектуры серии BERT для различных задач автоматической обработки текста привело к росту качества решений этих задач, в том числе и в задачах анализа тональности.
Первоначально модель BERT обучалась на многоязычных текстовых данных, затем в ряде исследований было выявлено, что дообучение BERT на данных конкретного естественного языка может дать лучшие результаты решения задач для этого языка. Так, например, в работе [9] исследователи описывают модель RuBERT, которая дообучена на модели BERT для русского языка.
3. Сбор и разметка данных
Набор данных создавался самостоятельно из постов социальной сети «ВКонтакте». Данные взяты из 100 наиболее популярных сообществ «ВКонтакте» на 5 февраля 2023 года. Статистика по самым популярным сообществам взята с сайта «TOPPOST». Выбор постов из социальной сети «ВКонтакте» в качестве материала исследования обусловлен тем, что данная социальная сеть является популярной платформой, которой пользуются русскоязычные пользователи. В постах пользователи выражают собственное мнение и открыто взаимодействуют посредством различных реакций (лайки, комментарии, репосты). В социальной сети чаще происходит неформальное эмоционально окрашенное общение, поэтому текст постов можно использовать для оценки эмоциональной окраски текста.
API (Application Programming Interface) «ВКонтакте» представлен в открытом доступе, с помощью открытых методов был написан скрипт для скачивания текста постов.
В качестве маркеров для разметки текста использовались эмо́дзи, которые встречаются в постах. Разметка на основе эмо́дзи является ограничением данного исследования, поскольку такой разметки может быть недостаточно для точной классификации текста по эмоциям и тональности, особенно в том случае, если эмо́дзи использовались авторами постов неоднозначно. Для пояснения значений эмо́дзи и их классификации использовались карточки с описанием с сайта «Смайлики Эмо́дзи».
Собран словарь эмо́дзи, которые встречаются в скачанных постах, состоящий из 146 эмо́дзи, входящие в тематическую группу Smileys & Emotion.
Полученные 146 эмо́дзи распределены по классам. В этих классах учитывается эмоциональная составляющая и тональная составляющая, поскольку однозначно категоризировать эмоции достаточно сложно, например, для такой эмоции, как удивление, может присутствовать как положительная, так и отрицательная тональность (см. табл. 1).
Таблица 1. Классы эмоций и тональности
№	Эмоция	Настроение (тональность)
1	улыбка (smile)	позитивное/негативное (positive/negative)
2	нет эмоции (no_emotion)	нейтральное/скептическое (neutral/skeptical)
3	удовольствие	позитивное (positive)
4	нет эмоции (no_emotion)	позитивное/негативное (positive/negative)
5	грусть (sadness)	негативное (negative)
6	страх (feat)	негативное (negative)
7	стыд (shame)	негативное (negative)
8	гнев (anger)	негативное (negative)
9	отвращение (disgust)	негативное (negative)
10	удивление (surprise)	позитивное/негативное (positive/negative)
11	отвращение (disgust)	нейтральное/скептическое (neutral/skeptical)
12	удивление (surprise)	негативное (negative)
13	нет эмоции (no_emotion)	негативное (negative)
14	грусть (sadness)	позитивное/негативное (positive/negative)
15	испуг (fear)	позитивное/негативное (positive/negative)
Самое большое количество эмо́дзи 26 из 146 относится к классу joy positive (удовольствие позитивное настроение).
Для оценки эмоциональной окраски проведена автоматическая разметка данных на основе использованных в тексте эмо́дзи. Для обучения и оценки алгоритмов машинного обучения были выбраны посты с 1 эмо́дзи и длиной поста не более 11 токенов вместе с эмо́дзи, получилось 9220 постов. В дальнейшем планируется исследовать тексты с другими параметрами по количеству эмо́дзи и количеству токенов в посте.
Среди выбранных данных больше всего постов с эмо́дзи из класса smile positive/negative (улыбка позитивное/негативное настроение), полученный набор данных является несбалансированным. Для эффективной работы с данными необходима их предобработка. Для этого из текста постов удалены id пользователей и групп, текст переведён в нижний регистр. Полученные 9220 постов автоматически размечены по 15 выделенным классам.
4. Эксперименты с моделями машинного и глубокого обучения
Выбор метода для анализа эмоциональной окраски текста зависит от требований решаемой задачи и характера набора данных. Для того, чтобы узнать, какой метод больше всего подходит для данного исследования, был проведён ряд экспериментов.
Тестовая выборка данных составляла 20% из общего числа постов, то есть 9220 * 0,2 = 1844 поста.
Для оценки эмоциональной окраски размеченных постов использовались классические методы машинного обучения из пакета scikit-learn. Для предобработки постов использовался лемматизатор pymorphy2.
Эксперименты проводились для текста с пунктуацией и с эмо́дзи, для текста без пунктуации и без эмо́дзи, для лемматизированного с помощью pymorphy2 текста c пунктуацией и с эмо́дзи.
Использовались представления слов в виде мешка слов (Bag of Words) [10], предобученные плотные векторные представления слов для русского языка из библиотеки Navec и Word2Vec [11] для классических методов машинного обучения, таких как, наивный байесовский классификатор (GaussianNB), логистическая регрессия (Logistic Regression), метод опорных векторов (SVM), градиентный бустинг (Gradient Boosting), случайный лес (Random Forest), классификатор дерева решений (DecisionTreeClassifier). Также проведены эксперименты с использованием ансамблей классификаторов с мажоритарным и мягким голосованием с помощью VotingClassifier.
Для экспериментов использовались нейросетевые модели: одномерная свёрточная нейросеть CNN, рекуррентная нейросеть LSTM (Long Short-Term Memory) и рекуррентная нейросеть GRU (Gated Recurrent Units).
5. Результаты оценки эмоциональной окраски текста постов
Для оценки качества классификации использовались метрики: F1-мера по макроусреднению (macro) и F1-мера по взвешенному усреднению (weighted). Выбор данных метрик для оценки эмоциональной окраски текста постов обусловлен тем, что полученный набор данных не является сбалансированным.
По F1-мере лучший результат получился для модели BoW +VotingClassifier (soft) (мешок слов + ансамблевый метод с мягким голосованием) на лемматизированном тексте c пунктуацией и с эмо́дзи, F1-мера macro равна 69.70%, F1-мера weighted равна 82.06%. Полученные результаты представлены в таблице 2 (лучшие результаты выделены жирным шрифтом).
Таблица 2. Результаты оценки эмоциональной окраски текста 
для классических методов машинного обучения
Модель 	F1 macro %	F1 weighted %
BoW + Logistic Regression (текст с пунктуацией и с эмо́дзи)	51.74	78.97
BoW + SVC (текст с пунктуацией и с эмо́дзи)	40.26	72.21
BoW + RandomForestClassifier (текст с пунктуацией и с эмо́дзи)	65.10	80.54
BoW + DecisionTreeClassifier (текст с пунктуацией и с эмо́дзи)	63.79	79.45
BoW + GaussianNB (текст с пунктуацией и с эмо́дзи)	28.49	62.17
BoW + GradientBoostingClassifier (текст с пунктуацией и с эмо́дзи)	65.27	81.48
BoW + VotingClassifier (hard) (текст с пунктуацией и с эмо́дзи)	64.64	81.34
BoW + VotingClassifier (soft) (текст с пунктуацией и с эмо́дзи)	67.99	82.02
Navec + Logistic Regression (текст с пунктуацией и с эмо́дзи)	11.31	49.51
Navec + SVC (текст с пунктуацией и с эмо́дзи)	6.78	50.25
Navec + RandomForestClassifier (текст с пунктуацией и с эмо́дзи)	11.02	51.75
Navec + DecisionTreeClassifier (текст с пунктуацией и с эмо́дзи)	10.21	46.40
Navec + GaussianNB (текст с пунктуацией и с эмо́дзи)	1.15	4.34
Navec + GradientBoostingClassifier (текст с пунктуацией и с эмо́дзи)	8.19	49.25
Navec + VotingClassifier (hard) (текст с пунктуацией и с эмо́дзи)	10.50	51.68
Navec + VotingClassifier (soft) (текст с пунктуацией и с эмо́дзи)	11.02	52.07
Word2Vec + Logistic Regression (текст с пунктуацией и с эмо́дзи)	5.17	48.99
Word2Vec + SVC (текст с пунктуацией и с эмо́дзи)	5.17	48.99
Word2Vec + RandomForestClassifier (текст с пунктуацией и с эмо́дзи)	23.64	62.53
Word2Vec + DecisionTreeClassifier (текст с пунктуацией и с эмо́дзи)	15.22	54.54
Word2Vec + GaussianNB (текст с пунктуацией и с эмо́дзи)	1.63	7.60
Word2Vec + GradientBoostingClassifier (текст с пунктуацией и с эмо́дзи)	15.55	57.24
Word2Vec + VotingClassifier (hard) (текст с пунктуацией и с эмо́дзи)	11.76	54.77
Word2Vec + VotingClassifier (soft) (текст с пунктуацией и с эмо́дзи)	13.21	57.14
BoW + Logistic Regression (текст без пунктуации и без эмо́дзи)	8.33	52.19
BoW + SVC (текст без пунктуации и без эмо́дзи)	6.99	50.60
BoW + RandomForestClassifier (текст без пунктуации и без эмо́дзи)	15.36	53.06
BoW + DecisionTreeClassifier (текст без пунктуации и без эмо́дзи)	13.42	50.57
BoW + GaussianNB (текст без пунктуации и без эмо́дзи)	10.86	39.11
BoW + GradientBoostingClassifier (текст без пунктуации и без эмо́дзи)	12.58	51.35
BoW + VotingClassifier (hard) (текст без пунктуации и без эмо́дзи)	14.38	52.34
BoW + VotingClassifier (soft) (текст без пунктуации и без эмо́дзи)	14.80	53.75
Navec + Logistic Regression (текст без пунктуации и без эмо́дзи)	12.28	50.47
Navec + SVC (текст без пунктуации и без эмо́дзи)	7.67	50.36
Navec + RandomForestClassifier (текст без пунктуации и без эмо́дзи)	10.57	51.80
Navec + DecisionTreeClassifier (текст без пунктуации и без эмо́дзи)	10.63	44.41
Navec + GaussianNB (текст без пунктуации и без эмо́дзи)	1.05	1.05
Navec + GradientBoostingClassifier (текст без пунктуации и без эмо́дзи)	9.12	49.62
Navec + VotingClassifier (hard) (текст без пунктуации и без эмо́дзи)	11.41	51.92
Navec + VotingClassifier (soft) (текст без пунктуации и без эмо́дзи)	11.89	52.67
Word2Vec + Logistic Regression (текст без пунктуации и без эмо́дзи)	5.17	48.99
Word2Vec + SVC (текст без пунктуации и без эмо́дзи)	5.17	48.99
Word2Vec + RandomForestClassifier (текст без пунктуации и без эмо́дзи)	9.71	51.74
Word2Vec + DecisionTreeClassifier (текст без пунктуации и без эмо́дзи)	9.83	45.48
Word2Vec + GaussianNB (текст без пунктуации и без эмо́дзи)	0.03	0.01
Word2Vec + GradientBoostingClassifier (текст без пунктуации и без эмо́дзи)	8.58	49.09
Word2Vec + VotingClassifier (hard) (текст без пунктуации и без эмо́дзи)	8.78	50.66
Word2Vec + VotingClassifier (soft) (текст без пунктуации и без эмо́дзи)	8.91	50.82
BoW + Logistic Regression (лемматизированный текст c пунктуацией и с эмо́дзи)	51.49	78.64
BoW + SVC (лемматизированный текст c пунктуацией и с эмо́дзи)	40.16	72.11
BoW + RandomForestClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	66.77	81.43
BoW + DecisionTreeClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	66.30	79.28
BoW + GaussianNB (лемматизированный текст c пунктуацией и с эмо́дзи)	27.26	60.74
BoW + GradientBoostingClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	67.01	81.74
BoW + VotingClassifier (hard) (лемматизированный текст c пунктуацией и с эмо́дзи)	63.35	81.32
BoW + VotingClassifier (soft) (лемматизированный текст c пунктуацией и с эмо́дзи)	69.70	82.06
Navec + Logistic Regression (лемматизированный текст c пунктуацией и с эмо́дзи)	11.39	49.15
Navec + SVC (лемматизированный текст c пунктуацией и с эмо́дзи)	6.59	50.04
Navec + RandomForestClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	11.14	51.98
Navec + DecisionTreeClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	9.89	46.18
Navec + GaussianNB (лемматизированный текст c пунктуацией и с эмо́дзи)	1.14	4.83
Navec + GradientBoostingClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	7.35	49.20
Navec + VotingClassifier (hard) (лемматизированный текст c пунктуацией и с эмо́дзи)	10.50	51.60
Navec + VotingClassifier (soft) (лемматизированный текст c пунктуацией и с эмо́дзи)	10.91	51.73
Word2Vec + Logistic Regression (лемматизированный текст c пунктуацией и с эмо́дзи)	5.17	48.99
Word2Vec + SVC (лемматизированный текст c пунктуацией и с эмо́дзи)	5.17	48.99
Word2Vec + RandomForestClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	25.85	64.19
Word2Vec + DecisionTreeClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	18.91	55.79
Word2Vec + GaussianNB (лемматизированный текст c пунктуацией и с эмо́дзи)	1.40	6.56
Word2Vec + GradientBoostingClassifier (лемматизированный текст c пунктуацией и с эмо́дзи)	18.77	56.97
Word2Vec   +VotingClassifier (hard) (лемматизированный текст c пунктуацией и с эмо́дзи)	13.93	55.47
Word2Vec +VotingClassifier (soft) (лемматизированный текст c пунктуацией и с эмо́дзи)	18.09	59.61
Также для экспериментов использовались нейросетевые модели: одномерная свёрточная нейросеть CNN, рекуррентная нейросеть LSTM (Long Short-Term Memory) и рекуррентная нейросеть GRU (Gated Recurrent Units).
Лучший результат среди использованных нейросетевых моделей показала рекуррентная нейросеть GRU на 15 эпохах обучения: F1-мера macro равна 48.77%, F1-мера weighted равна 83.74%. Полученные результаты представлены в таблице 3 (лучшие результаты выделены жирным шрифтом). 
Таблица 3. Результаты оценки эмоциональной окраски текста для нейросетевых методов
Модель 	F1 macro %	F1 weighted %
Одномерная свёрточная нейросеть (токенизатор Keras, optimizer=‘adam’, epochs=5)	17.42	71.54
Рекуррентная нейросеть LSTM (токенизатор Keras, optimizer=‘adam’, epochs=5)	11.85	62.66
Рекуррентная нейросеть GRU (токенизатор Keras, optimizer=‘adam’, epochs=5) 	28.29	78.42
Одномерная свёрточная нейросеть (токенизатор Keras, optimizer=‘adam’, epochs=10)	40.20	81.86
Рекуррентная нейросеть LSTM (токенизатор Keras, optimizer=‘adam’, epochs=10)	23.44	78.39
Рекуррентная нейросеть GRU (токенизатор Keras, optimizer=‘adam’, epochs=10) 	43.15	83.85
Одномерная свёрточная нейросеть (токенизатор Keras, optimizer=‘adam’, epochs=15)	27.77	78.96
LSTM (токенизатор Keras, optimizer=‘adam’, epochs=15)	29.34	79.81
Рекуррентная нейросеть GRU (токенизатор Keras, optimizer=‘adam’, epochs=15)	48.77	83.74
Получили, что в случае макроусреднения, т.е. когда всем классам даётся одинаковый вес, независимо от их количества в наборе данных, лучший результат F1-мера macro = 69.70% для модели BoW +VotingClassifier (soft) (мешок слов + ансамблевый метод с мягким голосованием) на лемматизированном тексте c пунктуацией и с эмо́дзи. В случае же взвешенного усреднения, т.е. когда вес классам даётся согласно количеству объектов в этих классах, лучший результат F1-мера weighted = 83.74% для модели рекуррентной нейросети GRU на 15 эпохах обучения. 
В дальнейшем планируется сравнить полученные результаты по метрикам качества классификации F1-меры с результатами работы модели RuBERT, которая позволяет работать с текстами на русском языке и имеет качественные распределённые векторные вложения (embeddings) текстов.
6. Заключение
В данной статье представлена оценка эмоциональной окраски постов из социальной сети «ВКонтакте», описан процесс получения, обработки и использования полученного набора данных. Приводятся результаты экспериментов с использованием методов машинного и глубокого обучения с оценкой работы методов по метрикам качества классификации. По оценке качества классификации текста постов лучший результат по метрике F1-мера macro = 69.70% показала модель BoW +VotingClassifier (soft) (мешок слов + ансамблевый метод с мягким голосованием) на лемматизированном тексте c пунктуацией и с эмо́дзи. Лучший результат по метрике качества классификации F1-мера weighted получен для модели рекуррентной нейросети GRU F1-мера weighted = 83.74%.
Поскольку эксперты не размечали полученные данные, а использовалась автоматическая разметка постов на основании встречающихся в этих постах эмо́дзи, в дальнейшем планируется провести экспертную оценку полученной автоматической разметки постов по выделенным классам. 
Также планируется провести эксперименты на сбалансированных данных. В будущем можно продолжить исследование с использованием текстов с другими параметрами по количеству эмо́дзи и токенов в тексте.
 
