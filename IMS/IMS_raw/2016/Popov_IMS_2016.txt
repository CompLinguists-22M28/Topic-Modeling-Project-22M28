Ещё раз о способах снятия структурной омонимии:
выбор единственной структуры в парсере Hurma
А.М. Попов1,2, Е.В. Протопопова1,2, Г.Т. Букия 1
1

Санкт-Петербургский государственный университет
hedgeonline@gmail.com, protoev@gmail.com, gregorybookia@yandex.ru
2
проект Хурма

1. Введение
Синтаксический анализ является одной из наиболее спорных и трудоёмких
задач автоматической обработки текста. С одной стороны, это связано с
большим количеством синтаксических теорий, многие из которых имеют лишь
ограниченное практическое применение. С другой стороны, модули
синтаксического анализа востребованы в таких приложениях, как системы
извлечения фактов, вопросно-ответные системы, машинный перевод.
Что касается русского языка, то вследствие богатой морфологии задача
синтаксического анализа оказывается более сложной по сравнению с
Сборник научных статей XIX Объединенной конференции «Интернет
современное общество» IMS-2015, Санкт-Петербург, 22 - 24 июня 2016 года.

и


английским, для которого сформировался ряд общепризнанных решений
(Stanford Parser etc.). Подробный анализ существующих решений для русского
языка был проведён в 2011–12 годах в рамках форума «Оценка методов
автоматического анализа текстов» [1], который был посвящён синтаксическому
анализу. В рамках соревнования был подготовлен золотой стандарт разметки,
который до сих пор остаётся единственным эталоном разбора текстов на
русском языке. Среди участников были как коммерческие системы — ABBYY
Compreno [2], SyntAutom [3], — так и академические разработки (ЭТАП-3 [4]).
Результаты форума и последующие работы показывают, что системы
синтаксического анализа (парсеры) используют как подходы, основанные на
правилах, так и статистические и гибридные подходы. Кроме того,
существующие парсеры предполагают различные виды синтаксического
представления — от традиционных грамматик зависимостей и составляющих
Parser
—
грамматики
связей
(Link
Grammar
до,
например,
http://slashzone.ru/parser/). Однако, немногие среди известных решений
представляют собой системы, доступ к которым открыт для исследователя.
Следует
упомянуть
MaltParser,
обученная
модель
для
которого
распространяется свободно, в том числе и для русского языка, и которую
используются большинство некоммерческих разработок [5; 6].

2. Архитектура синтаксического парсера Hurma
2.1. Реализация и алгоритм
В силу того, что к самому лингвистическому анализатору предъявляются
максимально широкие требования для возможности решения широкого спектра
прикладных и исследовательских задач, к модулю синтаксического анализа
были выдвинуты следующие требования:
(1) Синтаксический анализ должен проводиться без предварительного
снятия морфологической неоднозначности;
(2) Синтаксический анализатор должен строить все варианты
синтаксических структур;
(3) Алгоритмическая сложность анализа не должна быть экспоненциальной;
(4) В результате синтаксического анализа должна получаться единственная
структура и при этом наиболее вероятная среди всех;
(5) Алгоритм должен быть адаптирован к неполноте грамматики и
обеспечивать возможность выбора наиболее крупных фрагментов
«развалившейся структуры»;
(6) Тип выходной структуры — дерево зависимостей.
Требование (1) является необходимым для выполнения требования (2), т.к.
при удалении некоторых морфологических вариантов ещё до синтаксического
анализа можно потерять «хорошие» кандидаты структур. Требование (2)
является необходимым для выполнения требования (4), т.к. если не перебирать
все варианты структур, то нельзя гарантировать, что выдаваемая структура
будет иметь наивысший вес. Требования (3) необходимо для того, чтобы
гарантировать конечное время синтаксического анализа при условии (2).
Последние требования (5) и (6) обусловлены тем, что структуры зависимостей
лучше подходят для непосредственного использования на последующих
уровнях анализа, таких как, например, семантический, а вероятность частичных
разборов на ранних стадиях разработки грамматики весьма высока, поэтому
должна быть возможность извлечь максимум информации для последующих
уровней анализа даже в том случае, если разбор «развалился».
Проанализировав вышеописанные требования мы пришли к выводу, что
наиболее удобной базой для нашего анализатора является алгоритм КокаЯнгера-Касами (CYK). Тому есть ряд причин.
Во-первых, алгоритм CYK позволяет без каких-либо доработок
использовать морфологически неоднозначный вход — мы просто создаём
несколько нетерминальных символов в ячейке таблицы, соответствующей
каждому многозначному токену, таким образом, обеспечивая выполнение (1).
Во-вторых, алгоритм CYK является алгоритмом, использующим принцип
динамического программирования, что позволяет нам перебирать все варианты
синтаксической структуры и при этом в явном виде их не перечислять,
обеспечивая полиномиальную сложность анализа и, соответственно,
выполнение (2) и (3).
В-третьих, хотя на выполнение (4) выбор алгоритма непосредственно никак
не влияет, стоит отметить, что CYK, являясь подвидом табличного парсера,
позволяет максимально быстро определять наличие целого разбора, путём
просмотра содержимого угловой ячейки треугольной таблицы или, в случае
отсутствия такового, путём постепенного спуска выбирать наиболее вероятные
фрагменты развалившегося разбора, обеспечивая выполнение (5).
Разумеется, использование алгоритма CYK приводит к определённым
особенностям, которые можно было бы счесть недостатками, но в нашей
реализации мы попытались превратить их в преимущества. Во-первых,
алгоритм CYK предполагает использование грамматики составляющих, что в
принципе не очень хорошо соотносится с требованием (6). Во-вторых,
грамматика составляющих должна быть представлена в нормальной форме
Хомского, т.е. она должна быть бинарной.
Объединяя эти два аспекта в единую концепцию, мы получаем возможность
в каждом бинарном правиле проставить синтаксическое отношение между его
компонентами (отмечая каждую из двух составляющих каждого правила как
вершину или зависимое), что даёт нам простой и эффективный способ получать
структуру зависимостей автоматически по структуре составляющих. Кроме
того, менее очевидным преимуществом такого подхода является возможность
для каждой составляющей определять такой параметр как «длина связи»,
который в дальнейшем играет немаловажную роль в нашей модели для выбора
правильной структуры.
2.2. Особенности реализации таблицы CYK
Для того чтобы в полной мере воспользоваться преимуществами алгоритма
CYK в плане динамического программирования и для предотвращения
комбинаторного взрыва необходимо разработать специальную модель
представления составляющих, которая бы позволяла объединять «одинаковые»
составляющие, попавшие в одну ячейку таблицы в разное время и путём
применения разных правил в разном порядке. Данная модель будет накладывать
определённые ограничения на возможности описания составляющих в


правилах. Это связано с тем, что мы в нашем подходе отказываемся от
различения внутренних структур составляющих при их сравнении. В нашем
понимании, составляющие могут считать идентичными, если они:
 Покрывают один и тот же диапазон токенов;
 Имеют один и тот же тип (например VP или NP);
 Имеют один и тот же набор граммем и помет;
 Имеют один и тот же токен в качестве вершины.
За выполнение первого условия отвечает сам алгоритм CYK, т.к.
координаты ячейки таблицы определяют собственно начало и длину диапазона
токенов, таким образом, попавшие в одну ячейку составляющие всегда будут
совпадать по диапазону, а попавшие в разные — никогда не совпадут.
Соответственно, получается, что если в одну ячейку таблицы попадают
составляющие, совпадающие по (2) и (3), то они по определению будут
порождать в дальнейшем идентичные синтаксические структуры. Это, в свою
очередь означает, что их можно объединить в одну (что, в свою очередь, как раз
и обеспечивает полиномиальность алгоритма). Под объединением мы в данном
случае понимаем закрепление за одним сочетанием свойств (2) и (3) нескольких
возможных разбиений данной составляющей на две других. Кроме того,
условие (4) необходимо для того, чтобы гарантировать однозначность
зависимого слова для отношения, входящего в составляющую, имеющую
различные разбиения.
Кроме того, ещё одна важная особенность алгоритма CYK состоит в том, что
стандартная схема обхода таблицы для объединения составляющих по
правилам предусматривает поочерёдный обход составляющих по увеличению
длины. Это гарантирует, что когда составляющая включается в состав
родительской, то все возможные парные сочетания её дочерних составляющих
уже включены в её состав. Важность данного свойства будет показана в
следующем разделе.
2.3. Взвешивание составляющих
В конце предыдущего раздела была высказана фундаментальная мысль,
позволяющая нам в дальнейшем эффективно выбирать единственную
правильную структуру: к моменту, когда составляющая включается в состав
родительской, она уже содержит в себе все возможные разбиения на две других
(если, конечно, она не является атомарной). Это означает, что вес составляющей
c может быть определён как вес максимального её разбиения p.
max
Строго говоря, это означает, что мы для каждой составляющей можем
игнорировать все разбиения, которые имеют вес меньше максимального (т.е.
все кроме одной). Получается, что после завершения анализа, выбирая
составляющую с максимальным покрытием и максимальным весом, путём
обхода структуры сверху вниз и выбирая при обходе каждый раз разбиения с
максимальным весом, мы выбираем из множества всевозможных структур одну
единственную, и притом с гарантированно максимальным весом. Таким
образом, нам остаётся решить два задачи:
 Как определять вес разбиения;


Как определять вес атомарной составляющей (полученной из
терминального символа).
В нашей модели мы выбрали следующий подход. Для разбиений вес
считается как сумма трёх компонентов: веса, соответственно, двух
составляющих и вес синтаксической связи между ними:
→
.
Таким образом, главная задача сводится к тому, по каким критериям и как
вычислять вес синтаксической связи.
Что касается взвешивания атомарных составляющих, то, строго говоря,
методика принципиального значения не имеет: все атомарные составляющие
могут получать или один и тот же вес в начале анализа, или получать
индивидуальные веса, соответствующие вероятности появления в тексте леммы,
словоформы или морфологического тега того токена, который является основой
данной составляющей.
2.4. Взвешивание синтаксических связей
Мы плавно перешли в нашем вопросе о выборе единственной правильной
структуре от алгоритма и взвешивания составляющих к взвешиванию
синтаксических связей, т.е. фактически пришли к той модели, которую очень
часто используют в синтаксических анализаторах, использующие грамматики
зависимостей [3; 5]. Мы получили такую модель, в которой нам нужно только
лишь правильно взвесить синтаксические связи, а выбор единственной верной
структуры (в соответствии с весами) будет произведён автоматически. Нам
остаётся лишь описать критерии и механизмы преобразования этих критериев в
компоненты веса синтаксических связей. На сегодняшний день мы используем
следующие критерии:
(1) Длина синтаксической связи;
(2) Тип синтаксической связи;
(3) Лексическая сочетаемость связываемых слов.
По поводу критерия (1) существует обратная зависимость между длиной
между словами и вероятностью наличия синтаксической связи между ними [7]
— чем меньше расстояние между словами, тем больше вероятность, что ни
синтаксически связаны. Критерий (2) позволяет управлять процессом выбора
структуры путём присвоения веса каждому типа связи (путём изменения этих
весов, добавления или удаления типов связей). Критерий (3) позволяет
использовать статистику о лексической сочетаемости слов, для того чтобы
определить, насколько вероятна связь между этими словами. Таким образом,
итоговый вес связи может быть вычислен как:
где wr – это итоговый вес связи, v – это «сырое» значение по критерию (1), а
k — это коэффициент влияния критерия, d (distance — величина, обратная
расстоянию между словами), t (type — вес типа синтаксического отношения) и l
(lexical — вес лексической сочетаемости связываемых слов).
Получается, что критерий (1) условно можно назвать автоматическим (им
нельзя явно управлять), критерий (2) можно назвать экспертным (за счёт него
возможна тонкая настройка), а критерий (3) можно назвать статистическим. При


этом, тонкая настройка всей системы возможно при помощи экспертного
управлениями коэффициентами k, раздельно по каждому критерию.
Именно поэтому мы называем наш подход гибридным, подразумевая, что
вес синтаксической структуры определяется и на основе экспертных, и на
основе статистических данных.
2.5. Оценка лексической сочетаемости
Оценка лексической сочетаемости производится согласно алгоритму,
,
вычисляется базовая
описанному в статье [8]. Для каждой пары слов
мера сочетаемости f (в нашем случае – по критерию взаимной информации,
который показал наилучшие результаты в указанной статье). Затем
∼
, которое оказывается
используется понятие взаимозаменяемости
особенно удобным для пар, которые не встречались в обучающем корпусе:
грубо говоря, две лексемы взаимозаменяемы настолько, насколько совпадают
их контексты. Итоговое значение, характеризующее сочетаемость, описывается
через взвешенное среднее:


3. Оценка метода
3.1. Особенности тестирования
В силу того, что наш синтаксический анализатор находится в стадии
активной разработки, а наша грамматика далека от того, чтобы называться хотя
бы относительно полной, мы решили подойти к составлению тестовой
коллекции с точки зрения того, что наш синтаксический анализатор уже умеет
правильно анализировать. Для данного исследования мы решили ограничиться
только простыми предложениями, длиной не более 150 символов и не
содержащими никаких пунктуационных знаков, кроме кавычек и знаков конца
предложения. По данным критериям был сформирован предварительный
корпус объёмом 1000 предложений, выбранных из Открытого Корпуса. Далее
эти предложения были обработаны нашим анализатором и из них были
отобраны те, которые имели полный разбор, таких оказалось 241 предложение.
Далее мы вручную просматривали полученные структуры и экспертно отбирали
их правильность. Правильных оказалось 74 штуки, из которых и был
сформирован наш тестовый корпус. Это означает, что при текущих настройках
(включено взвешивание по расстоянию и типам связей) наш анализатор на
данном корпусе обеспечивает 100% точность выбора вариантов структуры.
3.2. Наш baseline
Теперь, отключив все механизмы взвешивания синтаксических структур, мы
можем определить наш baseline по точности выбора правильной структуры. Мы
определяем, какой процент структур и синтаксических связей наш анализатор
способен правильно выбрать в качестве единственного варианта, не имея
никаких критериев, т.е. произвольно. Мы получили для произвольного выбора
следующие показатели:
 5,4% точности при выборе целых структур;
 76,6% точности при выборе отдельных связей.
Первый показатель означает, что при произвольном выборе одной целой
структуры из предложенных грамматикой вариантов полное совпадение со
структурой из эталона происходит чуть более чем в пяти случаях из ста. Второй
показатель означает, что более трёх синтаксических связей из четырёх,
содержащихся в выбранной произвольно синтаксической структуре, являются
правильными.
3.3. Оценка различных методов взвешивания
Мы провели серию экспериментов, нацеленных на то, чтобы выяснить,
насколько вырастает наша точность относительно baseline при активации тех
или иных критериев взвешивания синтаксических структур при выборе
варианта.


Точность по целым структурам у baseline крайне низкая, чуть выше 5%, что
означает, что шансов на произвольный выбор правильной структуры
практически нет и для того, чтобы выбирать правильную структуру,
обязательно нужно подключать дополнительные критерии. Такой, казалось бы,
логичный критерий, как длина синтаксической связи, на практике, показывает
себя крайне малоэффективным при самостоятельном использовании —
точность с ним не доходит до 11%, прибавляя к baseline всего лишь 5,4%. Вес
синтаксической связи, напротив, показывает себя как наиболее эффективный
критерий, обеспечивая точность почти в 84%, что не удивительно, т.к. это
основной критерий, которым может управлять разработчик грамматики для
максимизации точности выбора синтаксической структуры. Критерий
лексической сочетаемости проверялся на различных биграммных моделях по
методу, описанному в статье [8] и при помощи инструмента Word2vec. Тем не
менее, модель, полученная при помощи Word2Vec, по приросту превысила
качество модели на длинах синтаксических связей. Более того, причины такого
результата следует анализировать относительно того, насколько в принципе
модель лексической сочетаемости может быть применима для исправления тех
ошибок выбора синтаксической структуры, которые имели место в корпусе.


3.4. Выводы
В рамках нашего исследования мы провели ручную верификацию почти
двух с половиной сотен предложений. Учитывая, что лишь треть из них
расценивалась экспертами как полностью правильные, остальные приходилось
анализировать с точки зрения ошибок синтаксических структур. Мы
обнаружили несколько основных типов ошибок:
(1) Правильный вариант синтаксической связи не описан в грамматике —
таких случаев примерно треть от всех встретившихся ошибок;
(2) Ошибки при присоединении предложных групп — самая
многочисленная категория, примерно половина всех встретившихся у нас
ошибок;
(3) Ошибки в выборе типа синтаксического отношения, не приводящие к
модификации структуры — например, когда прямой объект маркируется
как подлежащее, а подлежащие как прямой объект;
(4) Ошибки в выборе типа синтаксического отношения, приводящие к
изменению структуры — например, в предложении «банкноты прошлого
года» проставляются два генитивных отношения (слово «прошлое»
считается существительным) вместо атрибутивного и генитивного (слово
«прошлое» — прилагательное, определение к слову «год»).
На основе подобранного материала мы провели исследование возможного
использования различных критериев для снятия структурной омонимии.
Следует отметить, что никакой критерий не может нивелировать ошибки типа
(1) — их можно устранить только путём повышения полноты грамматики.
Ошибки типа (3) и (4) могут быть исправлены как при помощи изменения
модели весов синтаксических связей, так и при помощи семантического
анализа, что выходит за рамки данного исследования. Наиболее же частотные
ошибки типа (2) напрямую не могут быть исправлены при помощи критерия
лексической сочетаемости, т.к. под лексической сочетаемостью мы понимали
бинарное отношение, а сочетания с предложными группами состоят из трёх
слов, что требует адаптации статистической модели. Это планируется сделать в
будущем.