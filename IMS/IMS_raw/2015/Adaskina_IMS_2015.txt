Метод полуавтоматической классификации для
данных с несбалансированными классами
Ю.В. Адаскина1, А.М. Попов1,2, П.В. Реброва1,2
1
InfoQubes
2
Санкт-Петербургский государственный университет
1. Введение
Автоматическая классификация текстов при помощи методов машинного
обучения является одной из самых востребованных задач прикладной
лингвистики в последнее время. Для настройки модели с изначально заданными
классами необходимо вручную разметить небольшой фрагмент выборки
документов и на них обучить классификатор. Далее выявленные автоматически
характеристики категорий будут применены к новым документам. Существует
много разновидностей задачи классификации (иерархическая классификация,
классификация, допускающая пересечение классов, классификация с
ранжированием и др.), однако ключевым моментом для работы всех подобных
алгоритмов является наличие качественных тренировочных данных, получение
которых зачастую представляет собой отдельную сложную задачу.



Мы работаем над коммерческим проектом, в основе которого лежит
классификатор на ключевых словах. Подбором ключевых слов для каждой из
категорий, включая категорию «спам», занимается эксперт. Особенность этого
проекта состоит в том, что класс нерелевантных документов, которые
необходимо отсеивать аналитику, не имеет четких критериев. Это, а также
большие объемы поступающих на вход документов делают его работу очень
кропотливой и трудоемкой, поэтому перед нами встала задача снижения
трудозатрат эксперта в работе над улучшением качества классификатора.
Замена такого классификатора на автоматический кажется логичным шагом,
однако в нашем случае классы релевантных и нерелевантных документов не
сбалансированы, и для получение репрезентативной выборки пришлось бы
просматривать и размечать большое количество текстов.
Поэтому для снижения трудозатрат эксперта
мы применили
полуавтоматический метод классификации. За основу был взят алгоритм
пополнения семантических классов, разработанный нами в [1]. Метод в
исходном виде предназначался для сокращения трудозатрат эксперта,
занимающегося подбором лексики. Он предполагает обучение с частичным
привлечением учителя (bootstrapping), то есть итеративное применение
алгоритмов машинного обучения с корректировкой модели на каждом шаге на
основе вновь полученных данных. В результате для того, чтобы получить
достаточно полный словарь терминов персонала из корпуса объемом в 580 000
слов, достаточно было взять два исходных частотных термина и итеративно
просмотреть в общей сложности около 1000 слов, постепенно корректируя
классификатор.
Соответственно, для решения задачи классификации на основе этого метода
мы предлагаем алгоритм с автоматическим ранжированием списка документов
по вероятности их принадлежности к тому или иному классу. Мы предполагаем,
что таким образом возможно построение качественной классификации, и при
этом трудозатраты эксперта будут минимизированы. Раздел 2 нашей статьи
посвящен теоретическим предпосылкам исследования и краткому описанию
работ в этой области. В Разделе 3 изложена основная гипотеза, а Раздел 4
описывает наши эксперименты для ее проверки. В Разделе 5 обсуждаются
выводы и идеи для дальнейшей работы.

2. Предпосылки
Все работы по классификации текстов так или иначе связаны с [2],
посвященной категоризации текстов на основе вероятностей, обзор основных
методов решения задачи классификации представлен в работе [3].
Классификация текстов применяется к широкому спектру практических задач,
например, таких, как каталогизирование новостных статей, классифицирование
веб-страниц, автоматическое классифицирование писем электронной почты по
их содержанию. Очень часто для таких задач используются наивный
байесовский классификатор, метод опорных векторов, использование
максимальной энтропии.



17

В [4] рассматривается проблема автоматической классификации
документов с использованием машинного обучения, в рамках которой нужно
выявлять документы, релевантные для определенной категории.
Метод обучения с частичным привлечением учителя успешно применяется
для задач, где получение размеченного тренировочного корпуса достаточного
объема затруднено или невозможно: см., к примеру, [5] для задачи пополнения
лексических классов, [6] и [7] – для выявления именованных сущностей, [8], [9]
и [10] – для классификации текстов. Как показано в [1], наш алгоритм позволил
достичь приемлемого качества анализа небольшого специализированного
корпуса, состоящего из предварительно не очищенных данных, различных по
их отношению к тематике рассматриваемого семантического класса.
В работе [11] показано, что метод обучения с частичным привлечением
учителя хорошо справляется с задачей повышения точности классификации,
особенно в тех случаях, когда размечено всего несколько документов. Мы
развили эту идею, задействовав итеративный алгоритм дообучения с
использованием вновь размеченных документов.
В [12] предлагается метод ранжирования документов по вероятности
принадлежности к определенному классу – так называемая оценка доверия
(confidence estimate), то есть числовое значение, которое показывает, насколько
верным является принятие решения о принадлежности документа к одному из
классов, а также предлагается мера оценки подобных методов ранжирования.
Использование ранжирования облегчает задачу экспертной верификации автоматической классификации. То есть после того, как алгоритм классификации
отработал, эксперту предоставляется список классифицированных документов,
отсортированный по вероятности их принадлежности к приписанному классу.
Этот метод применим не только к области классификации текстов. Он будет
полезен для любой задачи классификации, в которой присутствует несбалансированность классов. Мы использовали этот подход вместе с итеративным
алгоритмом, что позволило все более эффективно размечать новые документы
на каждой следующей итерации.
Большинство алгоритмов обучения, применяемых для задачи классификации
текстов, по словам авторов, основываются на представлении документа в виде
«мешка слов», однако в работе [13] описывается использование синтаксической
информации в качестве параметров для классификации. В данном эксперименте в
качестве входной информации используются лингвистические модели словосочетаний, то есть та информация, которая и будет извлекаться из тренировочного
корпуса. Затем применялась синтаксическая эвристика для создания лингвистических моделей, которые смогут извлечь нужную информацию из тренировочных и
из неизвестных документов. Извлекались модели следующего типа: subject-verb или
verb-direct-object, или предложные группы. Обучение и классификация
производились при помощи наивного байесовского классификатора и алгоритма,
основанного на правилах. Оценивалось три варианта сочетания параметров:
− только слова;
− только словосочетания;
− и слова, и словосочетания.

18



Эксперимент показал, что использование лингвистических параметров
улучшает точность классификации текста на нижней границе полноты. Тем не
менее, улучшить точность классификатора на высоких уровнях полноты не
удалось, по мнению авторов, из-за того, что параметр словосочетаний обычно
сфокусирован очень узко. Мы решили задействовать имеющийся у нас
синтаксический анализатор на правилах для получения синтаксической
информации о документах, предполагая, что использование синтаксической
информации в качестве параметров для итеративного алгоритма позволит
повысить качество работы алгоритма.

3. Гипотеза
Основное предположение состоит в том, что наш алгоритм обучения с
частичным привлечением учителя позволит существенно снизить трудозатраты
эксперта путем уменьшения необходимого для просмотра количества
документов в процессе настройки классификатора. В основе метода лежит
итеративный алгоритм. Идея состоит в том, чтобы эксперт на каждой итерации
размечал небольшой фрагмент выборки всей выборки (несколько процентов),
после чего происходило бы обучение классификатора с последующей
сортировкой выборки по убыванию вероятности принадлежности документов к
целевому классу. Предполагается, что за несколько итераций подавляющее
большинство релевантных документов окажутся вверху сортированной
выборки, при этом число всех размеченных экспертом документов будет в
несколько раз меньше объема выборки.
Применительно к задаче классификации мы предполагаем, что на нулевом
шаге эксперт самостоятельно размечает небольшое подмножество исходной
выборки, в нашем случае было использовано 40–50 документов, что составляет
7–8% всей выборки. Затем классификатор произведет обучение на данном
фрагменте выборки и отсортирует всю выборку по вероятности принадлежности к целевому классу. После чего эксперт получает список неразмеченных им документов, отсортированный по вероятности их попадания в
класс нерелевантных. На следующей итерации эксперту необходимо будет
разметить еще некоторое количество документов (в нашем случае еще 40–50),
просматривая отсортированный список сверху вниз, после чего обучение и
сортировка повторяются.
Мы предполагаем, что такая модель даст приемлемые результаты
классификации уже при просмотре небольшого числа документов экспертом (в
несколько раз меньше объема выборки). Пользователь системы может
варьировать число итераций и число просмотренных на каждом шаге
документов в зависимости от желаемого критерия качества и наличия времени.
Критериями качества в данном случае мы считаем полноту классификации, а
также коэффициент эффективности, под которым мы понимаем отношение
числа просмотренных документов к общему объему документов. Коэффициент
эффективности метода – отношение полноты классификации к объему
просмотренных документов, то есть мера, соответствующая тому, сколько



19

процентов полноты приходится на каждый процент просмотренных при
использовании данного метода документов.

4. Эксперимент
Для нашего эксперимента было взято множество из 620 документов,
представляющих собой отзывы клиентов международной ритейл-сети. После
процедуры дедупликации осталось 546 уникальных документов. Данные
документы были обработаны нашей системой лингвистического анализа,
которая привела словоформы к нормальной форме и расставила синтаксические
связи между словами. Далее каждый документ при помощи специально
разработанного для этой задачи инструмента был представлен как
неупорядоченное множество параметров, всего мы использовали параметры
трех видов: нормальные формы (униграммы), две подряд идущие нормальные
формы (биграммы) и синтаксические связи (две нормальных формы связанных
друг с другом слов и тип отношения между ними). Мы решили проверить
эффективность совместного использования нескольких видов параметров во
всех возможных комбинациях (комбинации приведены с условными
обозначениями, использующимися ниже в результатах эксперимента):
− L – только леммы (униграммы);
− B – только биграммы;
− R – только синтаксические связи;
− LB – леммы и биграммы;
− LR – леммы и синтаксические связи;
− BR – биграммы и синтаксические связи;
− LBR – леммы, биграммы и синтаксические связи.
Выборка содержала около 10% нерелевантных документов, которые мы для
простоты будем называть «спамом». До начала эксперимента все документы из
категории «спам» были вручную размечены экспертом. Далее сам эксперимент
проводился автоматически, при помощи специально написанного скрипта,
который имитировал действия эксперта. На первой итерации скрипт «размечал»
N документов из выборки в соответствии с разметкой, предоставленной
экспертом, после чего проводил обучение на полученной разметке. Далее на
каждой из последующих итераций скрипт доразмечал еще N документов,
находящихся вверху сортированной выборки в добавление к уже размеченным
ранее документам. На каждой итерации в лог записывались текущие показатели
полноты и эффективности. Эксперимент продолжался до тех пор, пока все
документы не оказывались «просмотренными» программно. Каждый
эксперимент проводился для различного шага N (числа просматриваемых на
каждой итерации документов). Число N варьировало от 20 до 50 с шагом в 15
документов.
Мы использовали классификатор на опорных векторах с линейным ядром
LinearSVC из библиотеки sklearn для языка Python (см. [14]). При помощи
данного классификатора производилось двухклассовое обучение на всех
размеченных на текущей итерации документах, после чего были получены веса
принадлежности к целевому классу «спам» при помощи функции
«decision_function» и сортировка выборки по убыванию данного показателя.

Результаты собраны в несколько таблиц и представлены ниже. Во всех
таблицах и графиках используются условные обозначения, перечисленные в
описании параметров. В столбце «выборка» указывается отношение
просмотренных документов на каждой итерации к объему всей выборки.

Из этой таблицы видно, что для некоторых комбинаций параметров удается
добиться очень высокой полноты уже на небольшом числе итераций, при
просмотре небольшого фрагмента выборки. В частности, наиболее
эффективными оказываются параметры: биграммы (B), связи (R), связи и
биграммы (BR), которые позволяют получить полноту в диапазоне 0,87-0,91
при просмотре менее четверти всей выборки, то есть экономия времени
эксперта составила бы более четырех раз. На графике ниже приведена
зависимость полноты классификации от доли просмотренной выборки для
наиболее эффективных параметров (B, R и BR) вместе с результатом для только
лемм (L) и общего сочетания всех трех видов параметров (LBR). График
наглядно демонстрирует, что, как самостоятельная эффективность лемм, так и
сочетание лемм с другими параметрами, дает существенно более низкие
показатели.
В Таблице 2 приведены аналогичные результаты для выборки с шагом 35.
Видно, что увеличение шага просмотра не сказывается положительно на
эффективности работы: чуть-чуть более низкая полнота, в диапазоне 0,81-0,87,
достигается при чуть более низкой доле просмотренных документов, а такая же
полнота, в диапазоне 0,87-0,91 достигается более высокой долей
просмотренных документов, чем при шаге 20.
Для наглядности приведем также Таблицу 3 с шагом в 50, чтобы
продемонстрировать еще большее снижение эффективности.
Наглядно результаты сравнения эффективности между размерами шагов
представлены на Рис. 2. На графике показаны зависимости полноты от доли
просмотренных документов для параметров связи с шагом 20 (R 20) и связи с
шагом 50 (R 50), а также аналогично для комбинации биграммов и связей в
качестве параметром с шагом 20 (BR 20) и с шагом 50 (BR 50).

Из графика видно, что практически на всем протяжении кривых, кривые
показывающие зависимость на большем шаге, проходят ниже и правее кривых,


показывающих зависимость на меньшем шаге, что наглядно демонстрирует
преимущество использование меньшего шага.

5. Заключение
Полученные результаты подтверждают нашу гипотезу о том, что данный
метод, опробованный нами на задаче пополнения семантических классов,
применим также к задаче классификации документов, когда составление
тренировочного корпуса достаточного объема затруднено. В качестве
параметров классификатора мы брали различные комбинации из лемм, биграмм
и синтаксических связей; наилучший результат классификатор показал при
использовании синтаксических связей изолированно, а также синтаксических
связей с биграммами. Оптимальный прогон позволяет получить полноту
классификации 0,91 уже при просмотре 24% документов, то есть коэффициент
эффективности метода (отношение полноты классификации к объему
просмотренных документов) в таком случае составляет 3,79. Эксперимент
показал, что выбираемый набор параметров для классификации может
оказывать существенное влияние на качественные показатели, как и размер
шага. Выбор размера шага зависит от имеющегося у эксперта времени и
желательной полноты, однако алгоритмы с меньшим шагом дают бόльшую
эффективность. Что касается набора параметров, леммы в качестве параметра
классификации существенно снижают эффективность алгоритма как
изолированно, так и в комбинации с биграммами и синтаксическими связями.
Для дальнейших исследований в качестве параметров предлагается
использовать также семантические теги. Кроме того, представляет интерес
проверка работы этого алгоритма на других данных и для другого типа
классификации: например, для классификации с большим числом классов
возможно последовательное применение нашего метода, если число документов
из этих классов сильно меньше общего объема выборки.

