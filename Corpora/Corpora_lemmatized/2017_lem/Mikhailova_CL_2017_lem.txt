п. л. гроховский, м. о. михайлов автоматизация сегментация и частеречной разметка тибетский текст в ход работа над разметка два корпус тибетский текст (грант ффля № c-47 «базовый корпус тибетский классический язык с русский перевод и лексический база данных» и грант рффи № 13-06-00621 а «пилотный версия электронный корпус тибетский грамматический сочинений») возникнуть необходимость частично автоматизировать дальнейший разметку. разработка программный средство для предварительный автоматический разметка и сегментация тибетский текст осуществляться в рамка грант ргнф 16-0412016 «программный средство автоматический обработка текст на современный тибетский язык (морфологический уровень)». за стандарт разметка и сегментация принять формат корпус грамматический сочинений. это исключать использование разметка по словарь с последующий снятие неоднозначность по правилам, разработать группа британский исследователь [garret et al. 2014] в связь с различие в принцип сегментация и набор тегов. на пример, анализ дать иметься корпус показывает, что части-цы, выделять они как глагольный [garrett 2015: 70], мочь следовать и за токен другой типов. поэтому на основание реальный дать быть принять решение выделять такой частица в отдельный класс, а не относить к глагольный аффиксам. другой отличие — решение объединить в один токен глагольный основа и формообразующий аффикс глагола, поскольку между они ничего невозможно вставить, и обособить аффикс падеж существительное в отдельный токены, поскольку падежный аффикс присоединяться справа к именной группа и мочь быть отдельный от существительное определениями. изначально предполагаться только предварительный автоматический разметка заранее сегментировать текста, поскольку автоматический сегментация тибетский текст мало разработана. инструмент для сегментация текст на язык на база латинский письменности, использовать пробел в качество разделитель слово (например, nltk), не подходить для языка, не содержать никакой графический разделитель слов, даже при уcловие разработка тибетский языковой пакет для них, что теоретически возможно, хотя очень трудоёмко. данный словарь возможно автоматически пополнять при добавление новый разметить текстов, он позволять сортировать и искать дать по любой столбец — например, увидеть подряд всё токен один часть речь или всё токен с один леммой. за предел данный проект этот словарь мочь использоваться как словарь частот, лемма и часть речи, а также для решение комплексный задач, например, для поиск омоним разный часть речь (совпадать написание глагол и существительного) можно делать поиск по пара лемма+тег. общий объём корпусов, по который составить словарь, 91825 токенов, в тот число 9112 уникальный токен и 6111 лемм. второй словарь, который использоваться для токенизация и разметка — словарь форма глагол нейтен хилла [hill 2010], объединять дать несколько ранее создать глагольный словарей. программный средство написать на python 2.7. скрипт присуждать каждый токен лемма (леммы) и тег (теги) и записывать удобный для редактирование и проверка файл .csv, где каждый строка содержать один токен и он атрибуты. для упрощение проверка разметка написать инструмент для поиска, в тот число по любой атрибут или они сочетание и поиск контекста. для сочетаемость с корпус-менеджер написать конвертер табличный файл в вертикальный формат, xml или формат для nltk). так как частичный автоматизация обработка предполагать последующий ручной проверку, программа для разметка должный быть выдавать всё вариант разметки, найти для данный токен в доступный материале, и оставлять неразмеченный всё новый токен — при разметка только по изначальный словарь они составлять около 16 %. после успешный проведение эксперимент по автоматический сегментация основный режим работа стать одновременный вы-полнение сегментация и разметка неподготовленный текста, так как это значительно сокращать работа лингвиста. сегментация построить следующий образом. полностью обрабатываться каждый строка входящий текстовый файл по отдельности. она разбиваться на графический слог по разделитель слог tsheg. если после это строка быть слишком длинный (более 20 слогов) — использоваться генератор подстрок, который разбивать длинный строка на фрагмент по знак препинание (вертикальный черта shad и пробел) и передавать для разбор этот фрагмент по одному. далее такой фрагмент разбиваться на единицы, подходящий для поиск по словарю. на этот стадия от слогов, содержать только буква тибетский алфа-вита, отделяться знак препинание и цифры, обособляться элементы, который не отделяться от предыдущий слог графически, но являться отдельный морфемами: падежный аффикс 7, финитный частица о, вопросительный частица am и глагольный аффикс ang. затем каждый строка в вид список такой единица передаваться в функцию, который осуществлять по словарь поиск последовательность максимальный длины. это важно для тибетский языка, где почти всё буква мочь формировать отдельный слог и слово. после окончание сегментация и разметка скрипт выводить на печать общий количество токенов, количество разметить токенов, количество неразмеченный токен и время, затратить на обработку. при наличие уже сегментировать текст возможно также отдельно использовать функция разметки, без одновременный сегментации. анализ лакуна и ошибка сегментация и разметка выявить следующий проблемы, послужить основный направление доработка системы. во-первых, недостаточный полнота словаря. этот недостаток исправляться по мера пополнение словаря, но лишь частично: с добавление в словарь весь материал из корпус текст общий содержания, то есть, увеличение материал почти в три раз относительно изначальный объёма, количество неразмеченный токен сократиться весь на 5 %, до 11 %. во-вторых, многие ошибка относиться к открытый класс словоформа с очень больший варьирование (числительные, цифры, форма глаголов), образование который который можно описать правилами. введение система такой правило сократить количество неопознанный токен до 7 %. этот правило использоваться на стадия поиск возможный комбинация слог в словаре. использоваться следующий правила: • выделение форма глаголов: скрипт объединять глагольный основа (только основы, найти в словарь с тег “v”) с глагольный аффикс из списка, и присуждать такой словоформа тег в зависимость от аффикса, что позволять опознать и разметить даже тот форма глаголов, который не встретиться в существующий корпус и поэтому отсутствовать в словаре. словарь аффикс и тег составить по грамматический корпусу. • выделение число как непрерывный последовательность латин-ский или тибетский цифр. • выделение количественный числительное как единиц, состоять только из слогов, который образовать числительные, по список возможный составляющих. этот список взять из монография [beyer 1992: 221-226] и включать в себя как числа, так и специфический для тибетский язык разделитель разрядов. • выделение порядковый числительное как токенов, который на конец иметь тибетский аффикс -pa, а весь предшествовать часть который являться количественный числительным. • выделение сократить форма падежей: для два падеж (терминатив и эргатива) после гласный использоваться сократить формы. они особенность в том, что они сокращаться до один буква (‘r’ и ‘s’ соответственно) и встраиваться в предшествовать графический слог. отделить в самостоятельный токен всё ‘r’ и ‘s’ нельзя, так как такой случай гораздо меньше, чем случаев, когда этот согласный являться финаль токена, поэтому при поиск последовательностей, оканчиваться на этот согласные, также проверяться наличие в словарь этот последовательность без последний буквы. если она есть, то выделяться два токена: найти в словарь последовательность и падежный аффикс. система быть протестировать на корпус из 8 тибетский текст научный стиль общий объём 55 533 токена, 52 539 (94 %) токен быть разметить и 2994 (6 %) — нет. точность (precision) и полнота (recall) совпадать в предел округления. при тестирование только разметка на эталонный сегментация процент неразмеченный токен составить 6,2 %, строгий точность 45 % (только один вариант разметка и он верный), нестрогий 92,3 % (наличие несколько вариант разметки, в тот число правильного), неправильно разметить 1,5 % токенов. некоторый часть неразмеченный фрагмент оказаться результат ошибка в текстах. при тестирование на тот же текст после очистка от такой ошибок, количество неразмеченный токен сократиться на 0,7 % (до 5,5 %), это примерно 240 токен на весь корпус. при одновременный выполнение сегментация и разметка f-мера разметка при строгий оценка составлять 46 %, при нестрогий — 85 %, 7 % токен не размечено, f-мера сегментация составить 88 %. что касаться скорость разметки, то сегментация и разметка сам большой текста, который быть сегментировать в ход работа над это проект — 20 тысяча токен в автоматически разметить вариант — обрабатываться примерно два секунды. работа только в режим разметка (переть уже сделать человек сегментации) требовать маленький времени: сам разметка занимать 0.1 секунда для тот же текста.