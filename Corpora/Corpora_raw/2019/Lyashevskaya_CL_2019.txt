О. Н. Ляшевская
МОДЕЛЬ UDPIPE ДЛЯ ЛЕКСИКО-ГРАММАТИЧЕСКОЙ РАЗМЕТКИ РУССКОЯЗЫЧНЫХ ТЕКСТОВ НА ОСНОВЕ БОЛЬШОГО СВОДНОГО КОРПУСА СО СНЯТОЙ НЕОДНОЗНАЧНОСТЬЮ  
1. Введение
Русский язык нельзя назвать малоресурсным языком с точки зрения доступности средств автоматического анализа. В разное время разрабатывались как анализаторы, основанные на грамматическом словаре и правилах, так и инструменты, созданные с помощью обучения на размеченных корпусах, ср., например, Mystem, Starling, Dialing/AOT, Pymorphy, MorphoBabushka, русскоязычные модели TreeTagger, SVMTagger, MarMoT, UDpipe, TurkuNLP и мн. др.  Проводятся соревнования теггеров на русскоязычных текстах (Ru-Eval 2010, MorphoRuEval-2017, CONLL-2018), имеются удобные онлайн-инструменты разметки (например, Mystem+, Ru-Syntax) и библиотеки для языков программирования.
В последнее время усилия сообщества сосредоточены в основном на развитии нейросетевых архитектур и репрезентации данных в них [Anastasyev 2018]. Вместе с тем, наблюдается такая тенденция: с ростом качества дизамбигуации неоднозначных грамматических разборов с учетом контекста, с ростом точности определения несловарных (недоступных в обучении) словоформ качество лемматизации не улучшается, а скорее падает. Связано это с тем, что популярные общедоступные статистические модели обучены на корпусах объемом не более 1 млн. словоупотреблений (таких как UD_Russian-SynTagRus, корпус, де факто ставший стандартом для обучения большинства нейросетевых таггеров) и без использования встроенного большого словаря. Кроме того, разработчики и сообщество обращают самое большое внимание на качество определения части речи, в меньшей степени ориентируются на точность определения грамматических значений, а задача определения леммы часто не ставится вовсе. В результате, в практических задачах разметки больших коллекций новых текстов анализаторы показывают неожиданно низкий результат – ср., например, разметку и лемматизацию низкочастотных слов в сервисе RusVectores. 
Настоящая статья посвящена разработке русской модели разметчика UDPipe [Straka et al. 2016], основанной на большом (big) обучающем корпусе. Мы выбрали инструмент UDPipe, поскольку он прост в обучении (см. тьюториал http://wiki.apertium.org/wiki/UDPipe), работает со стандартом разметки Universal Dependencies (UD) [McDonald et al. 2013] и с форматом CONLL-U (а также с несколькими другими входными форматами), обладает модульной структурой (морфологический анализатор UDPipe встроен в пайплайн от сегментации предложений до синтаксической разметки). Кроме того, UDPipe был выбран в качестве официального ориентира (baseline) в соревнованиях по мультиязычной обработке текстов CONLL 2017 и 2018 гг. Разметка собранных данных для обучения UDPipe была переведена в тагсет UD и уницифирована на уровне лексических классов, чему посвящены следующие разделы статьи.
2. Обучающие и тестовые данные
Преследуя идею оценить вклад объема обучающих данных (при сохранении стандартного алгоритма) в улучшение качества лексико-грамматической разметки текстов, мы поставили задачу составить сводный корпус, более чем в 10 раз превосходящий стандартные миллионные корпуса (SynTagRus, RNC-Open). Это может быть достигнуто за счет использования открытых и закрытых корпусных ресурсов, а также за счет комбинирования доступных ресурсов с «золотой» (прошедшей двойной ручной контроль), «серебряной» (полуручной, часто с контролем параллельных ответов нескольких систем) и «бронзовой» (полностью автоматической) разметкой.
Наш сводный корпус получен из нескольких источников. 
1. Открытая коллекция соревнования MorphoRuEval [Lyashevskaya et al. 2017], включающая:
●	SynTagRus, около 0,9 млн с/у, жанры: художественная литература и новости;
●	RNC Open: открытый корпус НКРЯ, 1,35 млн с/у, жанры: художественная литература, новости, публицистика, устные тексты, блоги;
●	OpenCorpora.org, около 0,4 млн с/у, жанры: новости, тексты Википедии, научные публикации, блоги;
●	подкорпус ГИКРЯ, 1 млн с/у, жанры: блоги и тексты социальных сетей.
2. Другие открытые корпуса Universal Dependencies [Droganova et al. 2018], в т. ч.:
●	GSD (90 тыс с/у), корпус Google на основе выборки предложений из Википедии;
●	PUD (16 тыс с/у), русская часть параллельного корпуса UD на основе переводных предложений из Википедии;
●	UD-Taiga (25 тыс с/у), корпус, состоящий из текстов соцсетей, поэзии, новостей.
3. Большой корпус НКРЯ со снятой омонимией (закрытая коллекция, 5 млн с/у, дополнение к RNC-Open), в основном тексты художественной литературы и non-fiction.
4. Поэтический корпус НКРЯ (закрытая коллекция, 8 млн с/у).
С точки зрения качества исходной разметки, сводный корпус представляет собой континуум, от безусловно «золотой» в корпусе SynTagRus (неоднократная ручная проверка, исходно - разметка ETAP3) до «серебряной» в подкорпусе ГИКРЯ (полуручная проверка разборов ABBYY Compreno). Разметка в корпусе PUD и Поэтическом корпусе является «золотой» в плане лемматизации и определения части речи, и «серебряной» в плане определения грамматических помет. Кроме того, нужно учитывать, что разметка может подвергаться искажениям при конвертации в унифицированный стандарт. «Расстояние» между исходной и унифицированной разметкой для корпусов SynTagRus, OpenCorpora, Taiga оказывается разным. 
3. Унификация разметки в Universal Dependencies (UD)
Оригинальная разметка в перечисленных корпусах находится под большим влиянием традиции Грамматического словаря русского языка [Зализняк 2003], однако она отличается в деталях. В частности, разметка НКРЯ детализирована под выполнение теоретических  исследований (ср. пометы «вторых» падежей), некоторые решения SynTagRus  мотивированы проблематикой машинного перевода, а в разметке OpenCorpora, например, выделяются как отдельные части речи краткие прилагательные, компаративы, инфинитивы, деепричастия и т. п. 
Мультиязычный инвентарь UD 2.0 включает 17 помет частей речи, в том числе помету знаков пунктуации, а также 23 пометы грамматических категорий. В русской коллекции UD 6 из этих грамматических категорий не используются (Polite(ness), Clusivity, Evident(iality), Definite(ness), PronType, NumType), но зато включена одна языково-специальная категория для разметки полных и кратких адъективных форм. В 2017 году коллекция MorphoRuEval была сконвертирована в так называемую упрощенную схему UD для русского языка. В частности, она предусматривала игнорирование таких помет, как вид, переходность, залог, одушевленность, объединение частей речи VERB и AUX (вспомогательный глагол), CCONJ и SCONJ (сочинительный и подчинительный союз), SYM и X (символы и некатегоризованные слова). 
Поскольку для нас важнее применение модели в практических задачах, а не чисто экспериментальная оценка качества обработки языка, мы разработали, напротив, расширенную схему UD, в которой различаются все частеречные и 19 обязательных грамматических категорий UD, релевантных для русского языка (включая PronType, NumType), а также категории, имеющие эквиваленты в стандарте НКРЯ: Variant, NounType, NumForm (тип записи числительного), Abbr (аббревиатура или сокращение), Typo (опечатка или порча). Используются также более дробные, чем в универсальном наборе UD 2.0, значения категорий, такие как вторая сравнительная степень, см. табл. 1. По нашей идее, пользователю легче удалить или переименовать нерелевантные для его задачи пометы, нежели добавлять в разметку новые.
Расширенная схема UD в целом представляет собой компромисс между инвентарями помет НКРЯ и UD 2.0. Не различаются как отдельные части речи местоименные наречия и предикативы (ср. [Зализняк 2003]), числительные-прилагательные (кодируются как ADJ, NumType=Ord), предикативы (ср. ADJ, AdjType=Predic), вводные слова (ср. ADV, AdvType=Parenth). В Таблица 1. Грамматические категории и их значения в расширенном стандарте UD (пометы, входящие в универсальный набор UD 2.0, выделены жирным).
Категория	Значения	Части речи
AdjType	Predic	ADJ
AdvType	Parenth	ADV
Animacy	Anim, Inan	NOUN, PROPN, PRON, NUM, ADJ, DET, VERB, AUX
Aspect	Imp, Perf	VERB
Case	Nom, Gen, Gen2, Dat, Acc, Acc2, Ins, Loc, Loc2, Voc, Adnum	NOUN, PROPN, PRON, NUM, ADJ, DET, VERB, AUX
Degree	Pos, Cmp, Cmp2, Sup	ADJ, ADV
Gender	Masc, Fem, Neut, Com	NOUN, PROPN, PRON, NUM, ADJ, DET, VERB, AUX
Mood	Ind, Imp, Imp2	VERB, AUX
NounType	Persn, Patrn, Famn, Zoon, Topon, Ethn, Org, Trad, Init	NOUN, PROPN
Number	Sing, Plur	NOUN, PROPN, PRON, ADJ, DET, VERB, AUX
NumForm	Digit, Word	ADJ, NUM
NumType	Card, Ord, Sets	NUM, ADJ
Person	1, 2, 3	PRON, VERB, AUX
Poss	Yes	ADJ, DET
PronType	Dem, Ind, Int, Neg, Prs, Rel, Tot	PRON
Reflex	Yes	PRON
Tense	Pres, Past, Fut	VERB, AUX
VerbForm	Fin, Inf, Part, Conv	VERB, AUX
Variant	Long, Short	ADJ, VERB, AUX
Voice	Act, Pass, Mid	VERB, AUX
_	Категории, не допускающие грамматических помет:
ADP, CCONJ, SCONJ, INTJ, PART, SYM, X, PUNCT
Доп. пометы	Abbr=Yes, Typo=Yes
Пометы историче-
ских форм	Number=Dual, Tense=Aor, Tense=Imp, VerbForm=
PartRes, VerbForm=Sup, Clitic=Yes, NumForm=Cyril
отношении других корпусов конверсия потребовала объединения классов (например, причастий и деепричастий в один класс с глаголами), разбиения классов (например, компаративы были разделены на прилагательные и наречия), а также привлечения дополнительных словарей, например, для обеспечения согласия в разметке прилагательных и прилагательных-местоимений и лемматизации видовых форм глаголов.
4. Размер обучающих данных и качество разметки
Табл. 2 представляет результаты разметки. В качестве тестового корпуса был взят UD-Taiga, остальные данные использовались для обучения. Как видно, увеличение объема обучающих данных значительно улучшает качество лемматизации, однако прирост в качестве грамматической разметки не столь заметен, что может быть связано с ошибками в разметке ГИКРЯ и Поэтического корпуса. На конференции мы планируем представить более развернутые результаты, показывающие зависимость точности разметки от жанра текста, а также обсудить результаты эксперимента с включением в обучение данных словарей.
Таблица 2. Сравнение качества разметки (accuracy).
Модель	Часть речи	Грам. признаки	Лемма
SynTagRus (1 млн)	93,2	92,4	86,5
UD-Extended (15 млн)	94,1	92,8	92,7
