Б. Ньеки
ИЗВЛЕЧЕНИЕ ПРОИЗВОДНЫХ СЛОВ ИЗ КОРПУСОВ: СБОР ДАННЫХ ДЛЯ ИССЛЕДОВАНИЯ НЕМЕЦКИХ ДИМИНУТИВОВ
1. Сбор корпусных данных для исследования словообразовательной системы языка
1.1. Основная идея
Использование современных электронных корпусов может способствовать исследованиям, посвященным словообразованию. Операторы поиска позволяют быстро находить токены по аффиксам. После фильтрации результатов пользователь может сохранить ценный материал – совокупность предложений, содержащих производные слова выбранного типа. К ним можно добавить лингвистическую разметку, отсутствующую в корпусе.
В настоящем докладе рассматриваются преимущества сбора производных слов из корпусов (1.2.–1.3.), а также излагаются методы извлечения, фильтрации и дополнительной разметки диминутивов на –chen (отыменные существительные среднего рода, как например: Töchterchen ’доченька’, Mützchen ’шапочка’ и т.п.) из корпуса немецкого языка DWDS (2.1.–2.3.). Основные результаты эксперимента, основанного на этих методах, указаны в разделе 3.
1.2. Изучение продуктивности
Продуктивность словообразовательного правила рассматривается с точки зрения корпусной лингвистики Х. Байеном [Baayen 2009]. Он выделяет три показателя продуктивности, основанных на статистической характеристике. Первый показатель – реализованная продуктивность, которая характеризуется количеством изучаемых производных слов в корпусе известного объема. Показатель продуктивности по мере распространения – это доля исследуемых дериватов среди всех неологизмов в корпусе. Количество токенов, встречающихся один раз в корпусе (hapax legomena), считается Х. Байеном приближенным значением частоты неологизмов. Похожим образом оценивается потенциальная продуктивность, вычисляемая делением количества hapax legomena, образованных данным правилом, на частоту всех производных того же типа.
Совершенно ясно, что только потенциальную продуктивность можно оценить с опорой исключительно на извлеченные из корпуса предложения, содержащие дериваты. Однако их частотная характеристика является важной информацией для приблизительного вычисления остальных показателей продуктивности.
Значение продуктивности для компьютерной лингвистики заключается в том, что с помощью продуктивного правила образуются неологизмы, отсутствующие в словаре морфологического анализатора. Поэтому, как рекомендует В.П. Захаров [2016], целесообразно включить продуктивный аффикс в словарь анализатора. 
1.3. Автоматическое выделение морфем
В настоящий момент существуют алгоритмы, обеспечивающие процесс автоматического разбиения слова на морфемы. Morpho project (http://morpho.aalto.fi/projects/morpho/) предлагает алгоритмы, основанные на машинном обучении без учителя. Например, в [Creutz, Lagus 2002] излагается метод создания лексикона морфем на основе неразмеченного обучающего текста (Morfessor Baseline), а в [Creutz, Lagus 2005] – более развитый вариант алгоритма, учитывающий частоты морфем в обучающем тексте. Одна из реализаций алгоритмов проекта – пакет Polyglot (https://polyglot.readthedocs.io/en/latest/#). Для обучения программы, разбивающей текст на морфемы, были использованы списки 50 тыс. самых частотных слов разных языков. Нетрудно убедиться в том, что Polyglot разбирает некоторые дериваты заметно хуже, чем другие слова. Например, немецкие диминутивы на –lein обычно анализируются неправильно, сам суффикс разбивается на –lei и –n. Это, наверное, объясняется тем, что в словарях или в списках самых частотных слов редко встречаются диминутивына –lein. Возможно, использование множества извлеченных из корпуса разных дериватов с контекстом в качестве обучающего текста улучшило бы разборы.
2. Опыт извлечения диминутивов на –chen из корпуса немецкого языка
2.1. Выбор корпуса
Эксперимент извлечения диминутивов на –chen (или –chens в родительном падеже единственного числа) из корпуса немецкого языка носит иллюстративный характер: предполагается, что изложенные ниже методы применимы к сбору данных обо всех словообразовательных правилах, реализующихся суффиксацией.
Выбор корпуса – нетривиальный шаг в ходе эксперимента. Если целью исследования является обобщенное представление некоего словообразовательного типа, то корпус, из которого извлекаются результаты, должен быть репрезентативен и сбалансирован.
Самый большой электронный корпус немецкого языка – это DeReKo (Deutsches Referenzkorpus, http://www1.ids-mannheim.de/kl/projekte/korpora/). В 2018 году корпус содержал приблизительно 42 млрд токенов. Главная проблема данного корпуса – неравномерная репрезентация разных жанров. Ядро корпуса – публицистические тексты, хотя к корпусу постоянно добавляются тексты, что повышает сбалансированность распределения жанров.
Для того чтобы провести эксперимент, удобнее было пользоваться другим корпусом немецкого языка – DWDS (Digitales Wörterbuch der deutschen Sprache, https://www.dwds.de/). Объем основного корпуса (Kernkorpus), содержащего тексты 20-го века, составляет 120 млн токенов. Преимущество основного корпуса в том, что в нем сбалансированно представлены 4 жанра – художественные, публицистические, научные и другие нехудожественные тексты (см. доли: https://www.dwds.de/d/k-referenz#kern).
Для поиска диминутивов были выбраны десятилетие 1990-1999 гг. и полный корпус 21-го века (Kernkorpus 21), в состав которого входят тексты, появившиеся не позднее 2006 года. Сбалансированность источника диминутивов могло нарушить то, в последнем корпусе (Kernkorpus 21) жанры представлены неравномерно. Диминутивы из устных корпусов еще не были включены в эксперимент.
2.2. Фильтрация результатов
На сайте DWDS нельзя задать такой поисковой запрос, который полностью устранил бы шум в выдаче. Можно заранее исключить из результатов лишь некоторые частотные существительные, оканчивающиеся на –chen, но не являющиеся диминутивами.
Дальнейшая фильтрация осуществлялась с помощью обратного словаря [Mater 1970]. Из словаря были выбраны те существительные, которые имеют хотя бы одну словоформу, оканчивающуюся на –chen, но сами не являются диминутивами, например: Tisch ’стол’ → Tischen (д.п. м.ч.), Flasche ’бутылка’ → Flaschen (любой падеж м.ч.). Эти словоформы и также диминутивы, потерявшие композициональность значения (Mädchen ’девочка’, Stiefmütterchen ’анютины глазки’, Tastkörperchen ’тактильное нервное тельце’ и т.п.), были добавлены в общий список стоп-слов. Если ключевое слово результата корпусного поиска, экспортированного в формате csv, совпало с любым элементом списка, то данный результат (целое предложение) был удален. Учитывались и частичные совпадения по последним символам ключевого слова ввиду возможных сложных слов. После этого частеречный анализатор TreeTagger присвоил некоторый тег каждому ключевому слову с переведенными в нижний регистр символами. Если оно получило не тег существительного, содержащее его предложение было удалено из результатов. Таким образом, удалось отфильтровать такие слова, как Suchen ’поиски’ Glücklichen ’счастливый человек/счастливые люди’ (в косвенном падеже или в и.п. м.ч.). Это субстантивированные формы, поэтому частеречная разметка корпуса не могла их исключить. Некоторые инфинитивные формы были включены в список стоп-слов, поскольку субстантивированные инфинитивы иногда выступают в качестве компонента сложного существительного, например, Sportmachen ’занятие спортом’.
После фильтрации из 30 593 результата осталось 4174.
2.3. Восстановление леммы мотивирующего слова
Лингвисту, изучающему производные слова, часто приходится прибегать к мотивирующим словам: встречаются ли они без исследуемого аффикса, и если да, сколько раз, в каких контекстах и т.д. Поэтому целесообразно добавить в лингвистическую разметку информацию о лемме мотивирующего слова (т.е. практически об основе, к которой применяется деривационное правило), которая сделала бы возможным быстрый доступ к его токенам.
Даже безупречная морфемная сегментация не может решить задачу в силу возможности появления алломорфов. Однако для немецких дериватов можно написать правила восстановления мотивирующего слова. Эти правила требуют лингвистических знаний. Например, свойства образования диминутивов с суффиксом –chen описаны в [Fleischer, Barz 2012]. Алгоритм восстановления мотивирующего слова должен опираться на сведения об алломорфах (расширенных формах) суффикса, выпадении букв с конца основы при суффиксации и других изменений основы.
Итак, программа сначала строит список гипотетических основ без внутренних изменений. Выделяются три алломорфа суффикса: –chen, –elchen, –erchen (последние встречаются в таких дериватах, как Blümelchen ’цветочек’ от Blume, Prösterchen ’чоканье’ от Prost). Если диминутив d, состоящий из n символов, оканчивается на –elchen или –erchen, то порождаются следующие гипотетические формы: d до n-6 символа, d до n-6 символа + e, d до n-6 символа + en, d до n-4 символа. Вторая и третья формы нужны ввиду того, что при суффиксации безударные –е и –en выпадают в конце основы. Однако нет необходимости добавить в список еще вариант «d до n-4 символа + e/en», поскольку буквосочетания –ele/ –ere в конце слова нетипичны для немецких существительных. Если диминутив оканчивается на –chen, но не на –elchen или –erchen, то создаются гипотезы d до n-4 символа, d до n-4 символа + e, d до n-4 символа + en. Гипотетические формы упорядочены: например, «d до n-4 символа» чаще приводит к правильной основе, чем «d до n-4 символа + en»; эта форма применима к большему количеству основ, поэтому она получает более высокий ранг. Потом символы ä, ö, ü внутри порожденных форм заменяются на регулярные выражения (ä|a), (ö|o), (ü|u), таким образом устраняются проблемы, связанные с явлением «umlaut». 
Проверка наличия гипотетических форм в словаре часто приводила бы к отрицательному результату ввиду весьма продуктивного словосложения существительных в немецком языке. Поэтому программа на каждом шагу цикла добавляет к последнему символу гипотетической формы один символ слева, пока полностью не будет восстановлена данная форма. Наличие строки среди заглавных слов словаря постоянно проверяется. Если соответствующее заглавное слово найдено в словаре, программа сохраняет его, потом продолжается конкатенация. После этих операций выбирается сохраненное слово с максимальным рангом. Если таких слов несколько, то из них выбирается самое длинное. Наконец, оно добавляется к левой, несовпадающей части гипотетической формы (в идеальном случае эта часть представляет собой пустую строку). Получившаяся последовательность символов считается леммой мотивирующего слова. Если ни одно заглавное слово словаря в ходе выполнения алгоритма не было идентифицировано, то мотивирующим словом считается гипотеза «d до n-4 символа». 
Итак, например, имея диминутив Pferdefigürchen ’фигурка лошади’, можно восстановить мотивирующее слово Pferdefigur, даже если в словаре нет заглавного слова Pferdefigur, только Figur.
В качестве словаря в эксперименте был использован частотный список словоформ корпуса DeReKo 2014 г. (http://www1.ids-mannheim.de/kl/projekte/methoden/derewo.html, дата обращения: 13.03.2019). Для каждой словоформы указаны лемма и часть речи. После объединения словоформ, относящихся к одной и той же лемме, список содержал более чем 37 тыс. существительных. 
Мотивирующие слова были разбиты на морфемы с помощью пакета Polyglot.
3. Результаты эксперимента
В рамках эксперимента было получено 4174 ключевых слова в контексте одного предложения. Токены дериватов относятся к 1330 разным леммам. 473 из них встречаются более чем один раз. 5 самых частотных лемм – Päckchen ’небольшой пакет/пачка’ (122 раза), Städtchen ’городок’ (73 раза), Kästchen ’ящичек’ (71 раз), Stückchen ’кусочек/небольшая часть’ (66 раз), Fläschen ’бутылочка’ (63 раза). Каждое ключевое слово размечено следующими сведениями: лемма, мотивирующее слово и его морфемный разбор. Для оценки качества методов, изложенных в предыдущих разделах, были взяты две выборки объемом 100 и 200 результатов. Более чем 80% ключевых слов действительно оказались диминутивами. Приблизительно в 75% случаев лемма мотивирующего слова была восстановлена правильно (если ключевое слово не было диминутивом, результат выполнения данного алгоритма считался ошибочным). Полнота извлечения диминутивов из экспортированных материалов DWDS (30 593 результата) составляет примерно 90%. Естественно, некоторые диминутивы были искючены вследствие случайного совпадения их последних символов с каким-либо стоп-словом, поэтому нельзя было ожидать стопроцентной полноты. Значение F1-меры, вычисленное по показателям точности и полноты, — 0,847.
4. Заключение
В перспективе планируются совершенствование методов фильтрации и восстановления леммы мотивирующего слова и вовлечение в исследование DeReKo и устных корпусов. Добавление семантических признаков к разметке результатов также представляется целесообразным. Созданная таким образом совокупность дериватов могла бы служить базой для морфологического и семантического исследования словообразовательных правил.