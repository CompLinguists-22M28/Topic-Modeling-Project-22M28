ШАБЛОНЫ ДЛЯ АВТОМАТИЧЕСКОГО ПОИСКА
ОШИБОК В ИМЕННЫХ И ГЛАГОЛЬНЫХ ГРУППАХ (АНАЛИЗ КОРПУСА УЧЕНИЧЕСКИХ ТЕКСТОВ)
1. Проблемы разметки корпуса ученических текстов
Учебные корпусы (Learner Corpora), или корпусы ученических текстов, с самого начала задумывались как база для извлечения информации об ошибках в речи на иностранном (L3) или втором (L2) языке. Отличительной особенностью таких корпусов является то, что при их обработке приходится иметь дело с ненормализованными текстами, что делает автоматическую (и не только) разметку текста весьма проблематичной. Поскольку именно извлечение информации об отклонениях от нормы является основной задачей строительства таких корпусов, приоритет способа и типа их разметки представляется очевидным [Hirschmann 2009]. 
Собственно разметкой ошибок располагают единичные корпусы. Наиболее удачным до сих пор можно считать такой вариант, когда учебный корпус представляет собой коллекцию ошибок, предварительно распределенных (размеченных) по классам [Соснина 2006]. Однако разметка в полнотекстовом учебном корпусе, таком как SPbEFL LC , сопряжена с рядом трудностей, связанных с тем, что определить ошибку однозначно часто не представляется возможным: в одной словоформе могут быть обнаружены орфографические, грамматические, лексические и другие нарушения. Известны положительные опыты разметки ошибок, в том числе основанной на многоуровневой архитектуре [Hana et al. 2010, Hirschmann 2009 и др.], благодаря которой уровни разметки могут постоянно добавляться при сохранении ранее полученных данных.
Очевидно, что разметка ошибок в корпусах подобных SPbEFL должна осуществляться вручную с привлечением экспертной оценки, что даже в рамках таких малых корпусов представляется весьма трудоемкой и долгой работой. Естественно желание облегчить эту работу с помощью инструментов разметки. 
Для этого необходимо, во-первых, подобрать инструмент автоматической морфологической разметки с максимальным «иммунитетом» к многочисленным и непредсказуемым ошибкам, во-вторых, определить процедуры автоматического извлечения ошибок, которые позволили бы классифицировать ошибки и создать таксономию тегов для их последующей разметки. 
2. Выбор морфологизатора для ненормализованных текстов корпуса 
В результате нескольких проб, наш выбор остановился на хорошо известном морфологическом анализаторе на платформе Natural Language Toolkit (NLTK) [Bird et al. 2010]. Предварительно обработанные тексты (по условиям инструмента) подвергаются токенизации и, затем, собственно морфологическому анализу (по алгоритму униграмм), при котором каждому токену приписывается частеречная и грамматическая характеристика в виде тэга.
Результаты работы анализатора NLTK с текстами корпуса в целом можно признать удовлетворительными, хотя ручная проверка выдачи позволила обнаружить ряд ошибок (разрешение омонимии в пользу наиболее частотного значения в словарной базе инструмента, отнесение местоимений к классу детерминативов даже в отсутствие именной группы и др.).
В целом, морфологизатор дает достаточно точную грамматическую характеристику словоформе, игнорируя большинство ошибок. Это позволяет надеяться, что после ручной коррекции, в размеченном корпусе можно будет извлекать информацию, например, обо всех именных и глагольных лексемах в заданном окружении.
3. Определение контекстов и разработка шаблонов для извлечения ошибок в ИГ и ГГ в текстах корпуса 
Большое количество грамматических ошибок у авторов корпуса встречается в области детерминации имени и образования глагольных форм. Поэтому извлечение из текстов именных (ИГ) и глагольных групп (ГГ) могло бы ускорить обнаружение и разметку ошибок в рамках этих категорий. Для этого необходимо было найти или создать инструмент, генерирующий отчеты по заданным морфологическим и контекстным параметрам. Алгоритм для решения этой задачи был разработан на языке Python и применен к анализу корпуса, предварительно размеченного с помощью анализатора NLTK.
ИГ в текстах корпуса имеют достаточно простую структуру, Помимо ядра-существительного в состав ИГ входят детерминатив, который может быть выражен артиклем или местоимением (указательным, неопределенным и др.), и возможный модификатор, который в текстах школьников чаще всего выражен прилагательным, реже существительное имеет при себе два модификатора. Поэтому максимальное левое окружение ядерного существительного задается в программе 3 токенами: для детерминатива и двух определений. Таким образом, в качестве контекста для извлечения ИГ используется четырехкомпонентная n-грамма, четвертая позиция которой задается тегами для существительного (NN, NNS , NP, NPS, NR, NRS)
Алгоритм извлечения ИГ, разработанный по заданным параметрам на языке Python, в результате предоставляет выдачу существительных в их ближайшем контексте (см. рис. 1).
Установленный таким образом контекст достаточен для определения ошибок на согласование по числу (become a real [friends], without this pretty [creatures]), пропуск артикля (or people without [friend], do not have [opportunity]). Если для определения ошибки контекст недостаточен, его можно увеличивать рядом изменений в коде программы. 
Аналогичным образом определялись контексты для извлечения ГГ, в качестве ядра контекста рассматривались определяемые морфологизатором глагольные формы разных функциональных классов (связки, знаменательные глаголы, модальные глаголы).
Анализ полученных контекстов позволил выделить некоторые группы ошибок, дальнейший поиск которых можно автоматизировать с помощью создания шаблонов. Шаблон представляет собой заданный набор тегов и позволяет автоматически находить определенный тип ошибки. Например, в ГГ для случаев типа Does ('DOZ') this stuff has ('HVZ') something bad in it? шаблон имеет следующий вид:
if (tokens [i][1]='DOS' or tokens [i][1]='DO') and (tokens[i+2][1]='VBZ' or tokens [i+2][1]='HVZ' or tokens [i+3][1]='VBZ' or tokens [i+3][1]='HVZ'...)
В качестве условия для программы поиска ошибок этот шаблон будет искать все случаи совместного употребления вспомогательного и знаменательного глагола в 3 л. ед. ч. в вопросительном предложении на расстоянии до трех токенов (для группы подлежащего). Классу выделенных таким образом ошибок возможно в дальнейшем автоматически приписать общий тег.
Примером шаблона для поиска ошибок в ИГ может служить набор тегов, описывающих стандартную ошибку по несогласованию числа существительного и его детерминатива (become a real [friends], without this pretty [creatures]):
if token [i][0]='DT' and (token [i+1][1]='NNS' or token [i+1][1]='NPS' or token [i+2][1]="NNS' or token [i+2][1]='NPS'...), который будет искать все случаи нарушения согласования существительного и его детерминатива по числу на расстоянии до двух токенов с возможностью автоматически приписать тег данной ошибки.
4. Заключение
Выбор морфологического анализатора на платформе NLTK для разметки ненормализованных текстов корпуса оказался удачным, поскольку он малочувствителен к ошибкам в текстах корпуса, его результаты достаточно точны и сокращают усилия на ручную коррекцию.
Предварительный анализ текстов и разработанный в ходе исследования алгоритм позволил задать (на основе тегов размеченного корпуса) и автоматически извлечь минимальные контексты для выявления классов ошибок в ИГ и ГГ.
Для каждого класса ошибок возможно задать шаблон в виде заданного набора тегов, который позволяет извлечь из корпуса все ошибки данного класса. Результатом поиска по шаблонам может стать последующая автоматическая разметка ошибок.
Первые полученные результаты внушают некоторый оптимизм в осуществлении автоматической разметки ошибок в корпусе ученических текстов, однако следует признать ограниченность наших выводов областью ИГ и ГГ. 
