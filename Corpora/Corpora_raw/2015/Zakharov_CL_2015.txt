ОЦЕНКА КАЧЕСТВА ИНТЕРНЕТ-КОРПУСОВ 
РУССКОГО ЯЗЫКА
1. Введение
Корпусная лингвистика имеет уже свою историю. На протяжении примерно трех десятилетий она сформировала свою теорию и методологию, в центре которых стоят вопросы разметки, репрезентативности, сбалансированности. По-другому, применительно к корпусам, репрезентативность и сбалансированность можно назвать количеством и качеством. В современном понимании объем минимально репрезентативного корпуса должен насчитывать не менее 100 млн словоупотреблений. Многие национальные корпуса сегодня превзошли эту границу. Много это или мало, 100 млн словоупотреблений? Возникает ответный вопрос, для чего? Для того чтобы вычислить частотное распределение букв и буквосочетаний в русскоязычных текстах этого даже много. 
Если под репрезентативностью понимать объем, то опыт работы автора с корпусами говорит о том, что во многих случаях объем Национальный корпус русского языка (НКРЯ) (http://ruscorpora.ru) (основной корпус 230 млн словоупотреблений) оказывается недостаточным для получения полноценных достоверных данных. Этого мало, как правило, для словосочетаний. Такой объем совершенно не подходит и для диахронических исследований. Так, если сочетание «громкие аплодисменты» в НКРЯ встретились по одному разу в 1885, 1906, 1908, 1910, 1925, 1939-40, 1959, 1963, 1998-2000, 2003 гг. и два – в 2001 г., то трудно делать какие-либо умозаключения на основе такого ничтожного количества данных. Коллокации и коллигации для среднечастотных и низкочастотных слов реально изучать только на миллиардных корпусах. 
Еще сложнее обстоит дело со сбалансированностью. Во многом, корпусная лингвистика формулировала понятие сбалансированности и задавала «баланс» «на ощупь». На первых этапах этот баланс имел «крен» в сторону художественной литературы, что можно объяснить влиянием лексикографии толковых словарей. Но главное, что это многомерная величина, где трудно сформулировать векторное пространство – основания для пропорции данных внутри корпуса – и задать саму пропорцию.
2. Web as Corpus
Создание корпусов процесс очень трудоемкий и не очень быстрый, и как только была осознана потребность в корпусах большого объема, стало ясно, что потребности лингвистов и возможности корпусной лингвистики сильно расходятся. Поэтому многие лингвисты за решением своих задач обращаются к вебу, задавая запросы на языке поисковых систем в сети Интернет. Но использование поисковых систем как корпусных инструментов связано со многими проблемами (см. их перечень и анализ в [Беликов и др. 2012: 42–44]).
Тогда родилась идея формирования корпусов на основе текстов из веба. Вероятно, первым ее явно сформулировал Адам Килгаррифф [Kilgarriff, Grefenstette 2003]. Вскоре эта идея «овладела массами» и появились первые корпуса, созданные по технологии, получившей обобщенное название wacky (The Web-As-Corpus Kool Yinitiative) или BootCaT (bootstrap specialized corpora and terms from the web) (см. материалы семинаров https://sigwac.org.uk/). Эта технология позволяют сравнительно быстро и без больших трудозатрат создавать корпуса объемом несколько десятков миллиардов токенов. 
Однако исследования, проведенные на основе wacky-корпусов показали, что все не так просто. Их проблемы можно подразделить на 3 части: проблемы лингвистической разметки, метаразметки и технические проблемы, связанные с удалением дублей, элементов гипертекстовых языков разметки веб-документов и т.п. Проблемы, которые мы условно назвали проблемами метаразметки, в отличие от традиционных корпусов, выглядят перевернутыми с ног на голову. Там мы имеем документы, которые надо разметить, в новой технологии же перед нами стоит задача отобрать документы, соответствующие заданным элементам метаразметки. Но нужно оговориться, что полноценная традиционная метаразметка (в терминах TEI) по отношению к веб-документам неприложима. На практике мы получаем корпуса с минимальной метаразметкой в терминах веба (домен или доменное имя, дата помещения на сайт или дата формирования корпуса, длина документа и др.), и, следовательно, сказать о их сбалансированности в терминологии традиционных корпусов ничего нельзя. То есть, мы получаем корпуса большого объема, но встает вопрос их качества.
Новые подходы к созданию корпусов на базе веба были заявлены и реализуются в проекте под названием Генеральный интернет-корпус русского языка [Беликов и др. 2012].
Как характер текстового материала, так и несбалансированность таких корпусов остро ставят вопрос об оценке достоверности полученных результатов. Проблема верификации и достоверности данных, получаемых на основе статистических методов на базе корпусов, это не только проблема создания больших корпусов, но и проблема хороших, сбалансированных и правильно интерпретируемых корпусных данных. Покажем эти проблемы на нескольких примерах.
3. Некоторые проблемы Интернет-корпусов
3.1. Материал и инструмент исследования
В качестве материала и инструмента исследования были использованы Национальный корпус русского языка (НКРЯ) (230 млн слов) (http://ruscorpora.ru), корпус русских текстов ruTenTen 2011 системы Sketch Engine (18 млрд. токенов) (https://the.sketchengine.co.uk/), корпуса русских текстов из семейства псевдопараллельных корпусов Aranea Университета им. А. Коменского в Братиславе (http://ucts.uniba.sk/). 
Система псевдопараллельных корпусов Aranea (A Family of Comparable Gigaword Web Corpora) для 18 языков представлена корпусами двух типов, созданными по технологии wacky: Maius (1200 млн токенов; как правило, из этого числа около 1000 млн токенов представляют собой слова, или в другой терминологии, текстоформы) и Minus (120 млн токенов, чуть более 90 млн текстоформ). Для некоторых языков имеются региональные варианты, в т.ч. и для русскоязычных корпусов, которых шесть: Araneum Russicum Maius & Minus (русский универсальный), Araneum Russicum Russicum Maius & Minus (русский на основе текстов с сайтов с доменом .ru), Araneum Russicum Externum Maius & Minus (русский на основе текстов с доменами, отличными от домена .ru). Подробнее см. [Benko 2013]. 
Анализ корпусов позволяет выделить ряд проблем, с ними связанных, из которых мы остановимся на двух.
3.2. Нераспознанные слова
Тексты, взятые из Интернета,  с большой долей вероятности содержит разного рода недостатки, влияющие в том числе и на качество лемматизации и морфологического анализа, и на качество лингвистического анализа: опечатки, орфографические вариации, ошибки капитализации, слова из других (похожих) языков, обрывки слов (часто из-за переноса), имена собственные, экспрессивная лексика, новые слова, которые не удается правильно лемматизировать (например, слушаю-с, хрюкмены, щаcкакдам, приве-е-ет, вылысыпыдыстко, иоаннутый, та-а-ак, триногометрия, советобоязнь, нью-вэйв, Архнадзор и т.п.).
Частотный словарь в корпусе ruTenTen насчитывает более десяти миллионов слов, в корпусе Araneum Russicum Maius – порядка 5 млн слов. Понятно, что там представлены и ошибочные слова, и нелемматизированные словоформы и мн. др. Вот примеры из такого словаря , точнее, того, что мы имеем на выходе из морфологического анализатора TreeTagger с частотами  из корпуса Araneum Russicum Maius. 
На основе корпуса Araneum Russicum Minus для 1000 наиболее частотных слов, для которых лемма не распознана, была составлена сравнительно небольшая статистика. 
Среди нелемматизированных слов мы видим неологизмы, сленг, а также новые слова, образованные с помошью разных префиксоидов. Их неполный список, составленный нами, насчитывает около 400 единиц. Для каждого префиксоида из этого списка была подсчитана абсолютная частота и ipm по Национальному корпусу русского языка и по корпусу Araneum Russicum Maius.  Была составлена сводная таблица, и каждому префиксоиду присвоен ранг в обоих корпусах. Видна разница, в корпусе Araneum бóльшую частоту имеют такие префиксоиды, как «Интернет-», «веб-», «евро» и т.д. 
3.3. Сбалансированность
Особенность wacky-корпусов заключается в том, что они получаются путем неуправляемого кроллинга русскоязычного интернета, и мы ничего не можем сказать об их сбалансированности. Более того, обсуждать проблему сбалансированности в терминах жанров и регистров тяжело, ибо не только отсутствует жанровая метаразметка в веб-документах, но и само понятие жанра применительно к ним должно быть изменено.
Тем не менее мы попытались, сравнивая словари Интернет-корпусов со словарем НКРЯ, выявить корреляцию между ними. В качестве словника НКРЯ мы брали Новый частотный словарь русского языка [Ляшевская, Шаров 2009], составленный на данных НКРЯ объемом 109 млн словоупотрблений. Для этого была написана программа , которая отбирает подмножество двух словарей и вычисляет коэффициент корреляции по трем мерам. Параметры для отбора лексических единиц следующие: значение ipm или ранг, часть речи (если требуется) и объем подкорпуса (количество слов). Вот некоторые результаты (табл. 1, 2).
Далее была предпринята попытка (пока вручную) вычислить корреляцию между корпусами Aranea и подкорпусами НКРЯ, как они отражены в [Ляшевская, Шаров 2009]. По рангам двух словарей рассчитывался коэффициент Спирмена по 50 самым частотным существительным и глаголам в Araneum Russicum Minus. Результаты сравнения представлены на рис. 1. 
Мы видим, что и для существительных, и для глаголов коэффициент корреляции выше всего для публицистического подкорпуса. Для глаголов очень близко к нему значение по подкорпусу другой нехудожественной литературы, но по нему самый низкий коэффициент для существительных. Возможно, это связано с тем, что этот подкорпус просто очень разнородный.
Рис. 1. Корреляция между корпусами Aranea и НКРЯ 
4. Заключение
В работе описаны проблемы современной корпусной лингвистики. Можно сказать, что корпусы стали неотъемлемой частью инструментария лингвиста, с другой стороны, приходит понимание, что нужны новые методы и подходы. Одно из активно развиваемых направлений – создание корпусов большого объема на основе текстов из веба.
Не касаясь всего комплекса проблем, мы коснулись некоторых особенностей таких корпусов, которые ставят вопросы как перед разработчиками корпусов, так и перед пользователями – это качество текстов веб-документов и проблема сбалансированности создаваемых корпусов.
