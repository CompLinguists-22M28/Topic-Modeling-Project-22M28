А. Н. Чевелева, Э. С. Клышинский
АВТОМАТИЧЕСКОЕ ИЗВЛЕЧЕНИЕ КОНСТРУКЦИЙ
ДЛЯ ПОВЕРХНОСТНОГО СИНТАКСИЧЕСКОГО АНАЛИЗА
1. Введение

Одним из вариантов проведения синтаксического анализа текста
является предварительный поиск синтаксически связанных групп соседних слов (выделение синтаксических фрагментов текста, chunking)
[Кудинов 2013]. В некоторых случаях подобный поиск может не принимать во внимание синтаксических связей между словами [Смирнов и др. 2013]. В случае, когда синтаксические связи не нужны, речь
обычно идет о выделении терминов, описываемых определенными
синтаксическими конструкциями (см., например, [Большакова и др.
2007]), именованных сущностей, извлечении фактов и решении похожих на них задач [Molina et al. 2002]. В случае определения синтаксических связей речь идет о поверхностном синтаксическом анализе.
Среди прочего, проведение поверхностного синтаксического анализа позволяет ускорить работу полного синтаксического анализа, сократив количество анализируемых единиц и снизив синтаксическую
неоднозначность текста. Подобный подход был популярен в начале
2000-х годов (см., например, [Ножов 2003]), однако введение нейросетевых подходов отодвинуло его на второй план. Предложенные в рамках данного подхода методы все еще остаются актуальными, но для
их практического применения должно быть соблюдено несколько условий: точность выделения фрагментов должна превышать точность
работы существующих решений; применение результатов этапа выделения фрагментов должно повышать скорость работы системы.
Для проведения поверхностного синтаксического анализа могут
использоваться различные методы. Так, в [Molina et al. 2002] используются скрытые Марковские модели, в [Кудинов 2013] — условные
случайные поля, в [Большакова и др. 2007] — контекстно-свободные
грамматики, а в [Смирнов и др. 2013] упоминаются как конечные автоматы, так и различные методы машинного обучения. Упомянутые
методы можно разделить на две группы: эмпирические методы и методы машинного обучения. В работе [Ножов 2003] для выделения
именных групп используются конечные автоматы, обладающие высокой скоростью работы. Однако создание подобных автоматов требует длительного ручного труда по поиску кандидатов в извлекаемые
конструкции. Методы машинного обучения не всегда показывают сопоставимую точность и работают с меньшей скоростью, однако сами
выделяют конструкции из размеченного корпуса, обеспечивая большую полноту.
Мы предлагаем метод автоматического выделения шаблонов для
анализа фрагментов текста, обладающих синтаксически однозначной
структурой, на основании статистической информации из синтаксически размеченных корпусов русского языка. Одной из задач являлось
определение доли текстов, которые могут быть подвергнуты подобному анализу.
2. Метод выделения фрагментов с однозначными связями

На начальном этапе мы разбиваем синтаксически размеченный
корпус на предложения и извлекаем из них частеречные 3- и 4-граммы
с информацией о номере родительской вершины для каждого слова.
При этом мы не рассматриваем опущенные слова (empty nodes), а также исключаем из числа n-грамм иностранные слова, так как они не
несут практической пользы. В оставшихся n-граммах номера вершин
назначаются относительно начала выбранного окна. Для слов, вершина которых оказалась снаружи n-граммы, постулируется отсутствие
внутренней связи. В результате полученные конструкции можно
представить в виде строки POS1, #host1, …, POSn, #hostn, total_entries,
где POSi, #hosti — часть речи и номер родительской вершины i-го слова n-граммы, а total_entries — число вхождений каждой конструкции
в корпус. Синтаксические связи рассматриваются как направленные
не помеченные.
Очевидно, что даже в частотных конструкциях внутренние связи при поверхностном синтаксическом анализе могут определяться
неоднозначно. Например, для частотной конструкции «существительное, прилагательное, существительное» синтаксические связи не
определяются однозначно: последнее существительное может как относиться к первому существительному (обострение холодной войны),
так и иметь родительскую вершину снаружи ((не представляет для)
власти особой проблемы). С другой стороны, неверно утверждать, что
среди менее частотных конструкций не найдется удачных: так, связь
частицы и наречия в шаблоне ADP, PART, ADV (В не менее (правильных
советских фильмах)) определяется однозначно.
Для решения этой проблемы мы продублируем n-грамму несколько раз, оставив в каждой только одну связь, и сгруппируем строки
по списку частей речи. Для каждой такой n-граммы с одной связью
рассчитывается ее суммарное число вхождений. После этого во всех
общих конструкциях рассматриваем все слова в отдельности: вычисляются количество конструкций с данным подчинением и доля этого
подчинения среди общего числа подобных n-грамм.
Финальный этап состоял в отборе относительно частотных конструкции (50 и более вхождений), используя которые мы будем
определять связь правильно с вероятностью не менее 0,97. Уровень
50 вхождений выбран исходя из эмпирических соображений, точность 0,97 выбрана с тем, чтобы конкурировать с современными
синтаксическими анализаторами, UAS которых достигает 0,96 (см.,
например, https://spacy.io/models/ru). В список 3-грамм, подходящих
для поверхностного синтаксического анализа, отбираются те, что
подходят по данным критериям. Далее из списка 4-грамм удаляются те, что являются расширением контекста справа и слева для уже
отобранных 3-грамм (считаем, что этот контекст избыточен). Затем
каждая из 3-грамм, не прошедших порог, дополняется контекстом
справа. Получившиеся 4-граммы с точностью ниже 0,97 удаляются.
Из оставшихся к удачным 3-граммам добавляются те 4-граммы, которые встретились 50 и более раз. Аналогичная процедура расширения
проводится для левого контекста. Наконец, из оставшихся 4-грамм,
не являющихся расширением контекста для каких-либо 3-грамм,
отбираем прошедшие установленный порог по доле и числу вхождений.
3. Анализ результатов

Эксперименты проводились с синтаксически размеченным корпусом SynTagRus в формате деревьев зависимостей Universal Dependencies
(https://universaldependencies.org/) с добавлением маркеров начала
и конца предложений. Размер корпуса превышает 1,1 миллиона словоупотреблений. После начального этапа мы получили 10 821 3-грамму и 75 126 4-грамм. После обобщений и отбора было выделено
109 3-грамм и 347 4-грамм (из них 7 и 45, соответственно, содержали
маркеры начала и конца предложения). Суммарно удачные 3-граммы
встретились в тексте более 146 000 раз, 4-граммы — более 153 000. Это
означает, что вместе они покрывают около 27,2 % синтаксических связей корпуса (добавление маркеров начала и конца предложения увеличивает покрытие на 4,7 %). Заметим, что подобная оценка покрытия
является оценкой сверху, так как 3- и 4-граммы могут накладываться
друг на друга. Если считать все 3-граммы, которые имеют два общих
слова в начале и в конце, за совпадения, необходимо сократить нижнюю границу примерно на 16 000 вхождений. Для 4-грамм снижение
покрытия может составить около 50 000 вхождений. Таким образом,
нижняя граница покрытия может быть оценена в 21,7 %.
Наиболее частотными оказались 3-граммы, связанные с определением связи прилагательного или определителя с существительным
в именной и предложных группах: прилагательное/определитель и существительное, перед которыми находится предлог, еще одно существительное, глагол, еще одно прилагательное, определитель или число (например, в последнее время, (при) помощи специального канала,
говорит организатор конференции). Подобные конструкции описаны,
например, в [Кобзарева 2007], и их корректность с заданным уровнем
точности не вызывает сомнений. Еще одной частотной конструкцией
стало подчинение прилагательного существительному, стоящему перед союзом (молодой человек и). Предлог подчиняется стоящему после
него существительному, личному местоимению или имени собственному, если после них идут глагол, наречие, союз, знак препинания
и некоторые другие части речи (через месяц после, в комнату вошел,
на улицу и).
Среди прочих были выделены такие редкие конструкции, как
вспомогательный глагол, подчиняющийся прилагательному (трудно
было понять), или союз, подчиняющийся глаголу через другой глагол
(и стал смотреть).
Среди 4-грамм самой частотной оказалась зависимость предлога
от существительного через прилагательное, когда перед ними стоят
еще одно прилагательное, предлог или существительное, глагол, некоторые другие части речи (знакомой до последней трещинки, сказку
в новый год), или когда после них находятся союз, частица, знак препинания или другие части речи (по ценным бумагам и). Из низкочастотных конструкций неожиданно была извлечена конструкция «глагол,
прилагательное, существительное, существительное», в которой последнее существительное зависит от первого (измерять абсолютную
сложность заданий).
Наш метод не определил связь первого предлога и существительного как надежную, так как более 3 % случаев приходится на конструкции с составными предлогами или устоявшимися словосочетаниями:
по глубокому снегу, но (Несмотря) на свойственную возрасту (впечатлительность).
Исходные коды программного обеспечения для получения статистики, а также результаты расчетов приведены в репозитории https://
github.com/ancheveleva/grampatterns/
4. Обсуждение результатов

Как было показано выше, от 21,7 % до 27,2 % синтаксических связей
в русском тексте может быть восстановлено с использованием только
информации о части речи слов. Заметим, что покрытие может быть
увеличено за счет снижения требований к частоте встречаемости конструкций (их частоты распределены по закону Ципфа и имеют характерный «тяжелый хвост») или добавления 5- и 6-грамм. При этом мы
соблюдаем начальное условие, по которому конструкции должны быть
корректными для 97 % примеров, в которых они встречаются (с точностью до корректности разметки корпуса). Расширение до грамматических параметров должно повысить долю правильных ответов, например, при соединении прилагательных и существительных, но, как показали наши эксперименты, не является обязательным. Заметим, что
точность работы метода зависит от точности предшествующего ему
этапа снятия омонимии. Метод не сможет давать точные ответы без
хорошего разрешения частеречной неоднозначности, но не так чувствителен к неоднозначности леммы или грамматических параметров.
Представленные результаты могут использоваться для разработки методов поверхностного синтаксического анализа или извлечения
синтаксически связанных словосочетаний (например, [Klyshinsky
2018]). Метод выгодно отличается от существующих тем, что позволяет автоматически извлечь всех кандидатов, избегая ручного поиска.