О. В. Донина
АВТОМАТИЗАЦИЯ ВЫГРУЗКИ РЕЗУЛЬТАТОВ ПОИСКА
В КОРПУСАХ ЧЕТВЕРТОГО ПОКОЛЕНИЯ
1. Корпусы четвертого поколения: новые возможности
и новые трудности

Т. Макэнери и Э. Харди были выделены четыре поколения корпусных программных средств [McEnery et al. 2012], и хотя большинство
современных инструментов корпусной лингвистики относится ими
к третьему поколению, корпусная система М. Дэвиса (https://www.
english-corpora.org/) рассматривается как инструмент четвертого поколения, позволяющий работать с большими объемами данных, в связи с размещением базы данных на веб-сервере и предварительной индексации материала. На момент написания статьи объемы корпусов
М. Дэвиса варьируются от 100 млн до 14 млрд слов, что, с одной стороны, предоставляет широкие возможности для лингвистических исследований, но, с другой, обуславливает временные затраты на выгрузку
результатов поиска в корпусах. Так, например, формулировка поискового запроса и перенос 1000 примеров выдачи результатов поиска
из корпуса в таблицу формата .xls(x) для последующего лингвистического анализа занимает в среднем 25 минут. Учитывая объемы корпусов, результаты выдачи могут исчисляться сотнями тысяч. Наиболее
простым решением данной проблемы, связанной с трудоемкостью,
может являться ограничение материала исследования первой тысячей
контекстов поисковой выдачи, что, на наш взгляд, может привести
к ограничению и нашего лингвистического знания. В связи с этим целью данной работы является предложить способ автоматизации выгрузки результатов поиска, который, во-первых, позволит сэкономить
время исследователей, а во-вторых, даст возможность изучать лингвистический материал во всей его полноте.
Разработка загрузчика, необходимого для сбора данных из лингвистических корпусов, происходила на базе корпуса NOW (Newspapers
on the Web) [Davies 2016], содержащего 12,2 млрд словоупотреблений
в двадцати государственных вариантах английского языка и пополняющегося на 4 млн слов ежедневно.
2. Способы автоматизации выгрузки поисковых запросов

Наиболее распространенный вариант выгрузки данных с различных сайтов — через API. Как было выяснено при общении с командой М. Дэвиса, публичный API у них отсутствует в связи с необходимостью минимизации нагрузки на сервер. При этом они поощряют
создание другими исследователями полуавтоматической выгрузки запросов (но технической поддержки для этого не предоставляют). В качестве альтернативных вариантов были предложены:
1) приобретение групповой подписки (стоимость: 300$ за 1 год для
доступа 30 человек); нам этот вариант не подходит, так как групповая подписка только увеличивает количество ежедневных запросов, но функционал остается прежним, доступна только
ручная выгрузка;
2) приобретение ограниченных архивных версий корпусов (стоимость одного корпуса варьируется от 245$ до 795$); и хотя
в этом случае появляется возможность автоматизировать необходимые корпусные запросы, стоимость оказывается довольно
высокой, и, кроме того, эта опция не предполагает получения
обновлений, что неприемлемо при работе с корпусом NOW, который обновляется каждый день.
В качестве альтернативного варианта была рассмотрена возможность использования Macro Recorders (таких, как Auto Mouse Clicker, EasyClicks Macros, TinyTasks, Mouse Record Premium, Macro Toolworks,
Mini Mouse Macro, Ghost Mouse, AutoHotkey), которые запоминают
движения мышью и нажатия клавиш клавиатуры (аналогично записи макросов) и повторяют их. В этом случае можно было бы вводить исследуемые лингвистические единицы в поля поиска вручную,
а процесс копирования контекстов из корпуса в файл .xls(x) формата записать при помощи этой программы в виде последовательности
действий и запускать этот процесс необходимое количество раз. Но
в связи с полуавтоматическим характером этого процесса и только относительным его упрощением было принято решение отказаться от
этого варианта.
3. Постраничная выгрузка результатов поискового запроса

В итоге наиболее соответствующим нашим задачам и материалу
способом автоматизации сбора информации была признана постраничная выгрузка из корпуса (по сути, Web Scraping, т. е. сбор данных
в сети, их последующая очистка и извлечение требующейся информации). Рассмотрим процесс реализации постраничной выгрузки
из корпуса NOW.
Подход состоял в том, чтобы запрограммировать действия, производимые пользователем самостоятельно при ручной выгрузке. Для
этого в «Инструментах разработчика» браузера были изучены запросы к серверу и получаемые ответы. Программируемые этапы имитации действий пользователя при ручной выгрузке и используемые инструменты отражены на рис. 1. Стоит отметить, что при реализации
проекта было решено использовать универсальный мультипарадигменный скриптовый язык программирования Python, что, в первую
очередь, обусловлено наличием большого количества библиотек для
решения разнообразных задач (в том числе связанных с автоматической обработкой естественного языка). Далее рассмотрим имитируемые этапы подробнее.
Первым этапом выступает эмуляция запросов к серверу, состоящая в свою очередь из трех запросов:
• Запрос ключа сессии (эмулирует вход пользователя на сайт),
• Ввод необходимых для выгрузки данных,
• Получение соответствующих запросу примеров.
Изначально для всех трех запросов использовалась библиотека
requests_html для работы с HTTP, которая по сути является усовершенствованной версией разработанной ранее для аналогичных целей
библиотеки urllib2. Библиотека requests_html позволяет выполнять запросы к серверу, обрабатывать его ответы и выгружать содержимое
веб-страниц для последующего парсинга в виде HTML. Но при использовании данной библиотеки возникла проблема, заключающаяся
в том, что сервер возвращал данные в формате, отличном от того, что
есть на сайте. Было принято решение использовать беззаголовочный
браузер pyppeteer (headless chrome browser automation library), способный эмулировать работу браузера. До недавнего времени для решения
подобных задач требовалось прибегать к использованию таких проектов, как PhantomJS. С появлением беззаголовочных браузеров появилась возможность визуализировать и анализировать веб-страницы без
использования пользовательского интерфейса (UI — user interface),
получая тот же результат, что и в традиционном режиме с UI. Пионером в области автоматизации действий веб-браузера и удаленного
управления браузером считается инструмент Selenium, разработанный на Java. Pyppeteer же, позволяющий управлять браузером из кода
Python с помощью относительно простого и высокоуровневого API,
можно рассматривать как современную альтернативу использованию
традиционного Selenium. Pyppeteer позволяет получить практически полный контроль над браузером Chrome, в том числе открывать
вкладки, в реальном времени анализировать объектную модель документа (DOM), выполнять Javascript и многое другое. В связи с тем, что
в рамках решения нашей задачи не было очевидно, на каком именно
запросе возникают проблемы, мы пробовали использовать данную
библиотеку для всех трех запросов. Опытным путем было показано,
что возникающая проблема связана с первым запросом. Таким образом, в итоговой версии кода для получения ключа сессии (т. е. при первом запросе) теперь используется беззаголовочный браузер pyppeteer,
а для второго и третьего запросов продолжает применяться библиотека requests_html (из-за простоты использования).
На втором этапе для извлечения требующихся данных с вебстраниц использовалась библиотека для XML/HTML-парсинга
BeautifulSoup, которая, согласно информации разработчиков, способна преобразовывать даже неправильную разметку (tag soup), откуда
и получила свое название (с этой точки зрения BeautifulSoup считается
надежнее, чем ее более оперативно работающий аналог lxml). Несмотря на то, что, согласно документации, библиотека BeautifulSoup способна определять местоположение закрывающихся тегов даже при их
отсутствии, в процессе работы у нас возникла именно такая проблема:
тег Font открывался, но не закрывался. В связи с этим, чтобы убрать
невалидные элементы HTML, которые мешали парсингу BeautifulSoup,
мы использовали регулярные выражения, удалив все теги Font.
На последнем этапе для выгрузки данных в формате .xls(x) мы воспользовались библиотекой для обработки и моделирования данных —
pandas. Несмотря на то, что данная библиотека предоставляет множество способов анализа данных (в том числе: группировка, создание
сводных таблиц, визуализация при помощи графиков (при наличии
matplotlib) и многое другое), для решения нашей задачи была актуальна возможность чтения и записи всех самых распространенных
форматов данных (например, файлов .xls(x), HTML, SQL, .txt и пр.),
а также наличие объекта табличной структуры данных DataFrame, т. е.
проиндексированного многомерного массива значений.
4. Результаты

В результате выполнения данного кода мы получаем файл формата
.xls(x) (рис. 2), содержащий данные, аналогичные результатам, отражающимся во вкладке Context корпуса NOW, но в табличном формате,
позволяющем проводить дальнейший лингвистический анализ. Возможности выдачи корпуса в выгружаемом нами формате ограничены
контекстом из 30 слов во избежание нарушения авторских прав.
Стоит отметить масштабируемость данного подхода, который мы
в дальнейшем планируем применять для остальных корпусов Марка
Дэвиса, с которыми мы работаем (COCA, GloWbE, iWeb).