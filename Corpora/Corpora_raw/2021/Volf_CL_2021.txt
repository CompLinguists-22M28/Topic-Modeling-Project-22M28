Е. А. Вольф, Ю. О. Короткова, К. И. Семенов
АВТОМАТИЧЕСКАЯ РАЗМЕТКА ЗАИМСТВОВАНИЙ
ИЗ РУССКОГО ЯЗЫКА В КИТАЙСКИХ ТЕКСТАХ:
ПРОБЛЕМЫ СЛОВОДЕЛЕНИЯ И МОРФОПАРСИНГА
1. Введение

Задачи токенизации и морфологической разметки китайских текстов связаны с рядом трудностей в области орфографии, фонетики
и морфосинтаксиса. Все вышеперечисленные проблемы усугубляются
в случае, если в тексте присутствуют заимствованные слова.
С набором этих проблем столкнулась команда разработчиков Русско-китайского параллельного корпуса НКРЯ (далее — ruzhcorp). Несмотря на то, что на текущий момент ruzhcorp обладает несколькими
уровнями разметки для китайских текстов, в том числе разделением
на слова (далее — CWS, от Chinese word segmentation), все они представляют собой достаточно примитивные алгоритмы, выдающие много ошибок при обработке заимствований.
В настоящей статье мы представляем два исследования по улучшению текущего положения дел в разметке китайских текстов в ruzhcorp:
экспериментальную работу в области словоделения (Раздел 2) и PoSтэггинга (Раздел 3).
2. Исследования в области словоделения
2.1. Обзор стандартов и алгоритмов CWS
и экспериментального набора данных

В китайском языке отсутствует кодифицированный набор иероглифов, регулярно используемых при транслитерации заимствований. Более того, в китайской орфографии практически не существует маркеров, указывающих на начало или конец последовательности
символов, которые необходимо читать «фонетически», игнорируя семантику иероглифов. Таким образом, одна и та же комбинация полнозначных китайских иероглифов может быть распознана и как набор
несущих смысл китайских морфем, и как набор знаков, передающих
только звучание.
Учитывая, что в ruzhcorp присутствуют как тексты, содержащие заимствования из русского языка в больших количествах, так и тексты
большого размера, состоящие исключительно из «стандартных» китайских слов (например, китайская литература XX в.), задача CWS для
корпуса распадается на два блока: во-первых, качественное разделение
«стандартного» (т. е. не содержащего заимствований) китайского текста на слова; во-вторых, максимально корректное выделение фонетических заимствований. Для решения обеих задач мы сравнили качество ведущих алгоритмов CWS в области выделения заимствований.
В настоящий момент существует несколько популярных стандартов CWS, при этом ни один из них не является общепринятым ни
в науке, ни в NLP. Стандарты словоделения могут принципиально различаться, так как они берут за основу различные аспекты и уровни
языковой структуры — семантику, морфосинтаксис или лексику. Более того, для большинства этих стандартов существует более одной их
реализации. В нашем исследовании было использовано 17 алгоритмов
и их вариантов. Краткое описание каждого стандарта словоделения
и реализующих его алгоритмов представлено в табл. 1.


Цель нашего исследования — определить наилучший алгоритм
CWS из вышеперечисленных, который будет оптимально справляться
с выделением заимствований из русского языка. Для проверки качества алгоритмов мы создали датасеты, состоящие из 408 предложений
из художественной литературы и 87 предложений из текстов СМИ,
в которых содержались заимствования.
Исследование качества алгоритмов CWS на наших данных включает как количественный, так и качественный их анализ. В силу ограничений по формату мы вынуждены представить здесь лишь наши
соображения относительно качественного анализа; подробное описание количественного анализа представлено в [Семенов и др. 2021].
Отметим лишь, что наиболее эффективными оказались нейросетевые
алгоритмы fastHan (в особенности на стандарте CTB), LTP и PKUSeg,
дающие качество 80–95 % на каждом датасете.
2.2. Сравнение алгоритмов CWS на данных корпуса:
качественный анализ

Ошибки, сделанные сегментаторами на наших данных, можно разделить на две большие категории. Первая представляет разделение на
слова, которое, несомненно, нарушает целостность заимствований
и некорректно с точки зрения любого алгоритма словоделения. Эти
вхождения мы называем «однозначными ошибками». Вторая группа
представляет два класса заимствований, к выделению которых различные стандарты CWS подходят по-разному; поэтому данная группа
ошибок (по сути, являющаяся не в полном смысле слова «ошибками»)
названа «неоднозначными вхождениями».
Однозначные ошибки можно разделить на две категории — случаи
чрезмерной токенизации (заимствование разделяется на большее, чем
следует, количество слов) и недостаточной токенизации (в заимствование включаются соседние иероглифы из «стандартных» китайских
слов).
Случаи чрезмерной токенизации можно объединить в несколько
групп. Во-первых, часто выделяются иероглифы, выполняющие роль
грамматических маркеров, расположенные после заимствований (например, локативный послелог 里, lǐ или результативный маркер глагола 来, lái). К более примечательным случаям относятся два типа
вхождений. Так, заимствования из трех иероглифов, занимающие
именные позиции в китайских предложениях, нередко делятся на два
слова — односложное (первое) и двусложное (второе). Мы предлагаем
объяснять этот тип ошибок структурой китайского личного имени:
большинство китайских антропонимов состоит из односложной фамилии и следующего за ним двусложного личного имени. Так, транслитерация фамилии «Рогожин» разделяется сегментаторами PKUSeg
и Ckiptagger на два слова: 罗 luō (китайская фамилия Ло) и 戈任 gērèn
(может служить личным именем Гэжень).
Другой интересный тип ошибок связан с сегментацией четырехсложных заимствований: нередко они делятся на два двусложных слова. Мы предполагаем, что это следствие частотности двусложных китайских слов, которые, согласно [Wong, Xu 2010: 45], составляют 75 %
китайского лексикона. Согласно ряду работ, например, [Duanmu 1999],
тяготение китайского лексикона к двусложным словам объясняется
фонотактическими причинами. Итак, сталкиваясь с последовательностью из четырех слогов (графически соответствующих четырем иероглифам), алгоритм может посчитать, что более правдоподобным будет
разделение на два двусложных слова, а не на одно четырехсложное.
Явления недостаточной токенизации обычно происходят в случае,
если не отделяется односложная лексема, идущая после длинного заимствования. На первый взгляд этот процесс кажется обратным чрезмерной токенизации одиночных иероглифов в конце заимствований.
Однако подробный анализ выявляет обратное: случаи недостаточной
токенизации односложных лексем происходят с полнозначными глаголами (такими как 拿 ná «брать, поднимать» и 说, shuō «говорить»),
в то время как чрезмерная токенизация происходит со служебными
лексемами (например, с копулой 是 shì).
Обратимся теперь к неоднозначным вхождениям. Первый их тип
связан с, пожалуй, единственным указателем на иностранные имена,
принятым в китайской орфографии, — т. н. срединной точкой. Этот
знак (·) употребляется для разделения имени собственного, которое
в языке-доноре состояло из нескольких слов (в случае с русскими заимствованиями он будет ставиться, например, между именем и отчеством). Стандарт CNS предписывает разделять слова по этому знаку
и считать их разными токенами, в то время PKU и CTB предлагают
относиться ко всему транслитерированному кластеру, содержащему
срединную точку, как к одному слову. При этом алгоритмы, реализующие эти стандарты, имеют тенденцию работать противоположным образом: UDPipe, Stanza и fastHan (версия udc), основанные на
стандарте CTB, последовательно разделяют слова по срединной точке,
а основанный на CNS алгоритм Ckiptagger этого никогда не делает.
Следующий тип неоднозначных вхождений связан с родовыми словами. Так называются односложные (в большинстве случаев)
морфемы, которые нередко употребляются в постпозиции имени
собственного с целью его более точного определения. Они занимают
неоднозначную позицию с точки зрения как своих синтаксических,
так и семантических характеристик. Эту нестабильность отражают
и стандарты CWS: одни из них (государственный стандарт КНР, предшественник PKU) считают любые сочетания с родовым словом единым токеном, в то время как другие (например, PKU и CNS) дифференцируют разные родовые слова по разным признакам.
Алгоритмы в большинстве случаев не подчиняются стандартам,
однако в их действиях можно найти две тенденции. Первая: чем длиннее родовое слово, тем вероятнее оно будет отделено от имени собственного. Так, двусложный элемент 森林 sēnlín, «лес», отделяется от
предшествующего имени значительно чаще, чем односложный 村 cūn,
«деревня». Вторая тенденция заключается в более частом выделении
званий людей (которые занимают позицию родовых слов), нежели
в выделении родовых слов, характеризующих топонимы. Так, 将军
jiāngjūn, «генерал», всегда отделяется от предшествующей фамилии,
в то время как 城 chéng, «город», обычно образует единое целое с предшествующим названием.
Необходимо отметить, что две вышеописанные тенденции более всего совместимы с синтаксическим стандартом Penn Chinese
Treebank, который предписывает отделять титулы людей и многосложные постпозитивные элементы компаундов и при этом не отделять односложные постпозитивные морфемы. Это любопытно, так
как в данном случае за основу в выделении слов берутся не морфосинтаксические критерии, а фонотактические соображения, ведь стремление выделять двусложные родовые слова и не выделять односложные вновь напоминает нам тенденцию к употреблению двусложных
токенов в китайском языке, рассмотренную выше.
3. Исследования в области морфосинтаксической аннотации

Как уже было отмечено, в отличие от других языков при разметке
китайских текстов PoS-тэггинг не самая тривиальная задача. Это связано с тем, что существует несколько мнений о том, что такое части
речи в китайском языке и как они выделяются (дискуссия по этому
вопросу проиллюстрирована, например, в сборнике [Софронов 1989:
37–126]). Исходя из этого, существует большое количество стандартов
морфопарсинга для китайского языка. Более того, в ряде систем PoSтэггинга различают не только морфологические классы слов, но и семантические. Так, имена людей и названия географических объектов
могут размечаться различными PoS-тэгами.
Мы проверили алгоритмы китайского PoS-тэггинга на корректность разметки заимствованных слов, к которым относятся имена
людей и названия географических объектов. В качестве данных были
взяты те же предложения, что и для оценки качества алгоритмов CWS
(Раздел 2). Все предложения были разделены на две группы: содержащие топонимы и содержащие антропонимы (так как в ряде стандартов
этим группам присваиваются различные PoS-тэги). Мы рассмотрели
ряд алгоритмов, основанных на различных стандартах PoS-тэггинга
китайских текстов; все они представлены в табл. 2.
Как и в случае со словоделением, о количественном исследовании
подробно рассказано в [Семенов и др. 2021]. Отметим, что в этой задаче, аналогично CWS, явным лидером является fastHan.
Обратимся к качественному анализу ошибок PoS-тэггеров. Самые
частотные из них — это присвоение заимствованным существительным PoS-тэгов глаголов, прилагательных и наречий. При этом в некоторых случаях можно попробовать интерпретировать подобные ошибки: например, Ckiptagger разметил транслитерацию топонима
«Китеж» (基捷日 jījiérì) как «слово со значением времени» (отдельная
морфологическая категория в китайском, тэг Nb), вероятно, потому,
что в составе этого токена присутствует 日 rì («день, солнце»), составляющая частотная для временных слов.
Наконец, частотна ошибка, когда инструмент путает антропонимы и топонимы. При транслитерации фамилии «Гарин» (加林 jiālín)
Ckiptagger отнес имя человека к топонимам (тэг Nc), вероятнее всего,
из-за родового слова 林 lín, «лес». NLPIR, наоборот, при транслитерации города «Псков» (普斯科夫 pǔsīkēfū) приписывает тэг антропонима
nrf. Здесь можно предположить, что алгоритм введен в заблуждение
морфемой 夫 fū, «муж», которое нередко используется с личными именами или для образования профессий.
4. Заключение

В результате исследования мы сделали следующие выводы: с точки
зрения логичности в области словоделения и морфосинтаксической
аннотации наиболее подходящим для нашего корпуса является стандарт Penn Chinese Treebank, реализованный в CWS- и PoS-алгоритмах
fastHan.
Учитывая, что финальной целью исследований является улучшение алгоритма лингвистической аннотации ruzhcorp, мы планируем
встроить вышеописанные алгоритмы в систему препроцессинга китайских текстов. Тем не менее, нам предстоит доработать ряд алгоритмов (в частности, в области срединных точек), а также провести
фундаментальные исследования в области родовых слов и их морфосинтаксической и фонотактической трактовки.

Кроме того, наша рабочая группа продолжает практические исследования и эксперименты в области разметки китайских текстов,
а именно: дообучение наилучших моделей fastHan на наборах предложений из ruzhcorp; создание альтернативного модуля CWS, включающего нейросетевой модуль с определением смены кодов; эксперименты в области параллельной морфологической разметки (привлекая
PoS-тэги соответствующих русских предложений).