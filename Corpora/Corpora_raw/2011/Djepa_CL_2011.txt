Т.Л. Джепа КРИТЕРИИ ВЫБОРА ПРОГРАММНЫХ СРЕДСТВ ОБРАБОТКИ ТЕКСТОВЫХ ДАННЫХ В ЭЛЕКТРОННОЙ ЛЕКСИКОГРАФИИ Современная электронная лексикография предполагает использование предметно-ориентированных корпусов текстов, с помощью которых значительно расширяются возможности сбора и обработки данных о существующем составе и функционировании терминов заданной предметной области. Однако с обработкой постоянно увеличивающегося объѐма данных возникает другая проблема – верный выбор программных средств для реализации поставленных задач. На сегодняшний день отечественными и зарубежными разработчиками создано множество программ, позволяющих решать как частные вопросы обработки корпусных данных, так и их комплекс. В данной работе обобщаются результаты тестирования нескольких программных средств на соответствие критериям, сформулированным в рамках исследования «Лингвистический инструментарий построения базы данных на основе анализа предметно-ориентированного корпуса текстов». Предметной областью исследования является авиационное газотурбинное двигателестроение. Основу англо-русской базы данных составляют данные бумажных словарей, которые необходимо обновить и дополнить новыми данными, полученными на основе анализа корпуса текстов. Такой алгоритм работы представляется целесообразным, поскольку основной терминологический аппарат исследуемой предметной области сформироваться в XX веке. Наиболее развивающиеся на сегодняшний день направления авиационного двигателестроения, сопровождающиеся публикациями и появлением новых терминов – технологии конструирования и производства, новые материалы, типология 152 двигателей. Корпус англоязычных текстов составляется из научных и новостных публикаций в специализированной прессе. В качестве базовых критериев выбора программ обработки текстовых данных можно считать следующие: основное назначение (парсинг, исследование поведения слов в текстах, автоматическое аннотирование и т.д.); функциональность (возможность использования разных приложений программы для решения нескольких исследовательских задач); удобство использования (удобство настроек и интерфейса, возможность работы с файлами в требуемом формате); условия приобретения (платные / бесплатные, возможность тестирования демо-версии). В соответствии с первым критерием – основное назначение – для решения задач данного исследования рассматриваются программы, предназначенные для извлечения терминов из неразмеченного корпуса текстовых файлов, получения статистической информации по выбранным терминам и построения к ним конкордансов. С точки зрения функциональности желательно совмещение нескольких функций в одном программном средстве. Платные программы должны иметь демоверсии и подробные описания. На соответствие данным критериям были изучено и протестировано несколько программных средств, условно разделѐнных на три группы: инструменты извлечения терминов, инструменты получения статистической информации и инструменты построения конкордансов. Рассмотрим каждую группу инструментов. 1. Инструменты извлечения терминов Удобным и открытым для свободного доступа инструментом извлечения терминов является программа Terminology Extraction исследовательского центра T-Labs1. Извлечение осуществляется на основе распределения Пуассона, вычисления коэффициента подобия и частоты встречаемости термина по сравнению с 100-миллионными корпусами текстов на английском, итальянском и французском языках. Единицы, часто встречающиеся в документе, но редко в языке, признаются программой вероятными терминами, вероятность их терминологичности обозначается баллами. Результат извлечения выводится в виде таблицы, пример представлен на рисунке. Фрагмент таблицы результатов извлечения терминов из текста об аэродинамической оптимизации лопаток турбомашин Исходный текст помещается под таблицей, найденные в нѐм терминологические единицы маркируются, таким образом можно увидеть их в контекстном окружении. Недостатком программы является то, что с еѐ помощью каждый документ корпуса должен обрабатываться отдельно, поэтому еѐ нельзя признать полностью соответствующей критериям назначения и удобства. Одновременную обработку нескольких текстов поддерживает программа WordTabulator v.2.2.3. Инструмент предназначен «для построения упорядоченного индекса символьных элементов в заданном множестве текстов». Обрабатываемые элементы задаются в настройках, типы элементов определяются разработчиками как словоформы, словосочетания и синтагмы. В индексе (таблице результатов) указывается частота каждого элемента и документы, в которых он обнаружен. Программа поддерживает русский и английский языки, формат исходных файлов – .html и .txt. Возможность настройки стоп-листа отсутствует, меры ассоциации не вычисляются, поэтому программу нельзя назвать очень удобной для извлечения терминологии. Как следует из описаний инструментов LogiTermPro (Terminotix) и SDL MultiTerm Extract 2009, они в полной мере соответствуют необходимым критериям, но в связи с высокой стоимостью и отсутствием бесплатных демоверсий не тестировались. 2. Инструменты получения статистической информации Наиболее простые и доступные программы для получения статистической информации об элементах текста – приложение для создания частотных списков словаря Мультитран, SimWordSorter, Content Analyser v0.52. Данные инструменты, за исключением Content Analyser, вычисляют только частоту встречаемости отдельных слов в отдельных текстах. Content Analyser обрабатывает слова и словосочетания, но только в файлах в формате .html, так как его основное назначение – анализ содержания тематических Web-страниц2. Таким образом, данные инструменты только частично соответствуют критериям назначения и функциональности и не соответствуют критерию удобства использования. Инструменты построения конкордансов Инструмент Simple Concordance Program 4.09, несмотря на название, следует причислить к программам извлечения элементов текста, так как с его помощью можно получить список словосочетаний с заданным количеством слов, но контекстный просмотр найденных элементов отсутствует. Издательство Athelstan предлагает набор программных средств построения конкордансов. MonoConc Pro – инструмент для загрузки и поиска терминов по неразмеченному корпусу текстов на английском и нескольких других языках. Тексты должны быть в формате .txt. ParaConc Pro – инструмент для работы одновременно с двумя, тремя или четырьмя параллельными текстами. Содержит утилиту для выравнивания текстов. Ещѐ один инструмент – Collocate – предназначен для поиска в корпусе окружения для заданного слова (от 2 до 6 слов) и вычисления мер ассоциаций для извлеченных элементов. Используются меры Log Likelihood, Mutual Information, t-score. К сожалению, ни одна из этих программ не сопровождается демоверсией, подробное руководство пользователя предоставляется только при заказе программы. Пакет программ WordSmith Tools позволяет получать список слов отдельного англоязычного документа и совокупности документов, сравнивать полученный список с частотным списком слов Британского национального корпуса, вычислять ключевые слова текста и корпуса текстов, получать конкорданс к отдельному слову и нескольким словам, вычислять кластеры слов. Используемые меры ассоциаций: Specific Mutual Information, MI3, Z Score, Log Likelihood, t-score; меняя настройки приложений, их можно использовать совместно или избирательно. Программа позволяет соотнести полученный список ключевых слов с имеющейся базой терминов, однако подключаемая база должна быть сформирована также в формате .txt и состоять из однословных наименований. Программа платная, но снабжена подробным, доступным руководством и удобной демо-версией. Поддерживаются другие языки, но для них нет частотных списков национальных корпусов. Несмотря на эти ограничения, в целом, данный программный комплекс в наибольшей степени соответствует всем заявленным критериям. 4. Заключение Таким образом, выделенные критерии выбора программных средств обработки текстовых данных позволили определить основной инструмент работы с предметно-ориентированным корпусом текстов, который может быть дополнен другими инструментами в зависимости от условий реализации исследовательских задач.