О.А. Митрофанова
(Санкт-Петербургский государственный университет)
ИЗМЕРЕНИЕ СЕМАНТИЧЕСКОЙ ИНФОРМАЦИИ В ТЕКСТЕ 
НА ОСНОВЕ АНАЛИЗА ЛАТЕНТНЫХ СВЯЗЕЙ
Как утверждал физик П. Дирак, во всякой науке ровно столько истины, сколько в ней математики. Лингвистическая наука предоставляет как опровер-жения, так и доказательства данной мысли. С одной стороны, естественный язык имеет качественную природу, и далеко не все его проявления поддаются формализации или количественной оценке. С другой стороны, можно выявить те фрагменты языковой системы, описание которых допускает применение математического аппарата. Казалось бы, содержательный аспект естественного языка, в силу своей необъятности и трудноструктурируемости, может являться только контрпримером к наблюдению П. Дирака, тем не менее, целый ряд семантических исследований свидетельствует об обратном.
Классическое решение проблемы измерения семантической информации в тексте было предложено в 1950-е гг. И. Бар-Хиллелом и Р. Карнапом, среди отечественных исследователей в том же направлении работали Р.Г. Пиотров-ский и Ю.А. Шрейдер (см., например, [1]). Это решение предполагает задание искусственного закрытого языка L, алфавит которого состоит из конечного числа констант C (например, существительных, однозначно соотносимых с объектами и понятиями онтологии), одноместных предикатов P (прилагатель-ных, причастий), экзистенциального предиката E и логических связок (V, &, →, ). На основе данного алфавита стоятся предложения S. Это прежде всего атомарные предложения, которые, в свою очередь, могут объединяться в более сложные синтаксические конструкции. Цепочки, являющие собой конъюнкцию атомарных предложений, включающих в себя всевозможные константы, предикаты или их отрицания, есть описания некоторых состояний D в языке L. Все предложения языка L так или иначе соотнесены с действительностью, и тем самым, им могут быть приписаны значения истинности или ложности. Для определения количественной оценки смысловой информации в тексте применя-ется функция m, позволяющая определить абсолютную логическую вероят-ность предложений и описаний состояний языка L. Если предложение S ложно, то m(S) = 0. Если предложение имеет истинностное значение, то его абсолют¬ная логическая вероятность положительна и вычисляется как сумма абсолют¬ных логических вероятностей всех описаний D, в состав которых оно входит. Тем самым, измерение смысла в отдельном предложении может быть осущест¬влено стандартными средствами теории информации [2]: I(S) = – log2 m(S).
Эффективность данного метода может быть повышена при расширении языка L за счет введения многоместных предикатов, дополнительных связок и пр., а также тезауруса, предоставляющего описание необходимых данных о внешнем мире. Это привело бы к созданию семантического пространства, в котором возможно введение метрики и определение количества заключенной в нем информации через число и силу семантических связей (см, например, [3; 4; 5; 6]).
Следует признать, что данный метод измерения смысла есть часть лингвистической теории, он имеет ограниченную сферу применения и может быть полезен лишь в случае обработки текстов на искусственных языках или в случае анализа формализованных фрагментов естественного языка. Вместе с тем, он предполагает не прямое, а опосредованное обращение к смыслу язы-ковых выражений.
Практические нужды описания естественного языка потребовали разра-ботки более надежных инструментов измерения семантической информации в тексте и более реалистичных путей решения данной проблемы. Одним из них является латентный семантический анализ (ЛСА) – процедура измерения семантических расстояний между языковыми единицами на основе внутри- и межтекстовых связей.
ЛСА предполагает обращение к корпусу текстов и позволяет исполь¬зовать данные о значении, хранящиеся за пределами языкового знака. При помощи ЛСА можно определять содержательную близость лексических еди¬ниц, сопоставляя их синтагмати¬ческие свойства. Данный подход вполне согла¬суется с теорией значения как употребления, с идеей неаддитивного сложения смыслов (речь идет о реализации в тексте отношений семантического согласо¬вания, то есть о дубли¬ровании в контексте той семантической информации, кото¬рая содержится в слове).
ЛСА – это статистический метод извлечения и анализа семантической информации из корпуса текстов, не требующий предварительно созданных лексикографических описаний, сетевых представлений, баз знаний и пр. Идеологическую основу метода ЛСА составляет предположение о том, что между отдельными словами и контекстами их встречаемости – будь то мини-мальное окружение лексических единиц или целое предложение и даже текст – существуют неявные, или латентные, взаимосвязи. Тем самым, метод ЛСА направлен на выявление скрытых внутритекстовых или межтекстовых отношений. Сфера применения ЛСА обширна: эта процедура активно исполь-зуется в информационном поиске для кластеризации документов, в тезау¬русном моделировании для формирования групп близких по значению слов на основе статистического анализа их сочетаемости с элементами контекста, и т.д. Наиболее авторитетными учеными, практикующими ЛСА в том или ином виде, являются П. Гамалло, К. Гасперин, П. Смрж, П. Рыхли, Т. Ландауэр, С. Дюма, П. Фольц и др. С результатами исследований в области ЛСА можно также ознакомиться и в ряде электронных источников [7].
Обсуждая идеологию и особенности практического применения ЛСА, мы ограничимся данными современных исследований латентных связей внутри текста и попытаемся в них найти ответы на принципиально важные вопросы.
Что понимается под отношением семантической близости в ЛСА? 
Очевидно, критерии семантической близости языковых единиц при осуществлении процедуры ЛСА должны отличаться от тех критериев, которые предъявляются к отношениям синонимии, антонимии, гипонимии, конверсии, меронимии, холонимии, тропонимии и др. в лексической семантике (см., напри-мер, [8; 9]). В практических исследованиях оказывается более предпочти-тельным широкое понимание семантической близости, предполагающее высокую частоту взаимной встречаемости языковых единиц в контексте (см., например, [10]).
Одной из наиболее доступных практических иллюстраций использования данного метода является ресурс Google-Sets [11], который показывает, что группы слов, формируемые с помощью ЛСА, вряд ли представляют какие-либо из стандартных семантических отношений и скорее соотносимы с классами условной эквивалентности (см. пример 1).
Пример 1. Water, Air, Fire, Food, Electricity, Gas, Earth, Energy, Land, Salt, Minerals, Soil, Vitamins, Waste, Oxygen
Какова специфика математического аппарата, применяемого в ЛСА? 
Из математических инструментов в ЛСА успешно используются методы теории множеств и теории информации, дополняющие вероятностно-статис-тические методы.
Применение методов теории множеств в ЛСА иллюстрируется в иссле-довании, проведенном португальскими учеными П. Гамалло, К. Гасперин и др. [12] на материале корпуса текстов объемом около 1,7 тыс. словоупотреблений. Предварительно были осуществлены процедуры частеречной разметки и син-таксического анализа данного корпуса. Оценивалась семантическая бли¬зость свыше 4 тыс. существительных, связанных синтагматическими отношениями. Для каждого вхождения сущес¬твительного в текст устанавливались его непосредственные распространители (их оказалось около 200 тыс.).
Для оценки семантической близости слов в тексте используется бинарная мера Жаккара [13] в следующей форме: 
BJ(m,n) = |A(m) ∩ A(n)| / |A(m) U A(n)|, 
где m, n – слова, A(m), A(n) – множества распространителей слов m и n.
Применима также и взвешенная мера Жаккара:
WJ(m,n) = ∑ min (w(m,aj), w(n,aj)) / ∑ max (w(m,aj), w(n,aj)), 
где aj – распространитель, w = gw·lw – вес распространителей, опре-деляемый как произведение глобального gw и локального lw весов: 
gw(mi, aj) = 1 – ∑ [ |pij log2(pij)| / log2(nrels) ], pij = fr(mi, aj) / N(mi, aj), fr(mi, aj) – частота распространителя aj для слова mi , N(mi, aj) – общее число распростра-нителей aj для слова mi , lw(mi, aj) = log2(fr(mi, aj)).
В результате были получены группы близких по значению слов, подоб-ных приведенной в примере 2.
Пример 2. fim – objectivo, finalidade, resultado, efeito
Данный метод позволяет оценить тесноту семантических связей слов и сформировать кластеры близких по значению лексических единиц с учетом весов их распространителей при том условии, что для каждой пары лексем определено отношение числа совпадающих распространителей к их общему числу.
Применение методов теории информации демонстрируется в исследова-нии чешских коллег П. Смржа и П. Рихли, целью которого была разработка автоматической процедуры выделения семантически близких слов в тексте [10]. Мера взаимной информации [14], определяющая количество информации о слове х, содержащейся в слове у, используется авторами с тем, чтобы выявить языковые единицы, характеризующиеся высокой частотой совместной встреча-емости в контексте. При этом рассматриваются два дискретных множества Х и Y, а также ансамбль XY, образованный всевозможными парами типа (х,y). Для каждой языковой единицы х и y определяется собственная информация 
I(х) = –log2 p(x), I(y) = –log2 p(y), а также условная собственная информация I(х|y) = –log2 p(x|y), I(y|x) = –log2 p(y|x), тогда количество взаимной инфор-мации между языковыми объектами можно вычислить следующим образом: 
I(x;y) = log2 [ p(y|x) / p(y) ] = log2 [ p(x,y) / p(x) p(y) ]. Мера взаимной инфор-мации позволяет сопоставить вероятность совместной встречаемости слов x и y и их независимого употребления. Если между единицами x и y есть связь, то I >> 0, если связь незначительна, то I  0, если I << 0, то x и y находятся в отношениях взаимной дистрибуции.
Для апробации предложенной процедуры исследователи обратились к корпусу чешского языка объемом 120 млн словоупотреблений, в результате чего были выделены кластеры семантически соотнесенных слов (см. пример 3).
Пример 3. výpar; kontaminovat, zamoření, spad; znečistit, zamořit; znečištění; rozpouštědlo, vyčištění
Возможно, некоторые результаты, которые были достигнуты при класте-ризации, и не вполне соответствуют языковой интуиции говорящих, однако сама процедура поиска семантически близких слов в корпусе большого объема оказалась вполне эффективной.
В ЛСА применяются разнообразные вероятностно-статистические прие-мы, например, метод Байеса [15], SVD-метод [16; 17; 18] и т.д., но они предпо-лагают большой объем анализируемой информации и поэтому требуют отдель-ного обсуждения.
Как определять состав и границы контекста 
при проведении процедуры ЛСА? 
При осуществлении ЛСА контекст трактуется как с лингвистических позиций, так и с позиций информационного поиска.
С одной стороны, в качестве критерия выделения состава и границ контекста можно использовать морфологическую и синтаксическую информа-цию об исследуемых языковых единицах (см., например, [12]). Контекст в этом случае можно понимать как упорядоченную тройку, реализующую бинар¬ное отношение синтаксической зависимости r(m,n), как правило, на уровне именных групп с зависимой предложной или беспредложной формой, к примеру, autorizaçăo à empresa. Обработка текста может осуществляться с учетом соседей справа и слева или только справа, а также с учетом и без учета предложных форм. Так, в примерах 4 и 5 ряды для одних и тех же слов несколько отличаются друг от друга, поскольку при их формировании исполь-зовались разные стратегии – с учетом и без учета предлога соответственно.
Пример 4. finalidade – objectivo, escope, fim, objecto
lei – artigo, decreto, diploma, norma
tempo – data, momento, ano, antiguidade
Пример 5. finalidade – capacidade, campo, financiamendo, publicidare
lei – artigo, decreto, n, norma
tempo – década, presidente, admissibilidade, problemática
Следует подчеркнуть, что лингвистическая трактовка контекста требует обращения к морфологически размеченному корпусу, совместимому с синтак-сическим анализатором. Кроме того, существуют исследовательские задачи, сами по себе требующие обнаружения и описания именно лингвистических контекстов [19].
С другой стороны, при ограничении контекста языковой единицы можно руководствоваться формальными критериями, продиктованными процедурой информационного поиска. По этой причине контекстом языковой единицы может являться сам документ (вне зависимости от его размера). С тем, чтобы внести определенность в отношении объема контекста, предлагается рассмат-ривать его как окно [–N…N] (см., например, [10], где N=20). N следует опреде-лять как число единиц текста, располагающихся по обе стороны от описыва-емого слова. Данная трактовка контекста не учитывает разбивку текста на предложения, абзацы и пр., а также является приемлемой при работе с корпу¬сом без обращения к специализированным лингвистическим инстру¬ментам.
Какие факторы влияют на качество результатов ЛСА? 
Нет сомнений, что исход ЛСА зависит от степени точности определения семантических связей, от выбора типа контекста и разумеется, от математичес-кого инструментария. Обо всем это можно судить на основе практических дан-ных, упоминаемых в работах [7; 10; 12] и т.д., а также сопоставляя примеры 1–7.
Так, примеры 6 и 7 иллюстрируют результаты запросов Google Sets для слова truth. Множество, приведенное в примере 6, позволяет оценить резуль-таты расширенного запроса, а множество, приведенное в примере 7 – резуль-таты ограниченного запроса.
Пример 6. Truth, Faith, Hidden causes, Being involved, Being persuasive, Love, Justice, Righteousness, Salvation, Peace, Equality, Hope, Patience, Goodness, Mercy, Gentleness, Holiness, Joy, Diversity, Patriotism, Beauty, Spirit, Grace, Forgiveness, Wisdom, Prayer, LIKES, Godliness, Self control, Kindness, Liberty, Benevolence, Power, Unchangeable, Infinite, Perfect, One, Eternal, Freedom, Honesty, Courage, Service, Individual, Rights, Meekness
Пример 7. Truth, Love, Hidden causes, Being involved, Being persuasive, Justice, Equality, Faith, Brotherly love, Righteousness, Beauty, Relief, Reality
Обращение к более эффективным методикам извлечения семантических данных из корпуса и более специализированным ресурсам, например, к WordSketches [20], позволило бы получить более качественные и лингвисти-чески адекватные результаты.
Наблюдения, отраженные в данном докладе, позволяют нам сделать следующие выводы. Во-первых, если говорить о будущем измерения семанти-ческой информации в тексте, то в лингвистической практике оно все же остается за ЛСА. Во-вторых, само по себе измерение семантической инфор¬мации есть некоторый этап в комплексной процедуре ЛСА, итогом которой является лингвистическая интерпретация количественных данных, извлечен¬ных из текста.
