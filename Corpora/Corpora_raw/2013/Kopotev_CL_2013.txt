М. Копотев, Л. Пивоварова
«НЕ ДО Х»: АЛГОРИТМ ВЫЯВЛЕНИЯ УСТОЙЧИВЫХ ПАРАМЕТРОВ В СОЧЕТАНИЯХ СЛОВ
Язык как таковой можно рассматривать как «конструктикон» (constructicon1), в природу которого заложена спаянность единиц разного уровня и отсутствие границ между ними. По этой причине разработка формальных методов для измерения силы морфологических и лексических отношений между словами кажется нам одновременно и важной, и проблематичной. Предлагаемый подход в целом призван отвечать на вопрос, в чем причина того, что слова встретились вместе, – в их морфологических особенностях, лексической совместимости или в комбинации того и другого. Приведем примеры.
В сочетании «не до Х» самой устойчивой морфологической категорией является падеж, для которой значение родительного падежа реализуется у большого числа словоформ, а значение второго родительного (партитива) реализуется только в нескольких конкретных лексемах. Таким образом, студент или исследователь, желающий выяснить, какие значения может принимать Х в шаблоне «не до Х», должен, в идеале, получить следующий ответ: самый устойчивый параметр для Х – падеж, при этом:
 «не до + S.gen» – это сочетание с открытым списком лексем (коллигация);
 «не до + S.gen2» – это устойчивые сочетания типа не до смеху, не до жиру (коллокации).
Таким же образом можно сказать, что в сочетании «как Х на сковородке» самый устойчивый морфологический признак – одушевленность существительного. В сочетании «Х знает что» наиболее устойчивыми являются мужской род существительного и ряд конкретных лексем: БОГ, ЧЕРТ и т.д. и т.п.
Для автоматического решения такого рода задач мы разработали алгоритм, основанный на вычислении энтропии и дивергенции относительно нормального или выборочного распределения всех параметров для данного сочетания слов. На вход алгоритма подается произвольная nграмма (где n=24), где одна или больше позиций остаются незаполненными. Алгоритм находит ответы на следующие вопросы:
 какая морфологическая категория оказывается наиболее устойчивой для этой позиции?
 какое значение этой морфологической категории наиболее устойчиво?
 и наконец, что устойчивее: конкретные токены или морфологические параметры с открытым списком лексем?
Статистические модели, использованные в данной работе, помогают распределить частоты морфологических признаков и лексических единиц определенного шаблона на единой шкале, с тем чтобы определить наиболее стабильные параметры. Например, алгоритм принимает на входе лемму «греть» и производит упорядочение списков ожидаемого совместного вхождения, например, устойчивое выражение «греть душу», словосочетание «греть воду» и коллигация «греть + N.acc». Токен или лемма не являются единственными возможными вариантами на входе алгоритма, поэтому в запросе может содержаться указание на часть речи или любая комбинации морфологических параметров – в любом случае система находит все левые или правые контексты для заданного запроса и организует их в соответствии с их морфологической и лексической устойчивостью.
Метод
Говоря кратко, разработанная модель определяет разницу в распределении параметров в целом по корпусу и в определенном шаблоне.
Например, на pис. 1 представлено распределение падежей существительного в корпусе (темносерые плашки) и после предлога в (светлосерые плашки). На pис. 2 показано соответствующее распределение родов существительного. Как видно, значения рода распределены более или менее равномерно как в корпусе, так и в ограниченном контексте с предшествующим предлогом в.
Распределение падежей, напротив, совершенно иное: винительный и предложный падежи существенно чаще встречаются после этого предлога, чем любые другие. Это связано с тем известным
фактом, что предлоги контролируют падеж управляемого существительного, но не его род. Именно в этом состоит основанная
идея нашей модели.
Для измерения этого распределения мы используем нормализованную дивергенцию КульбакаЛейблера 1 . Параметры с
наибольшим значением нормированной дивергенции считаются
максимально связанными шаблоном. Для определения существенных значений выбранного параметра используется мера
отклонения (weirdness measure, frequency ratio), которая была
предложена в работе1 и использована в ряде других2. В целом, алгоритм работает следующим образом3:
 поиск всех токенов, которые появляются в шаблоне запроса, и их группировка в соответствии с частеречными тегами;
 расчет внутри каждой POSгруппы нормализованной дивергенция КульбакаЛейблера для всех параметров: тегов морфологической разметки, лемм и токенов; параметры, которые показывают максимальное расхождение с общекорпусным распределением, считаются наиболее значимыми для шаблона;
 значения каждой категории сортируются в соответствии с мерой отклонения: если значение меры составляет меньше 1, то значение считается случайным.
Эксперименты
В качестве материала для исследования мы использовали данные, извлеченные из подкорпуса со снятой омонимией НКРЯ (т.н. «снятник» НКРЯ, 5 944 188 токенов).
В настоящий момент разработан только основной алгоритм, который систематически проверен на списке из 25 непроизводных предлогов, которые обладают легко предсказуемым морфосинтаксическим свойством – падежным управлением. Предсказания модели совпадают с этим ожидаемым для всех из них, другими словами наибольшее значение дивергенция КульбакаЛейблера принимает для категории падежа, для которой «мера отклонения» во всех случаях больше единицы. Это означает 100% точности (precision) и полноты (recall) в этом случае. При проверке конкретного значения категории мы обнаружили, что алгоритм предсказывает правильные падежи для 21 из 25 предлогов1.
Таким образом, мы можем говорить, что алгоритм достаточно надежно предсказывает коллигации, или устойчивые сочетания лемм/токенов и морфологических признаков. Однако система, над которой мы работаем, предназначена для обработки как морфосинтаксической, так и лексической совместной встречаемости, рассматривая их как единый континуум без четких границ. Следующий шаг, над которым мы начинаем работать, – это устойчивость токенов / лемм в шаблоне. Было установлено2, что в корпусе без морфологической разметки даже простая сортировка по частоте работает достаточно хорошо. Поскольку наши данные содержат богатую морфологическую информацию, при выявлении коллокаций мы опираемся именно на нее. Опишем наш подход на конкретных примерах.
Ничтоже сумняшеся. Существуют коллокации, в которых грамматические параметры оказываются менее устойчивыми, чем токены. К самым очевидными примерам относится, в частности, оборот ничтоже сумняшеся, в котором грамматических параметров нет вовсе, а после ничтоже возможен только один токен. Естественно, что в запросе «ничтоже X» максимальное значение дивергенции показывается класс Токены и его значение сумняшеся. Запрос на установление левого контекста «Х сумняшеся» тоже возвращает максимальную дивергенцию для Токенов. Это, конечно, самый простой случай.
Слово в слово оказывается более сложным случаем. На месте X в запросе «слово в Х» возможны единицы, в разной степени устойчивости: случайные (слово в театр), частотные свободные сочетания (слово в предложении), устойчивые обороты (слово в защиту), идиомы (слово в слово). Нормализованная дивергенция определяет в качестве победителя только грамматические параметры, при этом самыми устойчивыми оказываются категория одушевленности, падежа и рода:
Как мы видим, категория числа и особенно леммы проигрывают другим категориям. В то же время выявить победившее значение в первых трех категориях не удается: мера отклонения не превышает единицы ни для одного из значений одушевленности, рода и падежа (Табл. 2).
Содержательно это значит, что ни одно из грамматических значений не является достаточно стабильным, чтобы выделить коллигацию вида «слово в [gram.tag]»1. В то же время значения неодушевленности и, в меньше степени, аккузатива являются наиболее устойчивыми из всего набора возможных признаков.
Мы полагаем, что именно эти сведения можно использовать для определения коллокации в тексте.
Идея, лежащая в основе следующего шага алгоритма, основана на использовании тех данных, которые мы получили на предыдущем этапе. В этом мы опираемся на идею грамматических профилей, предложенную С. Грайсом и Д. Дивьяк и развитую Л. Яндой и О. Ляшевской1. Наша реализация этого подхода основана на том, что распределение токена/леммы в шаблоне подсчитывается с учетом грамматических признаков, получивших наибольшие значения меры отклонения, то есть являются наиболее специфичными для шаблона. Так, в указанном примере устойчивость лемм в шаблоне подсчитывается не относительно всех токенов или всех леммсуществительных в корпусе, а только относительно токенов, имеющих такой же грамматический профиль, например, S.inan.acc. Проверим это.
Вопервых, мера отклонения для лемм, подсчитанная относительно общекорпусной, дает ожидаемо плохой результат. Лемма отдельность побеждает, потому что она вообще очень редко встречается в корпусе.
В таблице ниже приведены данные той же меры отклонения, подсчитанной с целью эксперимента относительно подвыборок, представляющих разные грамматические профили.
Из этого эксперимента следует, что результат, в наибольшей мере соответствующий интуиции (слово в слово), получен только для профиля S.inan.acc, в который входят два самых релевантных признака, полученных на предыдущем этапе: неодушевленность и аккузатив. Во всех других случаях побеждает лемма отдельность – отнюдь не потому, что она характерна для этой коллокации, а потому, что она является редкой, и даже ее случайное попадание в цепочку обеспечивает ей победу. На практике использование грамматического профиля позволяет отсечь лексический материал, не поддержанный синтаксической конструкцией.
Выводы
Конечно, наша работа находится еще в самом начале. Но уже сейчас можно видеть, что извлечение коллигаций произвольной длины предложенным методом дает достаточно надежные результаты. Извлечение коллокаций с учетом грамматических профилей кажется ближайшей перспективной задачей.